<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[网络代理]]></title>
    <url>%2F2018%2F08%2F05%2F%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是代理，网络代理，代理服务器代理（proxy）很容易理解就是代表处理，在生活中，有些事情就不是本人去完成，找一个人代你去完成，它是你代理人。把你的权利交给你的代理人，一般在这种在法律上比较常见，但是在计算机的世界里还好，经常会出现这种代理的现象，比如就有个设计模式叫代理模式。 在网络上发出请求是客户端，接收请求的是服务器端。请求从客户端到服务器端会通过好多网络。然后到达服务器端，这个时候一般中间会有好多服务器帮你 转发请求，不是客户端直接去链接服务器端，他们就是代理服务器。而网络代理就是帮你转发的请求的过程，那些帮你转发的服务器就是代理服务器。它的工作主要在开放系统互联(OSI)模型的对话层。我上面所描述的代理也就是正向代理。 正向代理正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。 举个栗子： 我是一个用户，我访问不了某网站（facebook）由于GFW（Great Fire Wall），但是我能访问一个代理服务器，这个代理服务器呢,他能访问那个我不能访问的网站，于是我先连上代理服务器,告诉他我需要那个无法访问网站的内容，代理服务器去取回来,然后返回给我。从网站的角度，只在代理服务器来取内容的时候有一次记录，有时候并不知道是用户的请求，也隐藏了用户的资料，这取决于代理告不告诉网站（facebook）。也就是可以在代理上做一些手脚，有人把代理机叫做跳板机。 优点： 1．突破自身IP访问限制：访问国外站点。教育网、169网等网络用户可以通过代理访问国外网站；或者访问一些单位或团体内部资源，如某大学FTP(前提是该代理地址在该资源 的允许访问范围之内)，使用教育网内地址段免费代理服务器，就可以用于对教育网开放的各类FTP下载上传，以及各类资料查询共享等服务。 2、提高访问速度：通常代理服务器都设置一个较大的硬盘缓冲区，当有外界的信息通过时，同时也将其保存到缓冲区中，当其他用户再访问相同的信息时， 则直接由缓冲区中取出信息，传给用户，以提高访问速度。 3、隐藏真实IP：上网者也可以通过这种方法隐藏自己的IP，免受攻击 4、对客户端访问授权，上网进行认证。（它可以记录你的访问信息和访问记录，从某个角度说GFW也可以说是一个代理，不过他的代理是只能代理部分网站，不是所有的都能去访问。他通过IP黑名单或者DNS污染禁止你去访问一些网站）。 一般网络根据协议去代理，比如说socke代理，http代理，htts代理，vpn代理等。 反向代理反向代理（Reverse Proxy）实际运行方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器（一般也要和DNS服务器配合），并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。一般反向代理需要配置的是服务端（所以一般程序员使用的比较多） 举个栗子： 在拨打10086客服电话，可能一个地区的10086客服有几个或者几十个，你永远都不需要关心在电话那头的是哪一个，叫什么，男的，还是女的，漂亮的还是帅气的，你都不关心，你关心的是你的问题能不能得到专业的解答，你只需要拨通了10086的总机号码，电话那头总会有人会回答你，只是有时慢有时快而已。那么这里的10086总机号码就是我们说的反向代理。客户不知道真正提供服务人的是谁。 优点： 1、保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击，如Dos，DDos。大型网站，通常将反向代理作为公网访问地址，Web服务器是内网。（WAF（Web Application Firewall）网站应用级入侵防御系统。Web应用防火墙是通过执行一系列针对HTTP/HTTPS的安全策略来专门为Web应用提供保护的一款产品。） 2、负载均衡，通过反向代理服务器来优化网站的负载。若服务器簇中有负荷较高者，反向代理通过URL重写，根据连线请求从负荷较低者获取与所需相同的资源或备援。 3、对一些内容进行压缩，以节约带宽或为网络带宽不佳的网络提供服务；还可以缓存静态内容，当静态内容发生变化时，通过内部通知机制通知反向代理服务器缓存失效，需重新加载。（也就是所谓的CDN （Content Delivery Network ）内容分发网络） 4、提供HTTP访问认证。统一提供加密和SSL加速（如SSL终端代理）。 一般反向代理都是通过服务器去分发请求，这种服务器有Nginx、Tengine、HAProxy、Apache HTTP Server。 正向代理与反向代理的区别正向代理中，proxy和client同属一个LAN，对server透明； 反向代理中，proxy和server同属一个LAN，对client透明。 实际上proxy在两种代理中做的事都是代为收发请求和响应，不过从结构上来看正好左右互换了下，所以把后出现的那种代理方式叫成了反向代理。 总结正向代理通过代理服务器隐藏客户端，反向代理是通过代理服务器隐藏服务端。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java垃圾回收与JVM]]></title>
    <url>%2F2018%2F06%2F20%2F%E6%B5%85%E8%B0%88Java%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%8EJVM%2F</url>
    <content type="text"><![CDATA[简介Java与JVM 为什么要有JVM。在程序里，没有一件事情是抽象出来一层解决不了的，如果有那就抽象出两层。 大家都知道，Java是一门跨平台的语言，有那么一个非常经典梗—一次编写，处处异常(一次编写，处处运行)。java是通过JVM实现在不同平台上运行的，无论你是Windows，Linux还是其他什么系统，只要你能装上对应的支持JVM，就可以把代码拿过来直接使用。不需要做任何修改（当你没有自定义或者调用一些特有的Native方法就可以）就可以直接运行。这就归功于JVM的设计，也就是Machine和Code之间抽象Virtual Machine（有所问题都可以通过抽象一个层次来解决）；java不用与系统底层直接打交道，而是通过JVM进行内存的分配与回收，多线程的处理等等。 我们都知道高级语言一般分两种，一种是编译型语言，一种是解释型语言。编译型语言就是常用的C、C++，Basic等他们都是编译语言，使用的时候都是先编译成目标文件（也就是.o和.obj文件），然后再去链接相应的类库，的工具库，然后才能运行，（做了一大桌子菜，都做好了，才能开始吃饭；菜就是代码，人就是CPU；也就是代码在运行之前就已经确定了，不能在改变）。他们编译之后都变成了机器码，不同的机器上对机器码（就是CPU执行的指令，就是一大堆0和1）的要求可能也不同，比如32位机和64位机，windows系统和linux系统，所以可能在别的机器上完美运行的代码在其他机器上就会有问题。所以编译型语言在不同的平台上使用不同的编译器重新编译一遍才能运行而解释型语言就不一样，他是通过解释器，解释给系统底层，一般没有编译的过程，在运行时候解释给操作系统（这个过程就像吃火锅，你需要什么就在里面加什么根据自己的喜好，而且还可以在这个过程中在进行二次处理，比如说反射的一些应用。也就是程序会在运行时被解释。我们可以在解释之前做一些操作）；这类语言有PHP，JavaScript，Ruby等等一般他们都是不需要编译。而java是介于这两者之间的一种语言。属于混合型。因为java有编译的过程（前期编译，后期编译），大多数时候java是被编译成字节码文件也就是.class文件。但是有一些常用或者热点代码也会直接编译成本地代码（机器码）直接被使用（详情可以看看JIT）。所以java属于混合型，这类型的语言还有C#。他们不是直接把代码交给解释器直接去执行，而是先编译成一个中间文件，然后再把中间文件交给解释器去处理。 Java与C++之间有一堵内存动态分配和垃圾回收的技术所围城的“高墙”，墙外的人想进去，墙里的人却想出来。对与C和C++的程序员他们都是自己去管理内存（malloc和free）否则就会产生内存泄漏和溢出的问题。内存泄漏指的是本应该回收（不再使用）的内存对象无法被系统回收的现象；在C++和C中都是程序猿手动申请和释放，而java是通过JVM实现内存的分配和回收，可以减少内存的泄漏，但是也不能完全避免。java使用的是可达性算法，来回收那些没有使用的也就是不可达的对象。但是被使用对象引用的无用对象却不能被回收；内存泄漏一般都是情况有，单例模式的使用，类里面的静态变量，Threadlocal弱引用key问题等等；内存溢出是指当对象分配内存时，可用内存小于对象的内存，也就是内存不足现象。两者也是有一定关联也就是如果内存经常泄漏导致可用内存越来越少，最后会导致内存溢出。 同样内存溢出也可能会导致安全问题，一般是缓冲区和栈内存，因为他们都是连续的内存，所以黑客可以通过你内存的溢出的位置去查找你栈中和缓存区的数据，然后修改数据。不过程序猿把控制权交给了JVM，一旦出现内存泄漏和内存溢出问题就会很难排查。我之前有一篇文章写java内存模型的，可以先了解一下JVM内存。 JVM内存分配策略 JAVA虚拟机里面各个区域都装的什么，难道是shit吗？ 回顾java运行时内存是由，java堆，虚拟机栈，程序计数器，方法区（现在是metadata），本地方法栈和运行常量池组成。还有一部分是直接内存，直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的内存区域，就是JVM以外的机器内存，比如，你有4G的内存，JVM占用了1G，则其余的3G就是直接内存。这部分被频繁的使用，所以也会出现OutOfMemory异常。在Java NIO中引入基于通道和缓冲区（Buffer）的I/O方式，它可以使用Native函数直接分配堆外内存也就是直接内存，（也就是JVM调用系统方法，把数据读取到内存中，而这一块内存不在JVM的堆内存中heap Memory。JVM在操作系统里其实就是一个进程）然后通过一个存储在java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些情况下显著提高性能，因为避免了在java堆和Native堆中来回的复制。 对象与引用什么是对象（对象是程序运行时的实体；它的状态存储在 fields (也就是变量)行为是通过方法 (method) 实现的；方法上操作对象的内部的状态方法是对象对对象的通信的主要手段）。 肯定有人说对象就是女朋友啊。没错如果你没对象可以尝试new一个出来。放心你在怎么new都不会有对象（女朋友）。开个玩笑，对象就是程序运行时用来存储数据的一个集合体(实体)，他包含你声明类（class）中有的变量（可能这些变量都是空）和一些操作变量的方法，一般java都是通过方法来操作属性，大多树情况下对象存在java堆中（也有可能存在堆上，这个要进行逃逸分析），通过引用去找到这个对象对象是程序运行时的实体。java是一门面向对象语言(Object-oriented programming OOP)。面向对象语言是对以前C的面向过程进行封装，过程都是通过函数来实现，也就是一个程序有很多函数。但是对象把函数和变量封装成一个整体，通过操作对象来实现对业务的处理（对数据的加工）或者实现功能，也可以说对象是对函数和变量的抽象。增加了代码的可复用性和灵活性，但是也增加了对象之间的关系比如说继承和多态（设计模式，增加代码的的复用性的设计）。其实函数式编程可以更好的减少代码（一个功能，代码写的越多bug越多，维护成本越高，尽量少写bug）。 什么是引用。（引用是数据存储于内存或存储设备中的地址。因此，引用亦常被称为该数据的指针或地址） 引用类型和其他基本类型差不多，都是存储值，只不过引用存储的是java堆内的地址。如果赋值了就像这样： 1Student s = new Student(); //创建一个新的Student对象 也就是把new 出来的 Student对象在java堆中的地址给s。之后我们操作这个新对象，都通过引用s。因为s就像一把钥匙能打开这个java堆中存储这个对象的大门，它可以操作Student对象的方法和变量，大多数时候我们都是这样操作对象。同样引用和基本类型都在栈上存储。但是String这个类型比较特殊，他的值一般都在堆上存储（直接赋值的String 一般都是存在字符串常量池（ Strings Pool）在堆里，这样方便管理字符串内容相同的String对象，他们都指向一个字符串，而不是多个。new出来的String对象除外，不在池子里），这个和引用类型很类似，它也只存一个堆上的地址，所以这些类型在初始化时候为null，而其他类型会报错，同时String可以new出来。 123456String s=null; //这样不会报错。int i=null; //这样会报错编译不通过。String k=new String("this is hill blog"); //String 是可以new出来的 k指向的值也是存在堆上面的Integer j=new Integer(1); //int 是不能这样new 的但是int的包装类Integer可以。j指向的对象也是存在堆上面的String o="hello hill"; //这个字符串是存在字符串常量池中的。o指向的值也是存在堆上面的int p=1； //这个p是存在栈上的，一般情况 强引用，软引用，弱引用，虚引用，ReferenceQueue。在JDK1.2以后，java对引用的概念进行的扩充，将引用分为强引用(Strong Reference)，软引用(Soft Reference)，弱引用(Weak Reference)，虚引用(Phantom Reference)。这四种，引用强度分别减弱。肯定有人会问搞这么多东西干嘛，一种难道不够用吗。这些引用为垃圾回收提供了灵活的方式，我知道JVM垃圾回收不是通过引用技术的方式，而是通过可达性算法来实现，也就是这个对象有没有被引用。就会被定义为垃圾然后把他回收掉，但是有虚引用和弱引用，就可以在回收的时候不用计算一遍，减少Stop-The-World的时间，可以直接判断为垃圾或者回收掉。 强引用：强引用就是代码中普遍存在的引用例如Object obj=new Object(); 这类的引用。这里的obj是强引用。只要强引用还存在，垃圾回收器就不会回收该对象。当obj=null;的时候强引用的值消失，也就是该对象不可达。没有任何引用和可以操作该对象，表示该引用可以被回收。有时候强引用会显得“过强”，比如实现一个图像缓存，缓存中保存了对图像的引用，当图像不再使用时，如果缓存中还保存了对该图像的强引用，图像就不会被垃圾回收，需要手动断开缓存中的引用。 软引用：用来描述一些还有用但是非必需的对象。对于软引用关联着的对象，只有在内存不足的时候JVM才会回收该对象。因此，这一点可以很好地用来解决OOM的问题，并且这个特性很适合用来实现缓存：比如网页缓存、图片缓存等。 弱引用：弱引用来描述非必需的对象，他的强度比软引用还要低。被弱引用关联的对象会在下一次GC的时候回收掉，无论当前内存是否充足，他的生命周期就是一个GC周期。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用对象的存在不会阻止它所指向的对象变被垃圾回收器回收。弱引用最常见的用途是实现规范映射(canonicalizing mappings，比如哈希表（WeakHashMap）。假设垃圾收集器在某个时间点决定一个对象是弱可达的(weakly reachable)（也就是说当前指向它的全都是弱引用），这时垃圾收集器会清除所有指向该对象的弱引用，然后垃圾收集器会把这个弱可达对象标记为可终结(finalizable)的，这样它们随后就会被回收。与此同时或稍后，垃圾收集器会把那些刚清除的弱引用放入创建弱引用对象时所登记到的引用队列(Reference Queue)中。 虚引用：又称为幽灵引用或幻影引用，虚引用既不会影响对象的生命周期，也无法通过虚引用来获取对象实例，仅用于在发生GC时接收一个系统通知。无法通过虚引用来获取对象。虚引用只能和ReferenceQueue一起使用。 虚引用：一个对象是都有虚引用的存在都不会对生存时间都构成影响，也无法通过虚引用来获取对一个对象的真实引用。唯一的用处：能在对象被GC时收到系统通知，JAVA中用PhantomReference来实现虚引用。PhantomReferenc的get()始终返回null，无法通过虚引用来获取对象。虚引用只能和ReferenceQueue一起使用。 ReferenceQueue：翻译过来就是引用队列。垃圾回收器可以在对象的可及性发生特定的改变时，把对象的引用加入到ReferenceQueue，可以记录被回收对象的引用。如果在WeakReference的构造器中指定一个ReferenceQueue，那么当该WeakReference(弱引用也包含软引用)指向的对象变为垃圾时，该对象就会被自动加入到所指定ReferenceQueue中，之后就可以通过这个ReferenceQueue来为死引用（Dead Reference）进行清理工作。 java各个分区内存储的内容我之前的博客有写可以去看一下java运行时内存模型，里面大致的讲了一下上面说的那5个区域都存的什么，不过JDK8版本后，把方法区改成了MetaData区（元数据区）一般MetaData和Native都属于非堆内存。堆内存指的是Survivor0，Survivor1，Eden，Old总和。在一点就是Java中不是所有的对象都会分配在堆上的，也有对象被分配到栈上。 逃逸分析 逃逸分析的基本行为就是分析对象动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，称为方法逃逸。甚至还有可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。（每一个方法都是一个栈帧，如果对象只在这个栈帧内没有被外部的的方法引用，说明他没有逃逸) 123456789101112public class EscapeTest &#123; public static Object obj; public void globalVariableEscape() &#123; // 给全局变量赋值，发生逃逸 obj = new Object(); &#125; public Object methodEscape() &#123; // 方法返回值，发生逃逸 return new Object(); &#125; public void instanceEscape() &#123; // 实例引用发生逃逸 test(this); &#125;&#125; 栈上分配 我们都知道Java中的对象都是在堆上分配的，而垃圾回收机制会回收堆中不再使用的对象，但是筛选可回收对象，回收对象还有整理内存都需要消耗时间。如果能够通过逃逸分析确定某些对象不会逃出方法之外，那就可以让这个对象在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。 在一般应用中，如果不会逃逸的局部对象所占的比例很大，如果能使用栈上分配，那大量的对象就会随着方法的结束而自动销毁了。 同步消除 线程同步本身比较耗，如果确定一个对象不会逃逸出线程，无法被其它线程访问到，那该对象的读写就不会存在竞争，对这个变量的同步措施就可以消除掉。单线程中是没有锁竞争。（锁和锁块内的对象不会逃逸出线程就可以把这个同步块取消） 标量替换Java虚拟机中的原始数据类型（int，long等数值类型以及reference类型等）都不能再进一步分解，它们就可以称为标量。相对的，如果一个数据可以继续分解，那它称为聚合量，Java中最典型的聚合量是对象。如果逃逸分析证明一个对象不会被外部访问，并且这个对象是可分解的，那程序真正执行的时候将可能不创建这个对象，而改为直接创建它的若干个被这个方法使用到的成员变量来代替。拆散后的变量便可以被单独分析与优化，可以各自分别在栈帧或寄存器上分配空间，原本的对象就无需整体分配空间了。 不过上面都属于java后期的编译优化，和垃圾回收没什么太多关系，扯远了 垃圾回收涉及到的算法什么是垃圾垃圾就是不使用的一块内存空间。我们知道现在的计算机是源于冯诺依曼机。把计算机分为五部分，分别为运算器，控制器，存储器，输入设备，输出设备。而内存，硬，高速缓存和寄存器盘都算是存储器（这里面主要说的是内存而不是其他的存储器）。内存主要存储一些从硬盘或这输出输出设备传输过来的临时数据。当这些数据使用完了之后应该被清除，而不是一直占用内存空间，所以清除内存中不在使用的空间叫做垃圾回收。 垃圾的确认，上面是说垃圾是一块不在使用的内存，那么什么垃圾我们该如何确认？这里要说两种算法一种是引用计数算法，另一种是可达性分析算法。 垃圾的判定引用计数算法：给对象添加一个引用计数器，每当有一个地方引用它时，计数器加1，当引用失效时就减1；任何时刻计数器为0的对象是不能在使用(也就是没有一个引用可以把堆内中的对象找到，或者是使用，这样这个对象就是一个死对象)。也就是内存中的垃圾。但是主流的JVM中没有使用引用算法来管理内存，主要原因是就是它很难解决对象之间相互循环引用的问题。 可达性算法：现在主流的JVM上使用的是可达性分析算法；可达性算法的基本思路就是通过很多“GC_ROOT”的对象作为起点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC_ROOT 没有任何引用链时，就说明对象是不可达的，没有一个引用可以找到这个对象，该对象就是死对象也就是可以被回收。 GC_ROOT的对象可以包括以下几种，1、虚拟机栈(栈帧中的本地变量表)中引用的对象，一般就是一个方法中的对象（一个栈帧就是一个方法,在递归的时候一个方法调用多次，也是多个栈帧）；2、方法区中类静态属性引用的对象(一般静态对象和类信息一起都是存在方法区里)；3、方法区常量引用的对象(存在常量池中，或者和类信息存储一起)；4、本地方法栈JNI(java native interface)引用的对象。 垃圾回收的安全点（stop-the-world，并发收集，几种gc收集器） 上面说道一般会通过可达性算法来判定那些对象是否被回收，那HotSpot 虚拟机通过 GC Roots 枚举判定待回收的对象，通过安全点和安全区域确定 GC 的触发点，最后通过各种不同的回收算法完成垃圾回收。 GC Roots 枚举最大的困难点在于：检查范围比较大，并且必须在内存快照中进行，保证一致性，而且时间要求比较敏感。 在生产环境中，即使不考虑其它部分内存，仅仅 Java 堆内存就可达几百兆甚至上G，在此范围内完成 GC Roots 确定是一件很困难的事情；同时，在进行 GC Roots 枚举时，必须保证一致性，即所有正在运行的程序必须停顿（这种停顿就是stop-the-world，一般这种停顿会导致jvm性能下降，生成所谓的gc抖动），不能出现正在枚举 GC Roots，而程序还在跑的情况，这会导致 GC Roots 不断变化，产生数据不一致导致统计不准确的情况；最后，由于所有工作线程必须停顿以完成 GC 过程，在大并发高访问量情况下，这个时间必须非常短。（一般GCRoot枚举就是垃圾回收中标记的过程，他会把能用的都对象都存储到相关的OopMap中） HotSpot 采用了一种 “准确式 GC” 的技术；该技术主要功能就是让虚拟机可以准确的知道内存中某个位置的数据类型是什么；比如某个内存位置到底是一个整型的变量，还是对某个对象的 reference；这样在进行 GC Roots 枚举时，只需要枚举 reference 类型的即可。在能够准确地确定 Java 堆和方法区等 reference 准确位置之后，HotSpot 就能极大地缩短 GC Roots 枚举时间。然后他引用了OopMap这个数据结构。 OopMap：记录对象引用关系的一个数据结构，它主要是用来查找GC Roots节点的，在 HotSpot 的 JIT 编译过程中，同样会插入相关指令来标明哪些位置存放的是对象引用，或者一些对象被创建和或者移动的时候，就会更新OopMap。这样在 GC 发生时，HotSpot 就可以直接扫描 OopMap 来获取引用对应堆上的信息，进行 GC Roots 枚举。 Safepoint：有了OopMap之后，如果为每一条指令都生成对应的 OopMap，那么将需要大量的额外空间，这样对导致 GC 成本很高，所以 HotSpot 只在 “特定位置” 记录这些信息，这些位置被称为 安全点(Safepoint)。一般进入安全点后就不会产生新的引用和对象。SafePoint保存了线程上下文中的任何东西，包括对象，指向对象或非对象的内部指针。 在JVM处于SafePoint时，所有在执行代码的Java线程将会被暂停。不与JVM交互的运行Native Code的能继续执行（如果需要通过JNI访问Java 对象，调用JAVA方法，从Native回到JAVA的话，则必须等到Safepoint结束。 一般进入SafePoint会在下面几种情况：1、垃圾收集。2、代码优化（JIT优化）。3、刷新代码缓存。4、类的重新定义（热部署）。5、各种调试工作（死锁检查，堆栈跟踪转储 Stack trace dump） 从线程状态的角度看，Waiting/Idle/Blocked/Running native code是处于SafePoint的，Running Java code是处在非SafePoint的状态。处于Safepoint时，Heap不能访问，Java代码不能执行。当全部Java线程都处于SafePoint状态时，JVM处于全局SafePoint,可用于执行：GC, 优化，Stack trace dump,锁偏向，类重定义等。我们的以下行为会导致进入SafePoint: 新生代耗尽，大对象分配导致的老年代耗尽，进入同步块等。 SafeRegion：安全区是指一段代码之中引用关系不发生变化，在这个区域中任何时候gc都是安全的。也就是在这段代码执行时候，不会产生浮动垃圾。 垃圾回收的几种算法一般垃圾回收有三种收集方法，复制算法，标记-整理算法，标记-清除算法。垃圾回收可以防止内存泄漏（也不是绝对的），让程序能有充足的使用和分配对象的空间，避免OOM（out of Memory）异常。 标记清除算法(Mark-Sweep)：他是最基础收集算法。算法分两个阶段，标记和清除。首先要标记出来要统一回收的对象。也就是上面提到的可达性算法中不可达的对象，然后把这些对象进行标记。这种算法标记和清除的。效率都不高；同时标记清除后会产生大量不连续的内存碎片，空间碎片太多导致大对象分配内存时无法分配内存(一段连续的内存)，可能导致触发又一次GC(Garbage collection) 。 复制算法：它将可用的内存容量划分为大小不等的两块，每次只能使用其中的一块，当这一块内存用完了，就将还存活的对象复制到另外的一块内存，然后再把已经使用过的内存一次性清理掉。这样使得每次都对整个半区进行内存回收，内存分配的时候也不用考虑到内存碎片等复杂情况，只要移动堆顶指针，按照顺序分配内存即可，实现简单，运行高效。这种算法的待见就是将原来使用的内存大小缩小到一般。但是JVM实现Eden的垃圾回收的时候使用了这种算法，比例是8:1:1。Eden是8，survivor1和 survivor0都是1。每次使用的时候是8+1，这样相当于只使用10%的用于复制对象信息，这样既保证的效率又保证了空间的利用率。 标记整理算法(Mark-Compact)：复制算法在随着存活对象增加的时候，效率也会变低，更关键的是如果不想浪费50%的空间，就要在内存中所有对象都是100%存活的情况下，分配额外的内存空间，所以老年代是不能使用这种垃圾回收算法，所以有人提出来标记-整理算法，标记过程和标记清除算法一样，但后续的步骤不是对可回收的对象进行清理，而是让所有对象都向一段移动，然后直接对回收对象清理掉端已外的内存。 内存碎片化：碎片化是一个常常被谈到的问题，那什么是碎片化呢？碎片化是之存储器把好多小的数据或文件不连续的存储在内存或硬盘上，空闲页面趋向于散落在不连续的空间，很难再有足够长的连续物理内存页面分配。导致以后要分配连续的内存空间时却没有足够的空间，这样会导致内存或硬盘空间明明够大但是却没有连续的一块足够大空闲部分。 效率：复制算法&gt;标记/整理算法&gt;标记/清除算法（此处的效率只是简单的对比时间复杂度，实际情况不一定如此）。 内存整齐度：复制算法=标记/整理算法&gt;标记/清除算法。 内存利用率：标记/整理算法=标记/清除算法&gt;复制算法。 垃圾的分代收集垃圾回收也是要分类的，不一样额垃圾不一样处理。 商业虚拟机一般都是使用分代收集算法。根据对象存活的周期，将Java的堆内存划分为新生代，老年代和持久代（1.8是MetaData Space）这样就可以根据各个年代的特点采用适当的收集算法。在新生代每次垃圾收集时都会发现大批量的对象死亡（不可达，新生代对象一般都是朝生夕死），只有少量存活，那就使用复制算法只需要付出少量存活对象的复制成本就可以完成收集。而老年代的对象存活率比较高，没有额外的空间分配担保，所以必须使用标记清除或者标记整理算法进行垃圾回收。 新生代 1、所用新创建的对象，都首先放在新生代中。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 2、新生代一般被8:1:1的被分配，Eden是8，survivor1和 survivor0都是1。大部分对象在Eden（伊甸园）生成，回收时将一部分Eden中的存活的对象，放在survivor0区，然后清空Eden区，当这个survivor0被填满的时候，虚拟机会把survivor0和Eden区中的活对象复制到survivor1中，在把survival0和Eden中的数据清空，这时survivor0是空的。虚拟机就是通过这种方式将survivor0和survivor1中的数据进行来回交换，总有一个是survivor是空的。 3、当survival0存放不下survival1和Eden的对象就会存放到老年代区，如果老年代存放不下，那么就触发一次fullGC。一般虚拟级会进行判断，默认在survival中年龄大于16（默认）就会移到老年代，或者是大对象直接进入老年代。 4.新生代发生的GC也叫做Minor GC，MinorGC发生频率比较高(不一定等Eden区满了才触发) 老年代 1、存放一些生命周期比较长的对象，一般都在新生代经过了多次垃圾收集，或者是一个很大的对象。 2、一般老年代发生的GC是major gc也是Full GC，一般这样的情况比较少，一般Full GC也会触发minor GC，一般在Full GC的情况下，JVM的吞吐量会下降。老年代的对象一般生命周期长，标记存活率高，同时老年代的空间也会比新生代要打，一般是1:2左右。 持久代 一般也成永久代，一般GC很少回收这部分的数据，一般都是方法区。一般存放静态信息，Class信息和方法信息。一般在类加载的时候，会把整个属于这个类的信息，加载到方法区。在这个类使用完之后被GC时，一般会触发这个类的卸载，也就从方法区清除这个类相关信息。 minor gc 、major gc、full gc肯定有人说，这三个长的这么像都什么意思。这三个gc就是上面分代gc的一种表现形式。老外很聪明把内存分成几部分，(也就是老年代，新生代，持久代)，然后对不同的对象做不一样的处理，也就是分而治之。分别用不同的收集算法去实现，而不是一股脑的把垃圾都回收。上面也都是说了三种收集算法，其实也就是对应这三种不同gc。各有优点，处理不同的分代和不同程度情况下的垃圾回收。 minor gc：就是年轻代gc，也可以说是小型gc，年轻代一般都是朝生夕死的对象（说白了就是活不长的对象，也就是被一次使用，或者几次使用，完成使命就进入垃圾堆了）所以这种垃圾收集比较频繁，要求内存整齐度和效率比较高，使用的是复制算法，但是有不能一半一半的复制，所以找了survivor0和survivor1交换复制来实现复制算法，提高内存的利用率。 major gc：就是老年代gc（大型gc），老年代的上的对象生命周期一半都比较长，比如线程池对象，一些单例的对象，或者是大对象。一般都会伴随minor gc，因为jvm一般都是引用可达性算法，所以老年代的对象可能与新生代的对象存在引用关系，但是新生代对象又很多，所以要在新生代先minor gc一次（也不定每次都要minor gc），清除大多数无用对象，这样与下major gc分析引用关系会省一些时间。然后在开始major gc分析引用标记对象，（分析引用与标记对象是一起操作，尽管说此时可能是多线程的并发的，但是在安全区或者安全点中还是一个stop-the-world的状态）一般在老年代，垃圾回收器都会多次标记垃圾。所以老年代的回收时间会比较长，一般是新生代的10倍左右。一般老年代常用的就是CMS（标记清除）和G1（标记整理） Full gc：full gc是整个jvm的内存空间中所有的垃圾都会被回收掉。也就是老年代，持久代，新生代的垃圾都会被干掉，然后重新分配空间，这里面一般都使用的是标记整理，这个时间就更长，而且full gc停顿的时间也更长。所以一般都避免full gc。 JVM里一个对象是怎么从对象变成垃圾的（垃圾回收的整个过程）首先JVM创建对象在新生代，新生代中的对象被使用，当又有大量新对象进入的新代，新生代没有足够空间分配空间开始minor gc，开始标记对象，然后将可用（存活，被标记）的对象复制到survivor0或者survivor1中进行。然后jvm清空所有的新生代空间（Eden），这个时候会有一个判断即如果对象过大，或者在survival区域中待的比较久的对象就直接进入到老年代。也也就是minor gc，一般新生代的垃圾回收器有（g1、ParNew 多线程，Serial单线程，Parallel Scavenge 并行收集器-&gt;吞吐量优先收集器。同时它和CMS无法配合使用）。新生代不停的gc（因为很多对象类加载进来，创建对象被使用，程序要跑下去）。很多长时间对象和大对象就会填满老年代，当老年代没有足够的空间去存放新来的对象，他就把之前存进来的对象，进行分析标记看那些对象已经变成垃圾（可达性算法），由于是可达性算法，所以新生代也会被分析，看有没有对象和老年代关联，所以一般也都会触发minor gc；这种标记然后开始清除没有被标记的对象（垃圾）也就是major gc，major gc的垃圾回收器有（cms 、g1、Parallel old、serial old-&gt;一般当CMS内存不足的时候的备选项）。最后一种情况是full gc，full gc JVM里面没有可用的空间比如说老年代，或者方法区没有足够多内存去分配（比如cms 垃圾回收导致老年代碎片化严重，不能把新生代的对象放进去，或者方法区没有足够多的空间）都会引发full gc 。full gc一般会比较慢，调用的收集算法也是之前的算法。（一般长期存活和比较大的对象会直接进入老年代） 肯定有人会问，既然JVM已经有垃圾回收机制，但是为什么还会有OOM异常，首先JVM只是帮忙处理不用的对象，如果你的在JVM所有的对象都在用，同时有不能回收当然会报OOM了。同样GC也只能在安全区和安全点进行GC，在full gc完发现还是不够用，毕竟谁也不知道这个gc 释放的内存对于下次是否够用。如果你的机器频繁full gc 说明你离OOM已经不远了。 并行（Parallel）：指多条垃圾收集器并行（一起）工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集器线程同时执行，（不一定是并行，也有可能是交替进行 ），用户程序继续运行，而垃圾收集程序运行于另一个cup上。 垃圾回收优化的基本原则JVM 优化的三个性能指标：吞吐率，内存占用，延迟时间吞吐率：是指不考虑垃圾收集引起的停顿时间或内存消耗，垃圾收集器能支撑应用达到的最高性能指标。内存占用：衡量为了高效的运行，垃圾回收器需要的内存大小延迟时间：衡量垃圾回收器最小化甚至消灭由垃圾回收器引起的暂停时间和应用抖动的能力 3进2原则（类似于CAP）一项指标的提升，往往需要牺牲其他一项或者两项指标。换一句话说，一项指标的妥协通常是为了支持提升其他一项或者两项指标。然而，对于大多数应用来说，很少有3项指标都非常重要，通常，一项或者两项比其他的更重要。由于始终需要各种权衡，那么知道哪项指标对应用是最有必要的就显得非常重要。所以一般优化只优化其中的两个指标，而不是三个指标都要优化。 在优化JVM垃圾回收器的时候，有3项基本原则1、在minor垃圾回收器中，最大量的对象被回收，这个被称为Minor GC回收原则。秉承这个原则可以减少由应用产生的full垃圾回收数量和频率，Full垃圾回收往往需要更长的时间，以致于应用无法达到延迟和吞吐量的需求。2、更多的内存分配给垃圾回收器，也就是说更大的Java堆空间，垃圾回收器和应用在吞吐量和延迟上会表现得更好，这条原则被称为GC最大内存原则。3、优化JVM垃圾回收器的3个指标中的2个，这个被称为2/3 GC优化原则 常有的几种JVM配置和JVM的指令行（没有监控就，没办法调优，同样不要为调优而调优）jps（不是jsp，JVM Process Status Tool）虚拟机进程状态工具查看所有的jvm进程，包括进程ID，进程启动的路径等等。 jps -l 输出主类的全类名，如果进程是jar包的话，输出jar路径（ElasticSearch的LVMID 4365） jps-v输出虚拟机进程启动的JVM参数（这个可以看到好多参数,图中能看到jps的参数和ElasticSearch的JVM具体参数） jps-m输出虚拟机进程启动的时候，传给main函数的参数（图中能看到jps 的参数和ElasticSearch的启动参数-d表示后台启动） ​ jps-q只输出LVMID，不显示其他信息 jstat（JVM Statistics Monitoring Tools）虚拟机统计信息监控工具用于监控虚拟机各种运行时状态信息和命令行工具，他可以显示本地或者远程虚拟机进程中类加载、内垃圾回收、JIT编译等数据。一般都需要获取JVM进程，这一般就使用jps来获取。 jstat -gc lvmid监控Java堆状况，包括Eden区，两个survivor、老年代、永久代等容量、已用时间、GC时间合计等信息。 S0C （Survivor0 Capacity）Survivor0总容量； S0U （Survivor0 Use）Survivor0使用量；S1C （Survivor1 Capacity）Survivor1总容量；S1U （Survivor1 Use）Survivor1使用量； EC（Eden Capacity）伊甸园容量；EU（Eden Use）伊甸园使用量； OC（Old Capacity）老年代总容量；OU（Old Use）老年代使用量；MC（MetaData Capacity）MetaData总容量；MU（MetaData Use）；CCSC（Compress Class Space Capacity）压缩类空间大小； CCSU（Compress Class Space Use）压缩类空间大小使用；YGC（Young GC）新生代GC次数 ；YGCT（Young GC Time）新生代GC时间；FGC（Full GC）Full GC次数；FGCT（Full GC Time）Full GC时间。上面说的这些参数都是单位都是KB。其中Xmx=128M=131072KB；Xms=128M=131072KB。 ​ S0总容量4352.0KB；S1总容量4325.0KB。（S0，S1大小一样） S0使用量 69.1KB；S1使用量0.0KB，S0的使用量1.58%（说明现在S0在被使用，S1属于空闲状态） Eden区的总容量34944KB，Eden使用量21961.9KB，使用率62.84%（伊甸园大小为34944KB，大约是S0，S1的8倍，占总比26.66%。S0+S1+Eden=新生代占总比33.30%。也就三分之一 Old区的总容量87424.0KB，Old的使用量是65446.2KB，使用率74.86%。总占比66.99%也就是三分之二。 MetaData区总容量54868KB，使用量51210.9KB。使用率93.33% 压缩类空间8080KB，使用量6906.9%；使用率85.48%。 YGC 新生代GC次数 48，总耗时0.723s，FGC FullGC次数6，FullGC时间0.84s。可以看出来YGC一次平均时间 0.0156秒，FullGC平均时间0.14秒，所以可以看出来FullGC时间比Young gc差10倍作用。这里ElasticSearch运行时间不长，但是我们可以看出来GC很频繁，应该是堆分配比较小，所以频繁GC，要扩大堆的大小，提高效率。 jstat -gcutil lvmid监视内容与-gc基本相同，但是输出主要是Java堆各个区域使用最大最小空间。只不过他会把各个空间的使用百分比拿出来 S0的使用率0.74%,S1没有使用，Eden（E）使用率74.86%和我们上面差不多，Old（O）Old使用率74.86%，MetaData（M）使用率93.33%。CCS使用率85.47%。新生代时间是0.7秒，Full GC次数 6，FullGC花费时间0.117秒，GCT（GC总时间）0.817秒。 jstat -gcnew lvmid 监控新生代GC情况。 DSS（Desired survivor size）:当前需要survivor（幸存区）的容量 (KB)（Eden区已满）。 TT（Tenuring threshold.）： 持有次数限制（Survivor持有对象的次数）MTT （Max Tenuring threshold.）： 最大持有次数限制。（Survivor持有对象的最大次数） S0、S1总容量4325KB，S0使用量87.6KB，S1使用0。持有次数和最大持有次数为6，survivor的期望容量2176KB（也就是还有2176KB对象是存活的，需要进入下一次周期），Eden区的总量34944.0KB，使用22414.0KB；GC了34次，消耗时间0.727秒。 jstat -gcold lvmid：监控老年代GC情况。 MetaData总量54032.0KB，使用量50347.5KB，压缩类空间大小8004.0KB，使用6792.0KB，老年代大小87424KB，使用量65475.2KB。新生代GC36次，FullGC 6次时间是0.136秒，GC总时间0.875秒。 jstat -class lvmid显示相关进程的类加载情况 Loaded：已经加载的类个数；Bytes：已经加载类的大小；Unload：没有加载类的个数；Bytes：没有加载类的大小了；Time：加载这些类所花费的时间。 加载了10386个类，大小是18626.5B；未加载类25个，大小28.3B；耗时11.23秒 jstat -gcmetacapacity lvmid查看MetaDataSpace空间详情 MCMN（MetaData Capacity Min）：MetaData空间初始最小空间（KB）;MCMX（MetaData Capacity Max）：MetaData空间最大容量；CCSMN（Compress Class Space Min）：压缩类空间最小为容量；CCSMX（Compress Class Space Max）压缩类空间最大容量； MetaData空间最小为0KB，最大为1095680.0KB（1070M这一点有点懵逼，估计是通过参数设置，因为我的这个主机最大512M内存）MetaData容量是54032.0KB（52.76M）；压缩类空间最小为容量0KB，最大容量是1048576.0KB（1024M），压缩类空间大小8004.0KB。新生代GC 38次，FullGC 6次，FullGC时间0.136秒，GC总时间0.875秒 jstat -gccapacity lvmid与上面监控类似，但是主要输出java堆各个区域使用的最大最小空间 NGCMN（ New Generation Capacity Min）:新生代（Young）最小的容量；NGCMX（ New Generation Capacity Max）:新生代最大的容量；NGC（New Generation Capacity） 新生代容量；OGCMN（Old Generation Capacity Min）：老年代带最小容量；OGCMX （Old Generation Capacity Max）：老年代最大容量； 新生代最小容量43648.0KB，最大容量43648.0KB；新生代容量4352.0KB；S0容量4352.0KB；S1容量4352.0KB；Eden区大小34944.0KB；老年代最小容量87424.0KB，最大容量87424.0KB老年代容量87424.0KB；MetaData最小容量0，最大容量1095680.0KB，MetaData容量54032.0KB；压缩类空间最小为容量0KB，最大容量是1048576.0KB（1024M），压缩类空间大小8004.0KB。新生代GC60次，FullGC 6次。 jstat -gccause lvmid与-gcutil 功能一样，但是会额外输出导致上一次GC产生的原因. LGCC（Last GC Cause）：上一次GC原因；GCC （GC Cause）：当前GC原因。 S0使用量0.0%，S1使用量106%，Eden区使用量74.04%，老年代使用量74.92%，MetaData使用量93.19%，CSS使用量84.88%，新生代GC次数61，新生代GC时间0.862秒，FullGC次数6，FullGC时间0.136秒，GC总时间0.999秒。上次GC原因 Allocation Failure（分配空间失败），当前没有GC jstat -gc/gcutil/gcold... lvmid 200 10 使用 jstat -options 每200毫秒，20次。 jinfo （Configuration info java）显示Java配置信息。注意在Linux里使用jinfo查看相关JVM的信息，要切换到启动JVM进程的用户要不然你就会收到（Unable to open socket file: target process not responding or HotSpot VM not loaded）。因为JVM的相关信息是存储在一个文件里，而在linux下面文件是隔离的。虚拟机具体参数表示-XX:+&lt;option&gt; 开启option 参数 例如 -XX:+PrintGCDetails 表示打印详细GC日志开启，相反的-XX:-&lt;option&gt; 关闭option参数 -XX:-UseParallelOldGC 不使用Parallel Old回收老年代和Parallel Scavenger回收新生代，-XX:&lt;option&gt;=&lt;value&gt; 将option参数的值设置为value例如 -XX:GCTimeRatio=99 即GC时间占总时间的比率1%。 jinfo -flag PrintGCDetails lvmid 查看打印详细GC日志 能看出来这个JVM并没有打印详细GC日志。在一般只有调试的时候打开，默认是关闭的。 jinfo -flag UseTLAB lvmid 优先使用本地线程缓存区分配对象，避免分配内存时的锁定过程。这个可以结合JMM，volatile去分析一下。 能看出来这个UserTALB这个参数已经生效 jinfo -flag GCTimeRatio lvmid GC时间占总时间的比率，默认值99，即允许1%的GC时间，仅在Parallel Scavenger 为回收器时生效。 可以看出来GCTimeRatio参数的值是99 jinfo -flag [+|-]&lt; name &gt;：设置或取消指定java虚拟机参数的布尔值。 开启打印详细GC日志。 关闭打印详细GC日志，当然不是什么参数都可以在这开启或者打开，一般都是要配置到配置文件里，然后让JVM重启才会生效，一般只有一些调试参数可以通过这方式开启。我也试过一些，但是好多都不成功 尝试设置GCTimeRatio的值，失败了。 关闭 UseTLAB失败 jinfo -flags lvmid显示这个JVM相关参数 1234567[es@host root]$ jinfo -flags 1655Attaching to process ID 1655, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11Non-default VM flags: -XX:+AlwaysPreTouch -XX:CICompilerCount=2 -XX:CMSInitiatingOccupancyFraction=75 -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=134217728 -XX:MaxHeapSize=134217728 -XX:MaxNewSize=44695552 -XX:MaxTenuringThreshold=6 -XX:MinHeapDeltaBytes=196608 -XX:NewSize=44695552 -XX:OldPLABSize=16 -XX:OldSize=89522176 -XX:-PrintGCDetails -XX:ThreadStackSize=1024 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC Command line: -Xms128m -Xmx128m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -Djdk.io.permissionsUseCanonicalPath=true -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Dlog4j.skipJansi=true -XX:+HeapDumpOnOutOfMemoryError -Des.path.home=/es/elasticsearch-5.5.1 jinfo -sysprops lvmid显示java系统的所欲配置参数，一般都能通过system.getproperty()能获取到的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475es@host root]$ jinfo -sysprops 1655Attaching to process ID 1655, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11jna.platform.library.path = /usr/lib64:/lib64:/usr/lib:/lib:/lib/i686/nosegneg:/usr/lib64/mysqljava.runtime.name = Java(TM) SE Runtime Environmentsun.boot.library.path = /java/jdk1.8.0_171/jre/lib/amd64java.vm.version = 25.171-b11es.path.home = /es/elasticsearch-5.5.1log4j.shutdownHookEnabled = falsejava.vm.vendor = Oracle Corporationjava.vendor.url = http://java.oracle.com/path.separator = :jna.loaded = truefile.encoding.pkg = sun.iojava.vm.name = Java HotSpot(TM) 64-Bit Server VMsun.java.launcher = SUN_STANDARDuser.country = USsun.os.patch.level = unknownjna.nosys = truejava.vm.specification.name = Java Virtual Machine Specificationuser.dir = /es/elasticsearch-5.5.1/binjava.runtime.version = 1.8.0_171-b11java.awt.graphicsenv = sun.awt.X11GraphicsEnvironmentjava.endorsed.dirs = /java/jdk1.8.0_171/jre/lib/endorsedos.arch = amd64java.io.tmpdir = /tmpline.separator = java.vm.specification.vendor = Oracle Corporationos.name = Linuxjdk.io.permissionsUseCanonicalPath = trueio.netty.noKeySetOptimization = truesun.jnu.encoding = UTF-8jnidispatch.path = /tmp/jna-3246/jna4123425316020679580.tmpjava.library.path = /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/libsun.nio.ch.bugLevel = es.logs.cluster_name = elasticsearchjava.specification.name = Java Platform API Specificationjava.class.version = 52.0sun.management.compiler = HotSpot 64-Bit Tiered Compilersos.version = 4.15.7-1.el7.elrepo.x86_64user.home = /home/esuser.timezone = Asia/Shanghaijava.awt.printerjob = sun.print.PSPrinterJobfile.encoding = UTF-8java.specification.version = 1.8es.logger.prefix = io.netty.recycler.maxCapacityPerThread = 0user.name = eses.logs.base_path = /es/elasticsearch-5.5.1/logsjava.class.path = /es/elasticsearch-5.5.1/lib/elasticsearch-5.5.1.jar:/es/elasticsearch-5.5.1/lib/lucene-highlighter-6.6.0.jar:/es/elasticsearch-5.5.1/lib/snakeyaml-1.15.jar:/es/elasticsearch-5.5.1/lib/jackson-dataformat-smile-2.8.6.jar:/es/elasticsearch-5.5.1/lib/lucene-grouping-6.6.0.jar:/es/elasticsearch-5.5.1/lib/lucene-sandbox-6.6.0.jar:/es/elasticsearch-5.5.1/lib/log4j-1.2-api-2.8.2.jar:/es/elasticsearch-5.5.1/lib/lucene-spatial3d-6.6.0.jar:/es/elasticsearch-5.5.1/lib/lucene-analyzers-common-6.6.0.jar:/es/elasticsearch-5.5.1/lib/lucene-misc-6.6.0.jar:/es/elasticsearch-5.5.1/lib/lucene-backward-codecs-6.6.0.jar:/es/elasticsearch-5.5.1/lib/lucene-queryparser-6.6.0.jar:/es/elasticsearch-5.5.1/lib/jackson-dataformat-cbor-2.8.6.jar:/es/elasticsearch-5.5.1/lib/t-digest-3.0.jar:/es/elasticsearch-5.5.1/lib/lucene-core-6.6.0.jar:/es/elasticsearch-5.5.1/lib/spatial4j-0.6.jar:/es/elasticsearch-5.5.1/lib/lucene-memory-6.6.0.jar:/es/elasticsearch-5.5.1/lib/log4j-core-2.8.2.jar:/es/elasticsearch-5.5.1/lib/hppc-0.7.1.jar:/es/elasticsearch-5.5.1/lib/lucene-suggest-6.6.0.jar:/es/elasticsearch-5.5.1/lib/lucene-spatial-extras-6.6.0.jar:/es/elasticsearch-5.5.1/lib/lucene-join-6.6.0.jar:/es/elasticsearch-5.5.1/lib/java-version-checker-5.5.1.jar:/es/elasticsearch-5.5.1/lib/jackson-dataformat-yaml-2.8.6.jar:/es/elasticsearch-5.5.1/lib/lucene-spatial-6.6.0.jar:/es/elasticsearch-5.5.1/lib/jackson-core-2.8.6.jar:/es/elasticsearch-5.5.1/lib/HdrHistogram-2.1.9.jar:/es/elasticsearch-5.5.1/lib/plugin-cli-5.5.1.jar:/es/elasticsearch-5.5.1/lib/log4j-api-2.8.2.jar:/es/elasticsearch-5.5.1/lib/lucene-queries-6.6.0.jar:/es/elasticsearch-5.5.1/lib/securesm-1.1.jar:/es/elasticsearch-5.5.1/lib/jopt-simple-5.0.2.jar:/es/elasticsearch-5.5.1/lib/jna-4.4.0.jar:/es/elasticsearch-5.5.1/lib/joda-time-2.9.5.jar:/es/elasticsearch-5.5.1/lib/jts-1.13.jares.logs = /es/elasticsearch-5.5.1/logs/elasticsearchlog4j.skipJansi = truejava.vm.specification.version = 1.8sun.arch.data.model = 64java.home = /java/jdk1.8.0_171/jresun.java.command = org.elasticsearch.bootstrap.Elasticsearch -duser.language = enjava.specification.vendor = Oracle Corporationio.netty.noUnsafe = trueawt.toolkit = sun.awt.X11.XToolkitjava.vm.info = mixed modejava.version = 1.8.0_171java.ext.dirs = /java/jdk1.8.0_171/jre/lib/ext:/usr/java/packages/lib/extsun.boot.class.path = /java/jdk1.8.0_171/jre/lib/resources.jar:/java/jdk1.8.0_171/jre/lib/rt.jar:/java/jdk1.8.0_171/jre/lib/sunrsasign.jar:/java/jdk1.8.0_171/jre/lib/jsse.jar:/java/jdk1.8.0_171/jre/lib/jce.jar:/java/jdk1.8.0_171/jre/lib/charsets.jar:/java/jdk1.8.0_171/jre/lib/jfr.jar:/java/jdk1.8.0_171/jre/classesjava.vendor = Oracle Corporationjava.awt.headless = truefile.separator = /java.vendor.url.bug = http://bugreport.sun.com/bugreport/sun.io.unicode.encoding = UnicodeLittlesun.cpu.endian = littlelog4j2.disable.jmx = truesun.cpu.isalist = jmap（Memory Map for Java）命令用于生成堆转存储快照(dump文件)。还可以用一些比较暴力的手段，比如通过-XX:+HeapDumpOnOutOfMemoryError参数，可以在虚拟机OOM之后自动生成dump文件，也可以通过-XX:+HeapDumpOnCtrlBreak参数使用Ctrl+Break键让虚拟机生成dump文件。 jmap -heap lvmid 显示java堆的详细信息，如使用那种回收器，参数配置，分代情况等等，只有在linux和solaris平台有效，windows10也可以，别的我没试过。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[es@host root]$ jmap -heap 1655Attaching to process ID 1655, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11using parallel threads in the new generation.using thread-local object allocation.Concurrent Mark-Sweep GCHeap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 134217728 (128.0MB) NewSize = 44695552 (42.625MB) MaxNewSize = 44695552 (42.625MB) OldSize = 89522176 (85.375MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB)Heap Usage:New Generation (Eden + 1 Survivor Space): capacity = 40239104 (38.375MB) used = 31512760 (30.05290985107422MB) free = 8726344 (8.322090148925781MB) 78.31377159889047% usedEden Space: capacity = 35782656 (34.125MB) used = 31464952 (30.00731658935547MB) free = 4317704 (4.117683410644531MB) 87.93352846697573% usedFrom Space: capacity = 4456448 (4.25MB) used = 47808 (0.04559326171875MB) free = 4408640 (4.20440673828125MB) 1.0727826286764706% usedTo Space: capacity = 4456448 (4.25MB) used = 0 (0.0MB) free = 4456448 (4.25MB) 0.0% usedconcurrent mark-sweep generation: capacity = 89522176 (85.375MB) used = 67081200 (63.97361755371094MB) free = 22440976 (21.401382446289062MB) 74.93249493846083% used15096 interned Strings occupying 2342736 bytes. ElasticSearch的JVM的堆参数，这是在Linux上的，JVM的新生代使用Parallel New收集器，老年代Concurrent Mark-Sweep GC收集器和一些其他信息如各个分区的大小和使用情况，这里就不一一列举了。这里的S0和S1变成了fromSpace和toSpace，这里他把新生代划分是S0或者S1+Eden。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051C:\Users\qjq&gt;jmap -heap 18480Attaching to process ID 18480, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.121-b13using thread-local object allocation.Garbage-First (G1) GC with 8 thread(s)Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 1073741824 (1024.0MB) NewSize = 1363144 (1.2999954223632812MB) MaxNewSize = 643825664 (614.0MB) OldSize = 5452592 (5.1999969482421875MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 1048576 (1.0MB)Heap Usage:G1 Heap: regions = 1024 capacity = 1073741824 (1024.0MB) used = 187700456 (179.0051040649414MB) free = 886041368 (844.9948959350586MB) 17.480967193841934% usedG1 Young Generation:Eden Space: regions = 55 capacity = 106954752 (102.0MB) used = 57671680 (55.0MB) free = 49283072 (47.0MB) 53.92156862745098% usedSurvivor Space: regions = 7 capacity = 7340032 (7.0MB) used = 7340032 (7.0MB) free = 0 (0.0MB) 100.0% usedG1 Old Generation: regions = 118 capacity = 154140672 (147.0MB) used = 121640168 (116.0051040649414MB) free = 32500504 (30.994895935058594MB) 78.91503677887171% used58394 interned Strings occupying 6157416 bytes. 这个是window10下面，eclipse的JVM的的堆情况，从这里我们可以看出eclipse使用的是G1垃圾回收器，同样G1的垃圾回收，年轻代和老年代的划分和上面描述的CMS垃圾回收的分区是不一样的，G1使用更小的区域Regions来划分空间；Survivor区，只划分了7个regions是100%使用，而不是S1和S0，eden和Survivor大小大概是8:1。 12345678910111213141516171819202122232425C:\Users\qjq&gt;jmap -histo 18480 num #instances #bytes class name---------------------------------------------- 1: 283121 33384912 [C 2: 581380 18604160 java.util.HashMap$Node 3: 449913 14397216 org.eclipse.equinox.internal.p2.metadata.OSGiVersion 4: 326694 12343296 [Ljava.lang.Object; 5: 300441 12017640 java.util.LinkedHashMap$Entry 6: 99920 10036696 [Ljava.util.HashMap$Node; 7: 201877 8075080 org.eclipse.equinox.internal.p2.metadata.RequiredCapability 8: 92849 7621184 [I 9: 252250 6054000 java.lang.String 10: 80490 5896296 [B …………………… …………………… 8003: 1 16 sun.util.locale.provider.AuxLocaleProviderAdapter$NullProvider 8004: 1 16 sun.util.locale.provider.CalendarDataUtility$CalendarFieldValueNamesMapGetter 8005: 1 16 sun.util.locale.provider.CalendarDataUtility$CalendarWeekParameterGetter 8006: 1 16 sun.util.locale.provider.CalendarNameProviderImpl$LengthBasedComparator 8007: 1 16 sun.util.locale.provider.SPILocaleProviderAdapter 8008: 1 16 sun.util.locale.provider.TimeZoneNameUtility$TimeZoneNameGetter 8009: 1 16 sun.util.resources.LocaleData 8010: 1 16 sun.util.resources.LocaleData$LocaleDataResourceBundleControl Total 4672630 195589424 jmap -histo 18480显示堆中对象统计信息，包括类和实例数量、合计容量；这里面使用的是windows的操作命令，Linux也一样，这个是eclipse的JVM类加载多少个，第一个是序号，第二这个实例的数量，第三个是所占的字节大小，第四个是类的名称，可以看出来最先加载和创建应该是本地库的一些类和实例，然后是HashMap一般HashMap都会作为一些容器类使用，比如spring中的DefaultListableBeanFactory个类中的bean容器使用的是HashMap。最后还有一个汇总也就是有4672630个实例，占用195589424字节大小（186.528M） jmap -finalizerinfo 1655显示在F-Queue中等待Finalizer线程中执行finalizer方法对象。linux，window10都可以。 jmap -dump [live,] format=b,file=&lt;fileName&gt;生成Java堆转储快照，格式是bin，文件名是；其中子参数live表示说明是否只输出存活的对象。 当虚拟机进程对-dump选项没有响应时，可使用这个选项强制生成dump快照。 jhat（JVM Heap Analysis Tool）虚拟机堆转储快照分析工具一般经常与jmap一起使用来分析jmap生成的堆转储快照，jhat内置了一个HTTP/HTML的微型服务器可以在浏览器上查看。（一般来说不太会有jhat去分析dump文件，因为比较消耗资源），会使用VisualVM，Eclipse MemoryAnalyzer、IBM HeapAnalyzer等工具。（不过我没用过） 123456789101112131415161718C:\Users\qjq&gt;jps -l18480976 sun.tools.jps.JpsC:\Users\qjq&gt;jmap -dump:format=b,file=eclispse.bin 18480Dumping heap to C:\Users\qjq\eclispse.bin ...Heap dump file createdC:\Users\qjq&gt;jhat eclispse.binReading from eclispse.bin...Dump file created Mon Jul 16 23:00:41 CST 2018Snapshot read, resolving...Resolving 2640380 objects...Chasing references, expect 528 dots................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Eliminating duplicate references................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Snapshot resolved.Started HTTP server on port 7000Server is ready. 之后就可以访问http://127.0.0.1:7000 来查看dump文件 jstack（Stack Trace for Java）用于生成虚拟机当前时刻的线程快照线程快照就是当前虚拟机内每一条线程在执行的方法堆栈的集合，生成线程快照堆主要目的是定位线程出现长时间停顿的原有，如线程死锁，死循环，请求外部资源时间过长，都是导致线程长时间停顿的原因。注意JVM启动用户与执行jstack同一个用户 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879[es@host hsperfdata_es]$ jstack -l 16552018-07-16 23:38:48Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.171-b11 mixed mode):&quot;elasticsearch[w7p9LOx][http_server_worker][T#2]&quot; #49 daemon prio=5 os_prio=0 tid=0x00007f27e4003000 nid=0x1eee runnable [0x00007f27e067a000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0x00000000fde47568&gt; (a sun.nio.ch.Util$3) - locked &lt;0x00000000fde47550&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0x00000000fde84a80&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:752) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:408) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at java.lang.Thread.run(Thread.java:748) Locked ownable synchronizers: - None&quot;Attach Listener&quot; #48 daemon prio=9 os_prio=0 tid=0x00007f27dc381800 nid=0x14fe waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE Locked ownable synchronizers: - None&quot;elasticsearch[w7p9LOx][flush][T#1]&quot; #47 daemon prio=5 os_prio=0 tid=0x00007f27f8024800 nid=0x7e1 waiting on condition [0x00007f27da70c000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fb480148&gt; (a org.elasticsearch.common.util.concurrent.EsExecutors$ExecutorScalingQueue) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737) at java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647) at java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Locked ownable synchronizers: - None ………………………… …………………………&quot;Finalizer&quot; #3 daemon prio=8 os_prio=0 tid=0x00007f28140af000 nid=0x67e in Object.wait() [0x00007f2804422000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000000facba6f0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x00000000facba6f0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:212) Locked ownable synchronizers: - None&quot;Reference Handler&quot; #2 daemon prio=10 os_prio=0 tid=0x00007f28140aa800 nid=0x67d in Object.wait() [0x00007f2804523000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000000facb4b88&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x00000000facb4b88&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153) Locked ownable synchronizers: - None&quot;VM Thread&quot; os_prio=0 tid=0x00007f28140a3000 nid=0x67c runnable &quot;Gang worker#0 (Parallel GC Threads)&quot; os_prio=0 tid=0x00007f281401c000 nid=0x67a runnable &quot;Concurrent Mark-Sweep GC Thread&quot; os_prio=0 tid=0x00007f281403e800 nid=0x67b runnable &quot;VM Periodic Task Thread&quot; os_prio=0 tid=0x00007f28140f0800 nid=0x684 waiting on condition JNI global references: 6398 能看出来现在在堆栈里总共有48个线程，他们都排列顺序，这里我把部分的线程堆栈删除了，要不然太多了，我们能看出来这些线程大多数都是daemon线程，同时也能看出他们的优先级os_prio=0，由于是守护进程，所以系统优先级是0。我们能看出来有些线程是java的线程，有的是JVM线程比如CMS回收的线程（老年代垃圾回收，运行），有Parallel回收线程（年轻代垃圾回收，运行）， VM周期性任务线程（VM Periodic Task Thread，运行），VM线程（运行）。 我们分析具体一个线程，比如#2线程，也就是Reference Handler线程，我们看到线程状态状态是WAITING，它执行的本地方法（object.wait()方法）。os_prio线程系统的优先级。nid是JVM中线程唯一表的标识， tid：线程id，&lt;0x00000000facb4b88&gt;这个地址，是这个线程在这个地址等待，而且锁在这个地址。没有锁定可拥有的同步器：。0x00007f2804523000线程起始地址。JNI总共的引用个数6398个。（我们可以看出来四个JVM系统线程没有prio。思考一下？） 线程的各个状态： New: 当线程对象创建时存在的状态，此时线程不可能执行； Runnable：当调用thread.start()后，线程变成为Runnable状态。只要得到CPU，就可以执行； Running：线程正在执行； Waiting：执行thread.join()或在锁对象调用obj.wait()等情况就会进该状态，表明线程正处于等待某个资源或条件发生来唤醒自己； Timed_Waiting：执行Thread.sleep(long)、thread.join(long)或obj.wait(long)等就会进该状态，与Waiting的区别在于Timed_Waiting的等待有时间限制； Blocked：如果进入同步方法或同步代码块，没有获取到锁，则会进入该状态； Dead：线程执行完毕，或者抛出了未捕获的异常之后，会进入dead状态，表示该线程结束其次，对于jstack日志，我们要着重关注如下关键信息； Deadlock：表示有死锁； Waiting on condition：等待某个资源或条件发生来唤醒自己。具体需要结合jstacktrace来分析，比如线程正在sleep，网络读写繁忙而等待； Blocked：阻塞； Waiting on monitor entry：在等待获取锁； jstack -m lvmid如果调用本地方法，可以显示C/C++的堆栈，很长而且没看怎么懂就不贴出来了 jstack -F lvmid 当正常的请求不被响应时，强制输出堆栈信息。这里面的F（Force） 其他杂项 CCSU的由来 在Java8以前，有一个选项是UseCompressedOops。所谓OOPS是指“ordinary object pointers“，就是原始指针。Java Runtime可以用这个指针直接访问指针对应的内存，做相应的操作（比如发起GC时做copy and sweep）。64bit的JVM出现后，OOPS的尺寸也变成了64bit，比之前的大了一倍。这会引入性能损耗，占的内存double了，并且同尺寸的CPU Cache要少存一倍的OOPS。于是就有了UseCompressedOops这个选项。打开后，OOPS变成了32bit。但32bit的base是8，所以能引用的空间是32GB——这远大于目前经常给jvm进程内存分配的空间。一般建议不要给JVM太大的内存，因为堆（Heap）太大，GC停顿实在是太久了。很多开发者喜欢在大内存机器上开多个JVM进程，每个给最大8G以下的内存。从JDK6_u23开始UseCompressedOops被默认打开了。因此既能享受64bit带来的好处，又避免了64bit带来的性能损耗。如果你有机会使用超过32G的堆内存，记得把这个选项关了。到了Java8，永久代被干掉了，由了MetaDataSpace的概念，存储jvm中的元数据，包括byte code，class等信息。Java8在UseCompressedOops之外，额外增加了一个新选项叫做UseCompressedClassPointer。这个选项打开后，class信息中的指针也用32bit的Compressed版本。而这些指针指向的空间被称作Compressed Class Space。默认大小是1G，但可以通过CompressedClassSpaceSize调整。如果你的java程序引用了太多的包，有可能会造成这个空间不够用，于是会看到java.lang.OutOfMemoryError: Compressed class space这时，一般调大CompreseedClassSpaceSize就可以了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[胡扯]]></title>
    <url>%2F2018%2F05%2F05%2F%E8%83%A1%E6%89%AF%2F</url>
    <content type="text"><![CDATA[​ 最近总是看一些网上的文章，发现现在自媒体或者新媒体包括公众号，发现能写出来有质量的东西越来越少，不知道从何时起我看的文章，发现都是千篇一律的套路，一般就是前面的文章的题目很醒人，都是标题党。进入到文章内部发现都是比较干枯，没有什么可以注意的点，好多东西都是平白的描述。没有任何营养，感觉读完之后没有让人产生思考，完全是快餐式的那种阅读，很快的知道内容，但是并没有告诉你内容背后的含义，你写这篇文章要表明什么意思。另外一种就完全相反就是表达意思很明确上来就是很洗脑的东西。一味的去描述好多不现实的东西，让人感觉不真实。 ​ 读书，读一篇文章，读一个帖子。感觉最重要的是一种交流是读者与作者的一种交流，作者首先要把自己想表达的东西描述的清晰客观，而不是一味的去吹捧或者贬低某些东西，而且让人感觉不真实。同时就是作者要把自己的思想或者情感放进去，不能说每个人理解的都一样，但是至少看了以后不能让我感觉和没看一样。（确实有人会说，看文章一定要学到东西吗，那看文章是不是太功利了）但是我想说的是至少作者要和读者有些许共鸣，让读者能感受到作者是在创作，而不是把很多东西拼凑在一起，让人看着迷茫，不知道作者想说明什么意思，或者意图。语言和文字就是传递一种信息，让人了解或者学习知识，而不是仅仅是为了消遣。如果消遣那就是段子，而不是文章。而现在很多文章或者公众号就是在传递一直消费文章，或者他很强烈的向你推荐一种想法（消费主义）。类似于广告让你感觉没有了这种东西你就缺少什么，或者别人都这样你不这样就会很low，被时代所抛弃。 ​ 时事热点，每天都在变，但是我大家对热点都没有什么反思或者思考，就是大家都会之前魏则西事件，或者莆田系医院，红黄蓝幼儿园等等热点事件。这种事件出现之后就像一个石头打在一潭死水上，泛起了部分涟漪，之后水还是一潭死水，没有什么本质的变化，本质的变化可能就是我们看不到其他相关报道了。估计因为看不到，所以也就认为没有了，感觉这是种自我欺骗，然后我们就慢慢忘却了，我们每天看到信息，都是被过滤过滤在过滤的信息。通过算法，看到你能看到的信息，而不是你想看到的信息，或者是其他意外的信息。你看到是你应该看到的，而不是你想要看到的。 ​ 思考，是人类与其他动物区分开来，我们学会的思考，学会了使用工具，然后不断的进步，然后变成现在的人。所以思考是生存的一本能。但是现在整体的氛围，就是不用去思考，就是一种快餐文化。感觉总有一种东西在操控这整个氛围，而这种氛围并不是让我们去积极的思考，而是灌输给我们别人已经做好的环境。然后你渐渐的就被感染，同时也在传播，像病毒一样扩散，大家都懒得思考，渐渐的你我都麻木了。 ​ 算是最近一段是时间，天天在地铁上看帖子和文章的感受。看的越多发现整个人就越飘，想法越不切合实际。所以还是要脚踏实地的多看看好书，充实自己。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析Java ArrayList源码]]></title>
    <url>%2F2018%2F03%2F20%2F%E6%B5%85%E6%9E%90Java%20ArrayList%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[什么是ArrayListArray是数组，List是线性表两个合起来就是一个数组化的线性表。也就是ArrayList是一个数组实现的列表。所以它有List的很多方法，可以实现List的功能，区别与数组ArrayList是可以自动扩容的。ArrayList的默认大小是10。（这个我也很好奇，为什么不是2的n次方的这种形式，后面有一个解释），每次扩容的时候是1.5倍，也不是两倍。同样ArrayList也是线程不安全的，也是用fast-fail机制。如果使用线程安全的类使用Vector，它使用了锁的同步机制实现了线程安全。但是效率比较低。 ArrayList的继承关系图 ArrayList是如何实现的先看一波ArrayList的定义的变量，从定义的变量中我们能看到，ArrayList的底层是基于一个数组实现的，它的默认大小是10，同时她存放数据的对象是不支持序列化的。 常用的参数变量123456789101112131415161718192021 //ArrayList实现了序列化的Serializable接口，这个是用于序列化的版本号。 private static final long serialVersionUID = 8683452581122892189L; //默认的初始化大小 private static final int DEFAULT_CAPACITY = 10; //用于空实例的共享空数组实例 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //用于默认大小空实例的共享空数组实例。 我们将此与EMPTY_ELEMENTDATA区分开来，以了解什么时候第一个元素被添加 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; //用于存储ArryList元素的数组。ArrayList的容量就是数组的大小(这里不像HashMap有负载因子)， 任何用//elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA清空ArrayList在添加第一个元素时将扩展为DEFAULT_CAPACITY。 transient Object[] elementData; // 这个对象不私有化是为了简化内部类的访问（而且在HashMap中这中容器也不是私有的）//数组的最大数量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;//ArrayList的大小，也就是有多少个元素 private int size; 构造函数1234567891011121314151617181920212223242526272829//指定ArrayList的大小的构造函数。 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123;//如果参数大于0，创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123;//initialCapacity为0创建一个默认空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123;//如果initialCapacity&lt;0抛出异常，非法参数 throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125; //构造一个初始容量为10的空列表。 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;//默认的一个空列表 &#125; //根据一个集合类对象，构造一个线性表 public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray();//把集合类对象转为数组，存放发到elementData数组中 if ((size = elementData.length) != 0) &#123;//如果原来集合对象长度不为0 if (elementData.getClass() != Object[].class)//如果elementData的类型和要加入的数据类型不一致，返回不正确的object数组，重新拷贝一份。 elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123;//如果原来的对象为空，使用空的数组代替 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; ArrayList的常用方法，通过这方法，实现了对线性表的最小维护。 添加方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293 public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! 增加操作的记录数 elementData[size++] = e;//给数组赋值，使用新add的对象 return true;//返回结果为true &#125; //向指定位置添加元素 public void add(int index, E element) &#123; rangeCheckForAdd(index);//判断添加是否数组越界 ensureCapacityInternal(size + 1); // Increments modCount!!增加操作的记录数 System.arraycopy(elementData, index, elementData, index + 1, size - index);//数组copy一下，原来的对象到+1的位置 elementData[index] = element;//赋值 size++;//大小+1 &#125;//私有方法，用于判断minCapacity是否是最小的容量，minCapacity是最小需要的容量 private void ensureCapacityInternal(int minCapacity) &#123; //如果elementData是默认的数组，就从默认值和最小容量选一个最小值 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; //调用确保容量扩容的方法 ensureExplicitCapacity(minCapacity); &#125;//私有方法，判断是否需要扩容private void ensureExplicitCapacity(int minCapacity) &#123; modCount++;//操作记录变量+1 // overflow-conscious code 可能会溢出的代码 if (minCapacity - elementData.length &gt; 0)//如果最小容量大于现在数组容量，那么扩容，否则什么都不做。 grow(minCapacity);//调用扩容方法。 &#125; //判断数组大小是否越界 private void rangeCheck(int index) &#123; if (index &gt;= size)//如果越界抛出异常 throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; //设置指定位置的对象，并返回原来位置的对象 public E set(int index, E element) &#123; rangeCheck(index);//判断是否越界 E oldValue = elementData(index);//获取之前的值 elementData[index] = element;//设置新的值 return oldValue;//返回旧的值 &#125; //添加时候的越界检验 private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0)//如果指定位置大于数组大小，或者指定位置小于0 throw new IndexOutOfBoundsException(outOfBoundsMsg(index));//抛出异常 &#125;//根绝当前线性表的容量，去修剪数组（列表）的大小.一个应用可以使用这个操作最小化存储 public void trimToSize() &#123; modCount++;//fail-fast的标志，表示修改次数。这变量继承自AbstractList类 if (size &lt; elementData.length) &#123;//如果当前容量大于当前数组（列表）的大小，进行修减，否则什么都不做 elementData = (size == 0)//如果等于0，赋值空数组 ? EMPTY_ELEMENTDATA: Arrays.copyOf(elementData, size);//重新copy一份新的 &#125; &#125; 扩容方法1234567891011121314151617181920212223242526272829//扩容方法。参数最小容量private void grow(int minCapacity) &#123; // overflow-conscious code可能会溢出的代码 int oldCapacity = elementData.length;//获取之前为未扩容的的数组大小 //根据未扩容的，计算新的大小，大小是原来的1.5倍。oldCapacity+0.5*oldCapacity，通过右移一位的方式除2 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //如果新容量大于最最小容量，把新容量赋值给minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0)//如果新的容量大于最大数组大小 newCapacity = hugeCapacity(minCapacity);//如果超出了调用方法来处理。 // 根据新的容量和数组的大小，重新进行拷贝 elementData = Arrays.copyOf(elementData, newCapacity); &#125; //对超出容量进行处理。如果minCapacity&lt;0说明溢出了，如果最小值大于最大容量，返回最大容量 private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; get方法和其他获取元素的方法12345678910111213141516171819202122232425262728293031323334 //根据对象在线性表的位置获取对象 public E get(int index) &#123; rangeCheck(index);//判断是否越界 return elementData(index);//返回数组中的对象 &#125;//获取数组对象的位置，从前往后找public int indexOf(Object o) &#123; if (o == null) &#123;//如果对象为null那么查找为null的值 for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i;//返回结果 &#125; else &#123;//for循环去找到位置 for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;//返回-1没有找到 &#125;//获取数组对象的位置，从后往前找public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123;//for循环去找到位置 for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;//返回-1没有找到 &#125; remove相关方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106//删除节点，返回节之前节点的对象public E remove(int index) &#123; rangeCheck(index);//越界查询 modCount++;//修改操作+1 E oldValue = elementData(index);//获取之前节点的值 int numMoved = size - index - 1;//获取删除节点到数组末尾的距离 if (numMoved &gt; 0)//如果大于0说明是在最后一个元素前面，进行数组copy System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work，否则删除最后一个节点 return oldValue;//返回之前的对象 &#125; //移除指定对象 public boolean remove(Object o) &#123; if (o == null) &#123;//如果对象为null，循环找到对象，删除后返回true for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123;//如果不为null，循环找出对象，删除返回true。 for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125;//如果上面都没走到，返回false return false; &#125; //私有方法，跳过了边界检查，不会返回被移除的值 private void fastRemove(int index) &#123; modCount++;//修改次数+1 int numMoved = size - index - 1;//获取要移动的位置 if (numMoved &gt; 0)//注释同上 System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; //清除数组里的所有信息 public void clear() &#123; modCount++;//修改次数+1 // clear to let GC do its work，清空整个数组，让GC工作 for (int i = 0; i &lt; size; i++) elementData[i] = null; //修改size大小 size = 0; &#125; //移除集合中所有的对象 public boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c);//判断是否为空，如果为空抛出异常 return batchRemove(c, false);//调用批量移除方法。 &#125;//批量的删除collection里面的元素。private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; final Object[] elementData = this.elementData;//获取当前线性表的元素 int r = 0, w = 0; boolean modified = false; try &#123; for (; r &lt; size; r++)//循环列表中的所有数据进行比较，如果complement为true，将集合c中的元素，存放到数组的前面。W是从0开始 if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; &#125; finally &#123; // Preserve behavioral compatibility with AbstractCollection, // even if c.contains() throws. if (r != size) &#123;//如果r不等于size，对数组进行copy，复制r后面的元素 System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; &#125; if (w != size) &#123;//如果w不等于size，循环删除下标w后的元素 // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; &#125; &#125; return modified; &#125; System中的copy方法1234//会经常用到System的arraycopy的native方法，了解arraycopy方法。参数src是源数组，srcPos是源数组的位置。dest是目标数组，destPos是目标数组的位置，从源数组到目标数组length是要复制的数组的长度。 public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 总结ArrayList是一种常用集合类，是Java对数组的一种封装，同时它的泛型只支持包装类不支持基本类型。它不会像HashMap一样会有一个负载因子（比如0.75）。如果有的话也就1。也就是在ArrayList在被填满后自动扩容，而且它的扩容是1.5倍，不是2倍应该是基于一个空间上的考虑，毕竟一块连续的一块空间，尽量在使用的到的时候扩容，不能一次就扩容很大，对内存造成了浪费。 ArrayList和其他数组结构一样，都是查找的速度比较快O(1),但是插入和删除的速度，比较慢，要通过arraycopy效率相对比较低是O(n)，而链表恰恰相反，所以还要一种是LinkedList查找比较慢，但是插入和删除比较快但是查找比较慢。所以HashMap是一种比较好的设计，她结合了两者的有点。查找速度和删除速度都还不错，不过在空间消耗是要比List要好，所以总结一下还是空间换时间。所以在计算机中经常会有这种问题，好多数据结构一般都是比较浪费空间，来获取比较的时间，以上都是自己的拙见。 ArrayList这个源码也不是特别完整，包含她SubList的内部类没有介绍，和subList方法。]]></content>
      <categories>
        <category>源代码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析Java HashMap源码]]></title>
    <url>%2F2018%2F03%2F05%2F%E6%B5%85%E6%9E%90JavaHashMap%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[回顾 之前写过一篇关于HashMap的文章，里面介绍了关于HashMap的基本概念，和简单的数据结构，但是并没有对HashMap的源码进行系统的分析。 HashMap主要结构是一个数组，数组的下标是hash值取余之后数，存储key和value的信息。允许key和value是null。HashMap的数组的使用率小于0.75（默认的0.75,也可以设置）。一般默认情况下数组的大小是16，随着数据的添加当HashMap的容量达到threshold（16*0.75=12）时候会扩容（resize），扩容是将原来的数组扩大两倍（HashMap的数组大小一定是2的n次方）。同时HashMap也不是线程安全的，在并发情况下resize可能会出现死锁。 HashMap除了数组之外还有一个是链表，链表是解决解决HashMap的中hashcode取模以后的碰撞问题，正常的hashcode的范围很大，碰撞的几率很小但数组没有那么大的空间，对内存占用太大；要在为hashcode取模，由于取余会导致hashcode碰撞，为避免之前数组的数据被覆盖。HashMap在数组后面添加了列表，来解决这个问题。在JDK8以后当链表长度超过8以后就会被替换成一个红黑树，这样可以提高查找和插入效率。 HashMap是如何设计的HashMap是实现了Map接口、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。在HashMap中有两个很重要的参数，容量(Capacity)和负载因子(Load factor)。Capacity就是buckets的数目，loadFactor就是哈希桶(就是数组)填满程度的最大比例。如果对迭代性能要求很高的话不要把Capacity设置过大，也不要把loadFactor设置过小。当哈希桶填充的数目（即HashMap中元素的个数）大于Capacity*loadFactor时就需要调整哈希桶的数目为当前的2倍也就是扩容，可能和上面的有些重复。 计算Hash值，根据Hash值计算哈希桶中数组的位置。由于HashMap使用数组+链表的方式实现，所以能否快速计算Hash值和根据Hash值找到元素的位置很重要。下面就是Hash值是如何计算的 1234567891011//方法一,JDK1.7和1.8static final int hash(Object key) &#123; int h; //第一步 取hashCode值 h = key.hashCode() //第二步 高位参与运算 h ^ (h &gt;&gt;&gt; 16) ，减少hashCode的大小，计算hash值 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//方法二：jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的。没有单独抽出来static int indexFor(int h, int length) &#123; return h &amp; (length-1); //第三步 取模运算，获取数组下标&#125; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位（数组的下标），而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。但是hash值也就与数组的大小相关，所以每次resize的时候要重新进行Hash。所以链表和树都会被改变，resize是一个不小的开销（for循环套do-while循环），而且多线程下会出现并发问题。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。 HashMap是如何实现的首先看一下HashMap中的变量和他们的用途。 1234567891011121314151617181920212223242526272829303132333435//HashMap默认初始化大小，大小为16。它一定的2的倍数，这里使用位运算实现的，1左移4位 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //HashMap容量的最大值2的30次方。如果想指定更高的值可以通过构造函数指定。容量是2的背时 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认的负载因子，如果不在构造函数中指定，为了防止HashMap冲突，数组内不是全部使用，而是使用一部分。 static final float DEFAULT_LOAD_FACTOR = 0.75f;//从链表转换成红黑数的阈值，当链表长度长度为8同时MIN_TREEIFY_CAPACITY大于64时，就会将冲突的链表升级红黑树。 static final int TREEIFY_THRESHOLD = 8;//将红黑树转化成链表的阈值。同时hashMap的容量应该小于TREEIFY_THRESHOLD（64）。 static final int UNTREEIFY_THRESHOLD = 6; // 树化的最小容量64，也就是当HashMap的容量小于64时不进行树化（将链表转换成红树） static final int MIN_TREEIFY_CAPACITY = 64;//哈希桶（Node的数组），用于存放链表。它会随着数据量的增加去扩容。它的大小一般是2的n次方，同时不参与序列化 （transient，表示不被序列化） transient Node&lt;K,V&gt;[] table;//entry是存放key和Value的基本对象，这个一个set，一般会在遍历时候用到。根据它获取keySet和values transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //哈希表中的大小，存放了多少数据 transient int size;//这个HashMap被结构化修改的次数。结构化修改例如resize。这个参数一般是来用于实现HashMap 迭代器的fail-fast机制的，一般和并发相关。例如HashMap不能循环读取的时候插入数据。会抛出ConcurrentModificationException transient int modCount; //哈希表内元素数量的阈值，当哈希表内元素数量超过阈值时，会发生扩容resize()。threshold= int threshold; HashMap的基本构造函数，根据HashMap的参数来构造hashMap。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 // HashMap的构造函数，initialCapacity用于指定初始化容量，loadFactor用于指定负载因子，也就是数组的最大使用率 public HashMap(int initialCapacity, float loadFactor) &#123; //如果初始化大小小于0，抛出非法参数异常异常（边界处理） if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); //如果最初始化的容量比默认的最大容量大，那就指定最大容量为初始化容量。否则最大容量是默认最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 判断负载因子是大于0，是小数（浮点数） if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor;//通过上面的判断后赋值 this.threshold = tableSizeFor(initialCapacity);//根据初始化容量获取阈值，HashMap的数组大小。数组大小一定是2的倍数。 &#125; //指定初始化容量，使用默认的负载因子也就是0.75f public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; //使用默认的初始化容量16。和默认的负载因子0.75f public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125;//通过一个Map，生成一个Hashmap,使用默认的负载因子0.75f public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; //根据期望容量cap，返回2的n次方形式的 哈希桶的实际容量 length。 返回值一般会&gt;=cap static final int tableSizeFor(int cap) &#123; //经过下面的 或 和位移 运算， n最终各位都是1。 int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; //查看是否越界，例如把11111 + 1 变成 100000 。返回哈希桶的阈值 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125;//Map加入表中。参数m是要加入的Map，参数evict.一般会在resize和构造HashMap的时候用到 final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size();//获取m的大小 if (s &gt; 0) &#123; //如果s&lt;0就不用操作了 if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F;//根据m的元素数量和当前表的加载因子，计算出阈值。就是threshold. s除以loadFactor就是，哈希表的新容量。 //如果新容量小于最大容量，就是新容量，否则就是最大容量。 int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold)//t相当于initialCapacity threshold = tableSizeFor(t);//根据t获取获取阈值 &#125; else if (s &gt; threshold)//如果map的size大于生成的阈值，扩容 resize(); //循环把Map中的Key和Value放到HashMap中去 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125; &#125; HashMap中常用的内部类 1234567891011121314151617181920212223242526272829303132333435363738394041//这个类是HashMap中的基本类。实现了Map的Entry，下面还有TreeNode类。Hash表（哈希桶）指定就是Node的数组，里面是一个单向链表。从Node的数据结构也能看出来。 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash;//存放hashcode final K key; //存放Key值 V value; //c存放Value值 Node&lt;K,V&gt; next; //存放冲突后下一个node节点的地址。（这是个链表） //Node的构造函数 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; //重写set方法，get方法，equals方法，hashCode方法。 public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; //获取hashcode，是根据Key和Value的hashcode值 public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; //这个set方法是有返回值的，把之前的值返回出来了，而不是直接覆盖掉 public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; HashMap中比较关键的方法 resize方法是初始化哈希桶或者扩容哈希桶的大小，扩容一般就是加倍（doubles table size），如果是当前哈希桶是null,分配符合当前阈值的初始容量目标。否则，因为我们扩容成以前的两倍。同时把冲突的在链表或者树上的值取出来重新在放到哈希桶里index为原来位置+oldCap，这个过程叫rehash。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。n为hash表的长度 Hash表的扩容的具体过程。 因此，我们在扩充HashMap的时候，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的哈希桶。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990//返回对象是一个Node数组，也就是个哈希桶； final Node&lt;K,V&gt;[] resize() &#123; //把当前哈希桶设置成旧哈希桶。 Node&lt;K,V&gt;[] oldTab = table; //如果旧哈希桶（也就是当前的哈希桶）是null，长度为0，否则获取旧哈希桶的长度，也就是容量。 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold;//获取旧哈希桶的阈值。也就是当前的哈希桶的阈值 int newCap, newThr = 0;//设置新哈希桶的阈值和容量为0。 if (oldCap &gt; 0) &#123;//如果旧哈希桶的容量大于0说明是扩容，否则是创建哈希桶 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;//如果旧哈希桶的容量大于等于最大容量() threshold = Integer.MAX_VALUE; //把阈值设置成integer最大值 return oldTab;//直接返回旧哈希桶，说明不能在扩容。已经到了最大限度 &#125; //1、新哈希桶的容量等于旧哈希桶容量的2倍，因为是左移1为2进制。 //2、扩容后新哈希桶的容量是否小于最大的容量同时旧哈希的容量大于等于默认容量16。 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // 阈值也要double。 &#125; //如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr;//那么新表的容量就等于旧的阈值 else &#123; // zero initial threshold signifies using defaults // 如果当前表是空的,默认初始化Hash表(新建的hashMap)。使用默认的16个和0.75f的负载因子 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123;//如果新的阈值是0，对应的是当前表是空的，但是有阈值的情况 float ft = (float)newCap * loadFactor;//根据新表容量 和 加载因子 求出新的阈值 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); //进行越界修复 &#125; threshold = newThr;//把新哈希桶阈值值给当前阈值 @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //根据新hash表的变量，创建一个新哈希桶 table = newTab; //当前哈希桶等于新哈希桶 //从旧的哈希桶里面迁移数据。 if (oldTab != null) &#123;//如果旧的hash表不为空，迁移数据 for (int j = 0; j &lt; oldCap; ++j) &#123; //根据旧哈希桶的容量去循环。rehash操做 Node&lt;K,V&gt; e; //临时获取数组中对象 if ((e = oldTab[j]) != null) &#123; //如果桶中的对象不为空，把对象赋值给e oldTab[j] = null;//清空这个对象，等待GC if (e.next == null)//如果当前对象没有next说明后面没有冲突的链表 //根据e之前的哈希值和新容量，来获取数组下标的值，并把e放进去 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //如果e的类是TreeNode的话，将e强转成TreeNode然后把值插入进去 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果发生过哈希碰撞，节点数小于8个。则要根据链表上每个节点的哈希值，依次放入新哈希桶对应下标置。 else &#123; // preserve order //原索引 Node链表的头和尾。 Node&lt;K,V&gt; loHead = null, loTail = null; //原索引+oldCap Node链表的头和尾。 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //用于获取链表下一个对象的临时变量。与while循环中的e=next实现循环链表 do &#123; //for循环里面+do while循环效率很低 next = e.next; //链表的从头上面获取 if ((e.hash &amp; oldCap) == 0) &#123;//原索引 if (loTail == null) //如果没有到链表的尾部，那么设置链表头和尾是一个 loHead = e; //那么e就是链表的头 else loTail.next = e;//在链表的尾部添加e。 loTail = e;//链表的尾部也设置成e，也就是最新加进来的e &#125; else &#123; //原索引+oldCap if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null);//e的next为null，链表只有一个值 //如果原索引不为空，写到新哈希桶中原来的位置 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //如果原索引+oldCap不为空，新哈希桶中原来的位置+oldCap if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; //返回新的哈希表 return newTab; &#125; putVal方法，向hash表里插入值。如果参数onlyIfAbsent是true，那么不会覆盖相同key的值value，evict用于LinkedHashMap，下面是putVal方法的执行流程图。 可以结合上面的图看一下对应的源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586 //put方法向hash桶放入key和value public V put(K key, V value) &#123; //调用putVal方法，这里会覆盖key相同的值 return putVal(hash(key), key, value, false, true); &#125; // 参数hash是索引，key就是Map的key，Value是Map的value，onlyIfAbsent是否覆盖。evict用于LinkedHashMap final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; //tab Hash桶，p临时链表的节点，n为hash表的长度（数组长度），i临时的索引变量 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0)//如果hash表是空，或者hash桶的长度为0。 n = (tab = resize()).length;//通过resize()方法创建一个hash桶，并获取桶的长度赋值给n if ((p = tab[i = (n - 1) &amp; hash]) == null)//计算index，也就是数组的值。如果没有值，则没发生冲突,同时获取原来tab数组对应节点上的Node对象 tab[i] = newNode(hash, key, value, null);//直接插入数组中（哈希桶） else &#123;//发生了冲突，即要插入数组下标位置已经有一个Node对象 Node&lt;K,V&gt; e; K k;//临时Node对象和key值。同时用于循环链表 //p是原来节点对象，判断新增对象和原来对象是否一样，hash值是否相等，key值是否相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;// 如果相等,表明该key为当前节点的第一个,将原值设置为当前 e 对象 else if (p instanceof TreeNode) //如果p节点是tree节点，用红黑树的方式。 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);//把值放入到树里面 else &#123;//如果是链表，为链表处理的方式，binCount指的是这个链表的长度 for (int binCount = 0; ; ++binCount) &#123;//这是个死循环，没有结束条件，只有下面的break跳出 if ((e = p.next) == null) &#123;//判断p节点后面有没有其他节点，即第一个冲突的。同时e被赋值next对象 p.next = newNode(hash, key, value, null);//如果没有直插入新节点 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // 判断hash列表是否需要树化，如果大于7也就是8个，从0开始算 treeifyBin(tab, hash);//将在tab中，同样hash值的对象树化。for循环套do-while循环 break;//跳出循环 &#125; // 如果链表中存在该 key（key插入成功了）,因为已经将该节点赋值给 e,所以直接结束循环。等待下面的方法对值进行更新 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //循环链表 p = e; &#125; &#125; //如果e不等null if (e != null) &#123; // existing mapping for key V oldValue = e.value;//把老的值取出来。 if (!onlyIfAbsent || oldValue == null)//onlyIfAbsent为false，覆盖相桶的key的value e.value = value;//覆盖value afterNodeAccess(e);//在访问之后的hook函数，在LinkedHashMap中会用到。 return oldValue; //返回旧的值 &#125; &#125; ++modCount;//修改的次数加1。 if (++size &gt; threshold) resize();//把size与阈值对比，如果大于resize扩容； afterNodeInsertion(evict);//用于LikedHashMap的hook函数。 return null; &#125; //创建一个非树结构的节点 Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next); &#125; //树化哈希桶里面的节点，根据hash值 final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e;//是hash桶大小，index是数组下标，e是临时节点 //如果hash表是null（初始化哈希桶）或者tab的长度，小于最小树化的长度，就将扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize();//只是扩容，什么都不做 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123;//根据hash值，来获取链表的头节点。 TreeNode&lt;K,V&gt; hd = null, tl = null; //创建红黑树节点 do &#123; //将Node节点替换成TreeNode的节点，即红黑树的属性 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) //如果尾部是null hd = p;//头就是p（hd==head） else &#123; p.prev = tl;//设置设计p节点的前驱为之前的tail。treeNode节点继承LinkedHashMap.Entry。是双向的 tl.next = p;//尾部的next为p，也就是p是尾部。 &#125; tl = p;//设置尾部为p（tl==tail） &#125; while ((e = e.next) != null); //直到链表的next为空。同时把next值赋给e if ((tab[index] = hd) != null)//如果hash表中第一个元素不为空 hd.treeify(tab);//把tab树化 &#125; &#125;//根据Node节点创建一个TreeNode节点。 TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); &#125; getNode方法。根据key的hash值和key来获取元素（对象）。在HashMap中通过hash值可以快速定位到元素所在的位置，然后根据key(key是唯一的)来找出元素所在的链表位置（或者树的位置）。所以从某个角度讲HashMap也是一个空间换时间的一种数据结构。他通过存储key和key的Hash值来快速定位元素。 12345678910111213141516171819202122232425262728293031 //根绝Key获取value public V get(Object key) &#123; Node&lt;K,V&gt; e; //如果是null。返回null，如果有值返回值 return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;//根据hash值和key获取存放数据的节点final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;//tab哈希桶，first 第一节点，n哈希桶的长度，k是key值 //哈希桶不等于空，哈希痛的长度大于0，隔绝hash值获取的第一个节点不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果第一个key和哈希值就给定的相配，直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //如果第一个对象，后面有值。 if ((e = first.next) != null) &#123; //如果是红黑树节点，使用红黑树的获取办法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123;//不是的话，就循环链表来取出值，这里面用的do-while循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //如果hash值和key值都相等返回Node节点 return e; &#125; while ((e = e.next) != null);//循环直到e的next节点为null &#125; &#125; //否则返回null return null; &#125; removeNode，删除哈希桶里面的值。同时要判断是否要使用值匹配。但是默认的都是不匹配的，如果使用匹配找到key和value相同的才会删除，否则返回null； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 //删除一个元素节点，根据key值,返回元素节点的值 public V remove(Object key) &#123; Node&lt;K,V&gt; e; //调用移除节点方法 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125;//，根据Hash值，key，value，matchValue是否要匹配value值否则忽略，在删除节点后是否移动，如果不移动为false。final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; //声明使用的变量，如临时节点p，p节点一般都是哈希桶里的第一节点，哈希表的总长度n和下标index Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //哈希桶不为空，长度大于0，根绝hash值获取节点不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v;//节点node和e，key和value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果key值和hash值相等不为null，就把赋值node else if ((e = p.next) != null) &#123;//否者循环链表,或者是红黑树 if (p instanceof TreeNode)//获取树里面的节点 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123;//获取链表里的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //找到元素后删除，和链表和树的移动。1首先node节点不为null，同时判断value节点值问题。 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode)//如果是Tree节点，那么使用tree的操作,移除节点 ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p)//如果是第一个节点。直接替换。 tab[index] = node.next; else p.next = node.next;//设置node的next节点 ++modCount;//操作数+1 --size;//大小-1 afterNodeRemoval(node);//hook 方法 return node;//返回node节点 &#125; &#125; return null; &#125;//清空HashMap里面的值public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; //操作数+1 if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; //如果哈希表不为空，循环取出哈希表里面的值 size = 0;//设置HashMap大小为0 for (int i = 0; i &lt; tab.length; ++i) tab[i] = null;//清空哈希桶里的数据，也就是清空数组 &#125; &#125; HashMap中线程安全问题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//hashMap中通过迭代器来获取，Map中的数据。通过迭代器前modCount与循环后modCount对比，如果不一样，抛出//ConcurrentModificationException异常。来实现fast-fail机制//迭代器，用于循环取出HashMap中的数据 abstract class HashIterator &#123; Node&lt;K,V&gt; next; // next entry to return ，下一个entry Node&lt;K,V&gt; current; // current entry，当前entry int expectedModCount; // for fast-fail，用于fast-fail的变量 int index; // current slot，当前所在哈希桶的位置（数组下标） //默认的构造函数，构造HashMap的迭代器 HashIterator() &#123; expectedModCount = modCount;//期待的修改次数，使用当前hashMap的修改次数 Node&lt;K,V&gt;[] t = table;//哈希桶 current = next = null;//初始化当前节点和next节点 index = 0;//数组下标从0开始 if (t != null &amp;&amp; size &gt; 0) &#123; // advance to first entry,如果哈希桶不为空，size大于0 //找到第一个entry，如果next不为空，跳出循环。并把元素赋值给next，等于null继续找 do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; &#125; //时候还存在next public final boolean hasNext() &#123; return next != null; &#125; //获取下一个Next节点 final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount)//如果当前的修改次数不等于之前修改。也就是在这个过程HashMap发生修改。这里实现了fast-fail throw new ConcurrentModificationException();//抛出异常 if (e == null)//如果next节点为null，抛出没回这样元素的异常，一般在做循环的时候都会做判断 throw new NoSuchElementException(); //这里赋值e，同时把next也赋值。 if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; //循环找到下一个元素 do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; //返回当前节点 return e; &#125; //移除当前节点 public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null)//如果当前节点是null抛出异常 throw new IllegalStateException(); if (modCount != expectedModCount)//fast-fail机制 throw new ConcurrentModificationException(); current = null; //根据key删除节点 K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount;//同时更新操作次数 &#125; &#125; 在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，因为在数据增加的时候会导致resize(扩容)，会导致链表上数据发生变化，容易在多线程情况下是很容易造成链表回路。在get的情况下造成死循环。 12345678910111213141516171819//死循环的例子public class HashMapInfiniteLoop &#123; //基于jdk1.7 private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f); public static void main(String[] args) &#123; map.put(5， "C"); new Thread("Thread1") &#123; public void run() &#123; map.put(7, "B"); System.out.println(map); &#125;; &#125;.start(); new Thread("Thread2") &#123; public void run() &#123; map.put(3, "A); System.out.println(map); &#125;; &#125;.start(); map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。通过设置断点让线程1和线程2同时debug到transfer方法的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图 注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。 e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了 于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop(无限循环)。 HashMap与HashTable 的区别HashTable是线程安全的，且不允许key、value是null。HashTable默认容量是11。 HashTable是直接使用key的hashCode(key.hashCode())作为hash值，不像HashMap内部使用static final int hash(Object key)获取hash值。 HashTable取哈希桶下标是直接用模运算%.（因为其默认容量也不是2的n次方。所以也无法用位运算替代模运算） 扩容时，新容量是原来的2倍+1。int newCapacity = (oldCapacity &lt;&lt; 1) + 1; Hashtable是Dictionary的子类同时也实现了Map接口，HashMap是Map接口的一个实现类； 参考HashMap源码解析（JDK8） Java 8系列之重新认识HashMap]]></content>
      <categories>
        <category>源代码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析Java线程池源码]]></title>
    <url>%2F2018%2F02%2F26%2F%E6%B5%85%E6%9E%90Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[什么是线程池线程池顾名思义，就是有很多线程的一个池子，这里面有多少线程，是要根据你要业务需求来确定；它方便你线程的创建和使用，不需要频繁的创建线程资源使得，线程资源充分的得到利用。所以和数据库链接池类似，线程池的作用就是充分利用资源，提高相应速度，增加系统的吞吐率同时方便管理和监控线程池中线程使用情况，实现对程序的优化。当添加的到线程池中的任务超过它的容量时，会有一部分任务阻塞等待。当等待任务超过阻塞队列大小，线程池会通过相应的调度策略和拒绝策略，对添加到线程池中的线程进行管理。 线程池解决什么问题多线程技术主要解决处理器单元内多个线程执行的问题，它可以显著减少处理器单元的闲置时间，增加处理器单元的吞吐能力。 假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的时间，T3 销毁线程时间。 如果：T1 + T3 远大于 T2，则可以采用线程池，以提高服务器性能。 一个线程池包括以下四个基本组成部分： 1、线程池管理器（ThreadPool）：用于创建并管理线程池，包括 创建线程池，销毁线程池，添加新任务； 2、工作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务； 3、任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等； 4、任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。 线程池技术正是关注如何缩短或调整T1,T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了。 线程池不仅调整T1,T3产生的时间段，而且它还显著减少了创建线程的数目，看一个例子：假设一个服务器一天要处理50000个请求，并且每个请求需要一个单独的线程完成。在线程池中，线程数一般是固定的，所以产生线程总数不会超过线程池中线程的数目，而如果服务器不利用线程池来处理这些请求则线程总数为50000。一般线程池大小是远小于50000。所以利用线程池的服务器程序不会为了创建50000而在处理请求时浪费时间，从而提高效率。 线程池如何设计的 Core and maximum pool sizes （ThreadPoolExecutor会根据corePoolSize以及maximumPoolSize的边界自动的调整线程池的大小。） 1、当通过execute(Runnable)提交任务时，而且正在运行的线程数少于corePoolSize，即使其他线程处于空闲状态，也会创建一个新的线程执行这个任务； 2、如果有大于corePoolSize但是小于maximumPoolSize数量的线程正在运行，则新提交的任务会放进workQueue进行任务缓存，但是如果workQueue已满，则会直接创建线程执行，但是如果创建的线程数大于maximum pool sizes的时候将拒绝任务。3、当corePoolSize和maximumPoolSize 相等时则会创建固定数量的线程池 4、将maximumPoolSize 设置为无边界的，比如整数的最大值，则意味着线程数和任务数量一致，也就没有等待的任务5、corePoolSize、maximumPoolSize可以根据实际需求通过构造器设置，也可以动态的在运行时设置。 On-demand construction （按照需求构造线程）1、默认情况下，每一个核心线程只有当有新任务到来时才会初始化创建，并执行2、但是可以在运行时可以通过prestartCoreThread(一个coreThread)或者prestartAllCoreThreads(全部coreThread)来提前创建并运行指定的核心线程，这种需求适用于初始化线程池时，任务队列初始不为空的情况下。 Creating new threads （创建一个新的线程） 1、创建线程是通过ThreadFactory。除非特别的设定，否则默认使用Executors.defaultThreadFactory作为线程池，这个线程池创建的所有线程都有相同的线程组，线程优先级，非守护线程的标志2、通过应用不同的线程池，可以更改线程的名字，线程组，优先级，守护标志等等3、当通过newThread()调用线程池创建线程池失败时，返回null，此时执行器会继续运行，但是可能处理不了任何任务 4、线程需要处理”modifyThread” RuntimePermission，对线程修改进行运行时权限检查。如果使用这个线程池的工作线程或者其他线程没有处理这个认证”permission”则会使服务降级：对于线程池的所有设置都不会及时的生效，一个已经关闭的线程池可能还会处于一种线程池终止没有完成的状态 Keep-alive times (空闲的线程存活时间) 1、当这个线程池此时含有多余corePoolSize的线程存在，则多余的线程在空闲了超过keepAliveTime的时间将会被终止2、这提供了一种减少空闲线程从而降低系统线程资源损耗的方法，还可以通过setKeepAliveTime进行动态设置3、默认情况下，keep-alive policy只对超出corePoolSize的线程起作用，但是可以通过方法allowCoreThreadTimeOut(boolean)将空闲超时策略同样应用于coreThread，但是要保证超时时间不为0值。 Queue （阻塞队列，任何BlockingQueue都可以被用来容纳和传递提交的任务） 1、如果正在运行的线程小于corePoolSize，则executor会新增一个线程而不是将任务入队2、如果正在运行的线程大于corePoolSize但是小于maximumPoolSize，executor则会将任务入队，而不是创建一个线程3、如果任务不能入队（队列已满），则在没有超出maximumPoolSize的情况下创建一个新的线程，否则某种拒绝策略拒绝这个任务。 three general strategies for queuing （三种入队策略）1、Direct handoffs：直接传递。比如 synchronousQueue，这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。2、Unbounded queues：无界队列。比如 没有指定容量的LinkedBlockingQueue，这将会使coreThread一直工作，而且由于任务总能入队，所以也不会创建其他超过corePoolSize的线程。用于所有任务完全独立，不相关，比如平滑瞬间高并发web页面的请求等，其实相当于异步框架了3、Bounded queues：有界队列。 比如ArrayBlockingQueue，有助于在设置有限大的maximumPoolSizes时，阻止造成系统资源的枯竭。队列大小和最大池大小可能需要相互折衷：使用大队列和小池最大限度地减少CPU的使用，操作系统资源，和上下文切换开销，但可能会导致人为的低吞吐量。如果任务经常被阻塞（例如，如果它们是I/O绑定），系统可能比你允许的时间安排更多线程的时间。使用小队列通常需要更大的池大小，这使得CPU繁忙，但可能会遇到不可接受的调度开销，这也降低吞吐量 Rejected tasks （拒绝任务） 当提交一个新任务时，如果Executor已经关闭或者有限的workQueue，maximumPoolSizes，并且他们已经饱和了，只要出现其中一种情况都会被拒绝。有四种已经定义的处理策略。也可以继承RejectedExecutionHandler自定义实现 Hook methods （钩子方法，提供在每个任务执行时不同阶段执行不同的处理函数） 1、protected void beforeExecute(Thread t, Runnable r)：优先使用指定的线程处理给定的任务，并在任务执行前做一些处理（如设置ThreadLocal变量或者记录一些日志等），t为执行r任务的线程，r为提交的任务。 2、protected void afterExecute(Runnable r, Throwable t)：任务执行完成时处理。r为执行完的任务，t为指定的造成任务终止的异常，如果设置为null则执行会正常完成，不会抛出异常 3、protected void terminated()当Executor终止时，被调用一次 以上三个方法都为空方法，使用者自行实现。在进行多层嵌套时都要显示调用 super.method() 完成上层的处理函数。如果在调用方法时发生异常，则内部的工作线程可能会依次失败，突然终止。 可以继承ThreadPoolExecute，并实现上述几个Hook方法来检测线程池的状态，自定义自己的线程池，如监控任务的平均、最大、最小执行时间，来发现有没有一致阻塞的线程任务。 线程池是如何实现的在Java中线程池使用ThreadPoolExecutor这类去实现了，它里面封装了线程池的相关属性和创建线程池的基本方法。下面我们就来简单看一下源代码，简答的分析一波 123456789101112131415161718192021222324252627282930313233343536373839404142434445 /* 这些是Java线程池中阶一些基本变量和简单方法*///用来存储工作线程数和工作状态，初始化状态和数量，状态为RUNNING，线程数为0 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//用来计数工作线程数。workerCount的最大为2^29 -1。这里Java中Integer是32位 private static final int COUNT_BITS = Integer.SIZE - 3;//这里取得后29位，也就是线程池的容量 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits(线程池的运行状态是存储在高3位) //可以接受新的任务，也可以处理阻塞队列里的任务 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;//b不可以接受新的任务，可以处理阻塞队列里的任务 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;//不接受新的任务，不处理阻塞队列里的任务，中断正在处理的任务 private static final int STOP = 1 &lt;&lt; COUNT_BITS;//过渡状态，也就是说所有的任务都执行完了，当前线程池已经没有有效的线程，这个时候线程池的状态将会TIDYING，并且将要调用terminated方法 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;//终止状态。terminated方法调用完成以后的状态 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl (打包和拆包ctl变量，也就是获取存储工作线程数和工作状态的变量和把工作状态和线程数转化成ctl)这里都是通过位运算实现的。//获取线程池的运行状态,根据ctl。CAPACITY的非操作得到的二进制位11100000000000000000000000000000，然后做在一个与操作，相当于直接取前3位的的值 private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;//获取工作的线程数，根据ctl。也就是后29位的数字。 直接跟CAPACITY做一个与操作即可，CAPACITY就是的值就 1 &lt;&lt; 29 - 1 = 00011111111111111111111111111111。 与操作的话前面3位肯定为0，相当于直接取后29位的值 private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;//根据运行状态和工作线程数获取ctl。或操作 private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;//不需要拆包的去访问变量，这些状态依赖runState /* * Bit field accessors that don't require unpacking ctl. * These depend on the bit layout and on workerCount being never negative. *///来判断两个运行状态的大小，运行状态越大，越接近停止。 private static boolean runStateLessThan(int c, int s) &#123; return c &lt; s; &#125;//来判断两个运行状态的大小 private static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s; &#125;//来判当前状态是否是运行状态 private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN; &#125; 线程池中使用AtomicInteger 的CAS机制来实现对运行时状态以及工作线程计数的并发一致性操作，低29位（32-3）用来保存workerCount，所以workerCount的最大为2^29 -1 。高3位用来保存runState，这样实现具有较高效率，不用单独两次存储。 RUNNING -&gt; SHUTDOWN：手动调用shutdown方法，或者ThreadPoolExecutor要被GC回收的时候调用finalize方法，finalize方法内部也会调用shutdown方法 (RUNNING or SHUTDOWN) -&gt; STOP：调用shutdownNow方法 SHUTDOWN -&gt; TIDYING：当队列和线程池都为空的时候 STOP -&gt; TIDYING：当线程池为空的时候 TIDYING -&gt; TERMINATED：terminated方法调用完成之后，ThreadPoolExecutor内部还保存着线程池的有效线程个数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172 /** * Attempts to CAS-increment the workerCount field of ctl. *///尝试CAS-递增ctl的workerCount字段。 private boolean compareAndIncrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect + 1); &#125; /** * Attempts to CAS-decrement the workerCount field of ctl. *///尝试CAS-递减ctl的workerCount字段。 private boolean compareAndDecrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect - 1); &#125; /** * Decrements the workerCount field of ctl. This is called only on * abrupt termination of a thread (see processWorkerExit). Other * decrements are performed within getTask. *///减少ctl的workerCount字段的值，当一个线程因为异常退出的时候调用这个方法。其他的递减都在getTask方法里进行 private void decrementWorkerCount() &#123; do &#123;&#125; while (! compareAndDecrementWorkerCount(ctl.get())); &#125;//缓存队列，是一个存放没有处理的任务。（也就是runnable接口中写的代码） private final BlockingQueue&lt;Runnable&gt; workQueue; // 线程池主锁，用于访问worker线程集，还有其他关于线程池信息的记录信息（比如线程池大小，runState） private final ReentrantLock mainLock = new ReentrantLock(); //工作线程集合，访问时需获取mainLock private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // mainLock上的终止条件量，用于支持awaitTermination private final Condition termination = mainLock.newCondition(); //记录线程最大的线程数，访问时需获取mainLock private int largestPoolSize; //记录已经完成的记录数，访问时需获取mainLock private long completedTaskCount; /** * 以下所有变量都为volatile类型的，以便能使所有操作都基于最新值 * （因为这些值都可以通过对应的set方法，在运行时动态设置）， * 但是不需要获取锁，因为没有内部不变量依赖于它们与其他动作同步变化。 */ // 用于创建新线程的线程工厂 private volatile ThreadFactory threadFactory; //当线程池满了的时候，拒绝服务策略 private volatile RejectedExecutionHandler handler; //一个空闲线程，可以保持存活的最大时间。核心线程不算 private volatile long keepAliveTime;//默认是false，核心线程可以在空闲的时候存活，如果是true那么核心线程超时会关闭。 private volatile boolean allowCoreThreadTimeOut;//核心线程个数，如果allowCoreThreadTimeOut为false那么会一直存在，如果ture的话可能为0。最小 private volatile int corePoolSize;//线程池的最大线程数。它小于CAPACITY private volatile int maximumPoolSize; //设置默认的拒绝策略。 private static final RejectedExecutionHandler defaultHandler = new AbortPolicy();// 对于调用线程池的shutdown(),shutdownNow()方法权限认证。用于保护线程安全的 private static final RuntimePermission shutdownPerm = new RuntimePermission("modifyThread"); 线程池的几个构造函数，线程池中一共有7个参数。每个参数都代表这个不同的意义。corePoolSize核心线程的数量；maximumPoolSize线程池的最多线程数；keepAliveTime当一个线程在空闲时的存活时间（核心线程要看allowCoreThreadTimeOut参数）；TimeUnit时间单位多数是秒，也可以设置毫秒；workQueue缓冲队列（即线程池没有运行的任务队列）；threadFactory用于创建新线程的线程工厂；handler用于线程池在满负荷下的拒绝策略。可以使抛异常，也可是放弃任务等。 拒绝策略指的是由于超出线程范围和队列容量而使执行被阻塞时所使用的处理程序。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//使用默认的线程工厂和，默认的拒绝策略生产线程池 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; //调用构造函数 this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125;//使用默认的拒绝策略，传入自定义线程工厂 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; //调用构造函数 this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); &#125;//使用默认的线程工厂，使用其他拒绝策略 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); &#125; //线程池的构造函数 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; //如果核心线程数小于0，最大线程数小于等于0，最大线程数小于核心线程数，超时时间小于0会抛出非法参数异常 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); //当工作队列为null，线程工厂为null，拒绝策略为null抛出空指针异常。 if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 线程池的几个内部类，主要是Worker类，和几个拒绝策略的实现类。Worker是一个AQS的实现类(为何设计成一个AQS在闲置Worker里会说明)，同时也是一个实现Runnable的类，实现独占锁(非重入的互斥锁)，它的构造函数只接受一个Runnable参数，内部保存着这个Runnable属性，还有一个thread线程属性用于包装这个Runnable(这个thread属性使用ThreadFactory构造。在构造函数内完成thread线程的构造)，实现互斥锁主要目的是为了中断的时候判断线程是在空闲还是运行（判断是否是闲置线程，是否可以被强制中断。 一般有锁闲置的工作线程，因为在执行runWorker的时候会去掉锁），可以看后面 shutdown 和 shutdownNow 方法的分析。另外还有一个completedTasks计数器表示这个Worker完成的任务数。Worker类复写了run方法，使用ThreadPoolExecutor的runWorker方法(在addWorker方法里调用)，直接启动Worker的话，会调用ThreadPoolExecutor的runWork方法。需要特别注意的是这个Worker是实现了Runnable接口的，thread线程属性使用ThreadFactory构造Thread的时候，构造的Thread中使用的Runnable其实就是Worker。在前面还有一个HashSet的Worker 的集合workers，线程池通过管理线程池里的线程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127· //worker是用于管理 private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; //这个类永远都不会序列化，只是符合Javac的规范 private static final long serialVersionUID = 6138294804551838833L; //当前的这个worker运行在这个Thread，worker也实现Runnable接口。如果ThreadFactory创建失败可能是null final Thread thread; //初始化运行任务，可能是空 Runnable firstTask; //每线程任务计数器 volatile long completedTasks; //Worker的构造函数，通过Worker的firstTask指定一个任务，同时通过ThreadFactory创建一个线程 Worker(Runnable firstTask) &#123; //把状态位设置成-1，这样任何线程都不能得到Worker的锁，除非调用了unlock方法。这个unlock方法会在runWorker方法中一开始就调用，这是为了确保Worker构造出来之后，没有任何线程能够得到它的锁，除非调用了runWorker之后，其他线程才能获得Worker的锁 setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 使用ThreadFactory构造Thread，这个构造的Thread内部的Runnable就是本身，也就是这个Worker。所以得到Worker的thread并start的时候，会执行Worker的run方法，也就是执行ThreadPoolExecutor的runWorker方法 this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker 将主运行循环委托给外部runWorker */ public void run() &#123; runWorker(this); &#125; // Lock methods 锁方法,state属性是从AQS中获取 // // The value 0 represents the unlocked state. //值为0 的时候是非锁定状态 // The value 1 represents the locked state. //值为1的时候是锁定状态 //是否被锁定，如果有就不等于0。 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; //尝试获取锁 protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; //释放锁 protected boolean tryRelease(int unused) &#123; //设定当前资源的线程为null setExclusiveOwnerThread(null); //设置状态为0 setState(0); return true; &#125; //锁定 public void lock() &#123; acquire(1); &#125; //尝试获取锁 public boolean tryLock() &#123; return tryAcquire(1); &#125; //释放锁，通过内部函数实现，然后调用 public void unlock() &#123; release(1); &#125; //判断是否被锁定 public boolean isLocked() &#123; return isHeldExclusively(); &#125; //中断已经开始的线程 void interruptIfStarted() &#123; Thread t; //判断任务已经开始，然后中断执行的线程（这个中断是强制的） if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125; //直接运行新添加的任务，除非意外终止。 public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; //构造函数 public CallerRunsPolicy() &#123; &#125; //直接运行任务 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125; &#125; //超出线程范围和队列容量时抛出异常 public static class AbortPolicy implements RejectedExecutionHandler &#123; //构造函数 public AbortPolicy() &#123; &#125; //抛出异常 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException("Task " + r.toString() + " rejected from " + e.toString()); &#125; &#125; //拒绝任务的处理程序，丢弃被拒绝的任务 public static class DiscardPolicy implements RejectedExecutionHandler &#123; //构造函数 public DiscardPolicy() &#123; &#125; //什么都不做，这会有丢弃任务r的效果 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125; &#125; //丢弃最老的任务 public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; //构造函数 public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; //如果线程池在运行，那么就获取缓冲队列，抛出最上面的一个 if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125; &#125; ThreadPoolExecutor执行任务。首先通过submit或者excute方法把任务放到线程池中（这里如果线程池空闲会直接执行，否则会进入到缓冲队列中去），然后线程池从缓冲队列中获取任务（getTask），然后添加Work，最后执行要执行任务内容(runWorker)。 12345678910// submit是存在AbstractExecutorService的源码。一般在Executors中会用到public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); //newTaskFor是把runnable接口转换有返回值 RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; &#125;//很明显地看到，submit方法内部使用了execute方法，而且submit方法是有返回值的。在调用execute方法之前，使用FutureTask包装一个Runnable，这个ftask就是返回值。 由于submit方法内部调用execute方法，所以execute方法就是执行任务的方法，来看一下execute方法，execute方法内部分3个步骤进行处理。 如果当前正在执行的Worker数量比corePoolSize(基本大小，核心线程数)要小。直接创建一个新的Worker执行任务，会调用addWorker方法 如果当前正在执行的Worker数量大于等于corePoolSize(基本大小，核心线程数)。将任务放到阻塞队列里，如果阻塞队列没满并且状态是RUNNING的话，直接丢到阻塞队列，否则执行第3步。丢到阻塞队列之后，还需要再做一次验证(丢到阻塞队列之后可能另外一个线程关闭了线程池或者刚刚加入到队列的线程死了)。如果这个时候线程池不在RUNNING状态，把刚刚丢入队列的任务remove掉，调用reject方法，否则查看Worker数量，如果Worker数量为0，起一个新的Worker去阻塞队列里拿任务执行 丢到阻塞失败的话，会调用addWorker方法尝试起一个新的Worker去阻塞队列拿任务并执行任务，如果这个新的Worker创建失败，调用reject方法 上面说的Worker可以暂时理解为一个执行任务的线程。 123456789101112131415161718192021222324252627public void execute(Runnable command) &#123; //判断任务是否为空 if (command == null) throw new NullPointerException(); //获取ctl int c = ctl.get(); //根据ctl获取工作线程线程数，如果小于核心线程数，添加新的worker，也就是新线程 if (workerCountOf(c) &lt; corePoolSize) &#123; // 第一个步骤，满足线程池中的线程大小比基本大小要小 if (addWorker(command, true)) // addWorker方法第二个参数true表示使用基本大小 return; //否则重新获取ctl c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 第二个步骤，线程池的线程大小比基本大小要大，并且线程池还在RUNNING状态，阻塞队列也没满的情况，加到阻塞队列里 //重新获取ctl，二次校验。 int recheck = ctl.get(); // 虽然满足了第二个步骤，但是这个时候可能突然线程池关闭了，所以再做一层判断 if (! isRunning(recheck) &amp;&amp; remove(command))//关闭了 reject(command); //调用拒绝策略方法 else if (workerCountOf(recheck) == 0) addWorker(null, false); // 第三个步骤，直接使用线程池最大大小。addWorker方法第二个参数false表示使用最大大小 &#125; else if (!addWorker(command, false)) //调用拒绝策略方法 reject(command); &#125; 如何添加一个Worker。 在外循环对运行状态进行判断，内循环通过CAS机制对workerCount进行增加，当设置成功，则跳出外循环，否则进行进行内循环重试 外循环之后，获取全局锁，再次对运行状态进行判断，符合条件则添加新的工作线程，并启动工作线程，如果在最后对添加线程没有开始运行（可能发生内存溢出，操作系统无法分配线程等等）则对添加操作进行回滚，移除之前添加的线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111// 两个参数，firstTask表示需要跑的任务。boolean类型的core参数为true的话表示使用线程池的基本大小，为false使用线程池最大大小 //返回值是boolean类型，true表示新任务被接收了，并且执行了。否则是false private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; //获取ctl int c = ctl.get(); //获取线程池状态 int rs = runStateOf(c); // 这个判断转换成 rs &gt;= SHUTDOWN &amp;&amp; (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty)。 // 概括为3个条件： // 1. 线程池不在RUNNING状态并且状态是STOP、TIDYING或TERMINATED中的任意一种状态 // 2. 线程池不在RUNNING状态，线程池接受了新的任务 // 3. 线程池不在RUNNING状态，阻塞队列为空。 满足这3个条件中的任意一个的话，拒绝添加 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; //获取工作线程数 int wc = workerCountOf(c); // 1、工作线程数大于总容量；2、如果core是true大于核心线程数，如果是false大于设置最大线程数，如果满足就返回false，不能添加 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 没有超过各种大小的话，cas操作线程池线程数量+1，cas成功的话跳出循环 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // 重新检查状态 if (runStateOf(c) != rs) // 如果状态改变了，重新循环操作 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 走到这一步说明cas操作成功了，线程池线程数量+1 boolean workerStarted = false;// 任务是否成功启动标识 boolean workerAdded = false;// 任务是否成功添加标识 Worker w = null; try &#123; w = new Worker(firstTask); //基于任务firstTask构造worker，firstTask可能是null final Thread t = w.thread; //从worker中获取线程对象 if (t != null) &#123; //ThreadFactory构造出的Thread有可能是null，做个判断 final ReentrantLock mainLock = this.mainLock;// 得到线程池的可重入锁 // 锁定下面的操作 mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. //获取线程池运行状态 int rs = runStateOf(ctl.get()); //1、线程池的状态是RUNNING的； //2、线程池的状态是SHUTDOWN同时firstTask是空 //上面两条有一个满足都可以天剑，否则添加失败 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 判断线程是否还活着，也就是说线程已经启动并且还没死掉 throw new IllegalThreadStateException(); workers.add(w); // worker添加到线程池的workers属性中，是个HashSet //获取workers的大小 int s = workers.size(); if (s &gt; largestPoolSize)//如果workers的大小小于largestPoolSize，s付给线程最大值 largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; //释放锁 mainLock.unlock(); &#125; //如果worker添加成功 if (workerAdded) &#123; //开始执行线程程序 t.start(); //设置标志为true workerStarted = true; &#125; &#125; &#125; finally &#123; //如果启动失败 if (! workerStarted) //调用添加失败方法 addWorkerFailed(w); &#125; //返回运行（也就是添加worker）是否成功失败 return workerStarted; &#125; //添加工作线程失败后调用的方法 private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; //获取可重入锁 mainLock.lock(); //锁定代码 try &#123; if (w != null) //如果添加的工作线程不为空，从workers中移除该工作线程 workers.remove(w); // 减少工作线程计数 decrementWorkerCount(); // 因为中断异常而没有启动线程，从而回滚已入队的线程 // 这个中断异常可能是关闭线程池时发生的，所以应该将终止线程池的信号传播 tryTerminate();//终止线程池 &#125; finally &#123; mainLock.unlock(); &#125; &#125; 运行Worker中的任务。 线程池中的这个基本大小指的是Worker的数量。一个Worker是一个Runnable的实现类，会被当做一个线程进行启动。Worker内部带有一个Runnable属性firstTask，这个firstTask可以为null，为null的话Worker会去阻塞队列拿任务执行，否则会先执行这个任务，执行完毕之后再去阻塞队列继续拿任务执行。 所以说如果Worker数量超过了基本大小，那么任务都会在阻塞队列里，当Worker执行完了它的第一个任务之后，就会去阻塞队列里拿其他任务继续执行。 Worker在执行的时候会根据一些参数进行调节，比如Worker数量超过了线程池基本大小或者超时时间到了等因素，这个时候Worker会被线程池回收，线程池会尽量保持内部的Worker数量不超过基本大小 Worker执行任务的时候调用的是Runnable的run方法，而不是start方法，调用了start方法就相当于另外再起一个线程了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394//这是个final的方法，不能被重写。 final void runWorker(Worker w) &#123; // 获取当前线程，在Worker类中的run方法调用这个runWorker方法。 Thread wt = Thread.currentThread(); // 从worker类中获取任务 Runnable task = w.firstTask; w.firstTask = null;//清空worker中的任务 w.unlock(); // 释放worker上独占锁。 boolean completedAbruptly = true;// 因为运行异常导致线程突然终止的标志 try &#123; // 如果worker中的任务不为空，继续，否则使用getTask获得任务。一直死循环，除非得到的任务为空才退出 while (task != null || (task = getTask()) != null) &#123; // 如果拿到了任务，给自己上锁，表示当前Worker已经要开始执行任务了，已经不是闲置Worker(闲置Worker的解释请看下面的线程池关闭) w.lock(); // 在执行任务之前先做一些处理。 //1. 如果线程池已经处于STOP状态并且当前线程没有被中断，中断线程 //2. 如果线程池还处于RUNNING或SHUTDOWN状态，并且当前线程已经被中断了，重新检查一下线程池状态，如果处于STOP状态并且没有被中断，那么中断线程 if ((runStateAtLeast(ctl.get(), STOP) || if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; //执行任务前的函数。一般都是是自己实现，它提供了空方法，需要自己复写 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 运行任务.这里调用的不是start方法，而是run方法。 //这里run的时候可能会被中断，比如线程池调用了shutdownNow方法 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; //执行运行前的函数。一般都是是自己实现，它提供了空方法，需要自己复写 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; //清空任务 w.completedTasks++; //已完成任务数+1 w.unlock(); //释放worker的锁 &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); // 回收Worker方法 &#125; &#125; //私有方法，用于回收Worker private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; //如果突然情况导致线程终止，WorkerCount-1 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); //获取锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //完成的任务数增加 completedTaskCount += w.completedTasks; //移除完成的workers workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; //尝试终止线程池 tryTerminate(); //获取ctl int c = ctl.get(); //根据ctl获取状态，判断是否是停止状态之前的状态Stop 为1 if (runStateLessThan(c, STOP)) &#123; //如果线程没有异常退出 if (!completedAbruptly) &#123; //allowCoreThreadTimeOut为true 的时候是，工作线程最小为0，否则最小为核心工作线程个数 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; // 如果线程数量大于等于正常工作的数量则不再添加新的线程 if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; //添加一个工作线程（没有任务的），false是使用最大线程数。true是核心线程数 addWorker(null, false); // 新开一个Worker代替原先的Worker // 新开一个Worker需要满足以下3个条件中的任意一个： // 1. 用户执行的任务发生了异常 // 2. Worker数量比线程池基本大小要小 // 3. 阻塞队列不空但是没有任何Worker在工作 &#125; &#125; 获取任务getTask，一般会在runWorker的时候去调用。 通过死循环来对线程池状态进行判断，并获取任务，在超时发生之前发生中断则重置超时标志位false并进行重试，如果获取到任务则返回任务 主要来看一下是如何实现移除空闲keepAliveTime线程的：workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)方法从任务队列中定时获取任务，如果超时，则说明线程已经在等待了keepAliveTime都没有获得任务，则将超时标志设为true，在下一次循环时进行判断，如果发现上一次获取任务发生超时，则立刻返回null，这时worker线程主循环将正常结束，并移除结束的worker。 123456789101112131415161718192021222324252627282930313233343536373839404142// 获取任务private Runnable getTask() &#123; boolean timedOut = false; // 如果使用超时时间并且也没有拿到任务的标识 for (;;) &#123; int c = ctl.get(); //获取ctl int rs = runStateOf(c); //根据ctl获取线程状态，每次现用现取 // 线程池状态在SHUTDOWN，或者是Stop之后或者工作队列为空直接返回null if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount();//工作线程数-1 return null; &#125; int wc = workerCountOf(c); //获取工作线程数 // Are workers subject to culling? //timed只的是，是否有直接的线程可用，是否要等待。 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; //工作线程个数大于最大线程池数，或者等待超时，后者阻塞队列中为空 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) //worker数量减一，返回null。回收worker return null; continue; //否则继续获取 &#125; try &#123; //timed为true说明线程池里没有充足的线程需要等待，否则直接获取任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take();// 如果在keepAliveTime时间内获取到任务则返回, if (r != null) return r; // 否则将超时标志设置为true timedOut = true; &#125; catch (InterruptedException retry) &#123; //抛异常设置超时时间为false表示没有超时 timedOut = false; &#125; &#125; &#125; Worker在回收的时候会尝试终止线程池也就是tryTerminate方法。尝试关闭线程池的时候，会检查是否还有Worker在工作，检查线程池的状态，没问题的话会将状态过度到TIDYING状态，之后调用terminated方法，terminated方法调用完成之后将线程池状态更新到TERMINATED。 123456789101112131415161718192021222324252627282930313233343536373839404142434445 //线程池尝试结束自己运行，不一定会结束 // 满足3个条件中的任意一个，不终止线程池 // 1. 线程池还在运行，不能终止 // 2. 线程池处于TIDYING或TERMINATED状态，说明已经在关闭了，不允许继续处理 // 3. 线程池处于SHUTDOWN状态并且阻塞队列不为空，这时候还需要处理阻塞队列的任务，不能终止线程池 final void tryTerminate() &#123; for (;;) &#123; //获取ctl int c = ctl.get(); //上面的三种情况，直接返回 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; //走到这一步说明线程池已经不在运行，阻塞队列已经没有任务，但是还要回收正在工作的Worker if (workerCountOf(c) != 0) &#123; // Eligible to terminate // 由于线程池不运行了，调用了线程池的关闭方法. // 中断闲置Worker，直到回收全部的Worker。这里没有那么暴力，只中断一个，中断之后退出方法，中断了Worker之后，Worker会回收，然后还是会调用tryTerminate方法，如果还有闲置线程，那么继续中断法 interruptIdleWorkers(ONLY_ONE); return; &#125; // 获取锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //设置线程池状态，和工作线程个数 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; //调用terminated方法，结束线程池 terminated(); &#125; finally &#123; //设置线程池状态和工作线程个数 ctl.set(ctlOf(TERMINATED, 0)); //唤醒其他线程 termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125; &#125; 线程池的关闭主要是两个方法，shutdown和shutdownNow方法。 shutdown方法会更新状态到SHUTDOWN，不会影响阻塞队列里任务的执行，但是不会执行新进来的任务。同时也会回收闲置的Worker，闲置Worker的定义上面已经说过了。 shutdownNow方法会更新状态到STOP，会影响阻塞队列的任务执行，也不会执行新进来的任务。同时会回收所有的Worker。 线程池的结束相关的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// 将线程池从运行状态转为SHUTDOWN状态public void shutdown() &#123; //获取锁锁定这块代码 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess();// 检查关闭线程池的权限 advanceRunState(SHUTDOWN);//设置运行状态为SHUTDOWN interruptIdleWorkers();//中断空闲的工作线程 //钩子方法，默认不处理。ScheduledThreadPoolExecutor会做一些处理 onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();//尝试关闭线程池 &#125;//将线程池从运行状态转为STOP状态，同时返回阻塞对列中的任务集合public List&lt;Runnable&gt; shutdownNow() &#123; //要返回的阻塞队列中的任务 List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock;//获取锁并锁定 mainLock.lock(); try &#123; checkShutdownAccess();//检验权限 advanceRunState(STOP);//设置状态为STOP interruptWorkers();//关闭运行的工作线程，无论是否闲置 tasks = drainQueue(); //将队列中没有运行的任务取出来 &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();//尝试关闭线程池 return tasks; &#125; //awaitTermination方法将状态设置为TERMINATED，并拒绝新增任务，调用isShutdown返回true，但是调用isTerminaed返回false，超时等待所有提交的任务的完成。 public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException &#123; //将设置时间转化成纳秒 long nanos = unit.toNanos(timeout); //获取锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (;;) &#123;， //判断线程池状态，如果所有提交的任务已经完成，则立刻返回true if (runStateAtLeast(ctl.get(), TERMINATED)) return true; if (nanos &lt;= 0)// 已经超时，则返回false return false; // 进入等待，直到被通知、中断、超时，则返回剩余的间， // 如果返回值小于等于0，则表示是超时返回 nanos = termination.awaitNanos(nanos); &#125; &#125; finally &#123; mainLock.unlock(); &#125; &#125;//中断空闲的Worker，传入了参数false，表示要中断所有的正在运行的闲置Worker，如果为true表示只打断一个闲置Workerprivate void interruptIdleWorkers(boolean onlyOne) &#123; //获取锁。 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //从workers中取出worker并中断 for (Worker w : workers) &#123; //获取线程 Thread t = w.thread; //如果该运行的工作线程是没有打断，同时闲置的工作线程（存在锁的） if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; //打断该工作线程 t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock();//释放worker的锁 &#125; &#125; //只打断一个，然后跳出循环 if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125; &#125; //中断workers private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; //获取锁 mainLock.lock(); try &#123; //for循环关闭workers for (Worker w : workers) w.interruptIfStarted(); &#125; finally &#123; mainLock.unlock(); &#125; &#125;// 在gc之前调用线程池的shutdown()方法,释放相关资源 protected void finalize() &#123; shutdown(); &#125; interruptIdleWorkers方法，注意，这个方法打断的是闲置Worker，打断闲置Worker之后，getTask方法会返回null，然后Worker会被回收。怎么判断Worker是闲置呢？ 闲置Worker是这样解释的：Worker运行的时候会去阻塞队列拿数据(getTask方法)，拿的时候如果没有设置超时时间，那么会一直阻塞等待阻塞队列进数据，这样的Worker就被称为闲置Worker。由于Worker也是一个AQS，在runWorker方法里会有一对lock和unlock操作，这对lock操作是为了确保Worker不是一个闲置Worker。所以Worker被设计成一个AQS是为了根据Worker的锁来判断是否是闲置线程，是否可以被强制中断（而且这个锁还是一个不可重入锁，即独占锁）。 Java提供了那几种线程池在Java 的Executors类中有很多创建好的线程池。FixedThreadPool固定大小的线程池，SingleThreadExecutor只有一个线程的线程池，CachedThreadPool带有缓存功能的线程池，ScheduledThreadPool可以定时的线程池，SingleThreadScheduledExecutor只有一个线程并且可以定时的线程池，WorkStealingPool使用ForkJoin方式的线程池,unconfigurableExecutorService不可配置的线程池。 FixedThreadPool线程池 1234567891011121314//FixedThreadPool是一个指定固定大小的线程池，它在构造函数中指定了线程池的大小public static ExecutorService newFixedThreadPool(int nThreads) &#123; //这调用的是ThreadPoolExecutor的构造函数，指定基本线程和最大线程都是nThreads，空闲线程存活时间是0ms，一般如果不设置allowCoreThreadTimeOut，keepAliveTime不会对基本线程起作用。时间单位是ms。传入一个没有边界的阻塞队列 return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125;//可以自己指定ThreadFactory public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); &#125; SingleThreadExecutor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// SingleThreadExecutor 创建一个线程的线程池。当单一线程抛出异常停止时会在新建一个线程public static ExecutorService newSingleThreadExecutor() &#123; //包装一下线程池使他只能暴露ExecutorService的方法，而不能设置线程池的其他参数。这样的目的是为了让任务串行化执行，不会被设置线程池大小 return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; //只暴露ExecutorService方法的包装类 ExecutorService实现，这里使用了代理方法。 static class DelegatedExecutorService extends AbstractExecutorService &#123; private final ExecutorService e; DelegatedExecutorService(ExecutorService executor) &#123; e = executor; &#125; public void execute(Runnable command) &#123; e.execute(command); &#125; public void shutdown() &#123; e.shutdown(); &#125; public List&lt;Runnable&gt; shutdownNow() &#123; return e.shutdownNow(); &#125; public boolean isShutdown() &#123; return e.isShutdown(); &#125; public boolean isTerminated() &#123; return e.isTerminated(); &#125; public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException &#123; return e.awaitTermination(timeout, unit); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; return e.submit(task); &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; return e.submit(task); &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; return e.submit(task, result); &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; return e.invokeAll(tasks); &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; return e.invokeAll(tasks, timeout, unit); &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; return e.invokeAny(tasks); &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return e.invokeAny(tasks, timeout, unit); &#125; &#125; static class FinalizableDelegatedExecutorService extends DelegatedExecutorService &#123; FinalizableDelegatedExecutorService(ExecutorService executor) &#123; super(executor); &#125; protected void finalize() &#123; super.shutdown(); &#125; &#125; CachedThreadPool 1234567//创建一个带有缓存队列的线程池public static ExecutorService newCachedThreadPool() &#123; //基本线程数（corePoolSize）为0，最大线程数是Integer的最大值，keepAliveTime时间是60，单位是秒，它使用的是直接队列，会直接分配给工作线程，如果有空闲工作线程就直接复用，没有就会直接新建一个线程，不会阻塞。一个工作线程空闲60秒后会被回收 return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; ScheduledThreadPool 12345678910//创建一个可以定时的线程池,并指定线程池的大小public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125;//ScheduledThreadPoolExecutor 是继承ThreadPoolExecutor所以super方法就是ThreadPoolExecutor构造函数 public ScheduledThreadPoolExecutor(int corePoolSize) &#123; //可以指定线程池的基本大小。线程池最大值是integer 的最大值，他的keepAliveTime是0，时间单位是纳秒。队列是一个延时队列。可也设置时间参数。 super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); &#125; SingleThreadScheduledExecutor 123456//创建单一线程的线程池，并且可以定时执行任务。当单一线程抛出异常停止时会在新建一个线程public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; //这里创建的基本大小为1的定时线程池 return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); &#125; WorkStealingPool 12345678// 创建一个ForkJoin的线程池，也就是将好多任务分解多个任务后给多个线程执行，执行之后在汇总。Fork获取副本和copy类似这里感觉是Map过程，join合并和Reduce类似。public static ExecutorService newWorkStealingPool() &#123; //创建一个ForkJoin的线程池。获取可用处理器（CPU）的个数，为parallelism，获取线程创建工厂。handler，和模式是异步还是同步。 return new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); &#125; unconfigurableExecutorService 1234567//创建一个不可代理的线程池。public static ExecutorService unconfigurableExecutorService(ExecutorService executor) &#123; if (executor == null) throw new NullPointerException(); //传入一个线程池作为参数，然后包装一下，只暴露ExecutorService相关的接口，其他接口被隐藏不能被设置。 return new DelegatedExecutorService(executor); &#125; 线程池使用的注意问题1、建议使用有界队列，有界队列能增加系统的稳定性和预警能力，防止资源过度消耗，撑爆内存，使得系统崩溃不可用。2、提交到线程池的task之间要尽量保证相互独立，不能存在相互依赖，否则可能会造成死锁等其他影响线程池执行的原因。3、提交到的线程池的task不要又创建一个子线程执行别的任务，然后又将这个子线程任务提交到线程池，这样会造成混乱的依赖，最终导致线程池崩溃，最好将一个task用一个线程执行。 4、一般需要根据任务的类型来配置线程池大小： 如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 Num(CPU+1) 如果是IO密集型任务，参考值可以设置为2Num(CPU)* 当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 Java线程底层映射到操作系统原生线程，而且Java在windows和linux平台下，一个Java线程映射为一个内核线程，而内核线程和CPU物理核心数一样，所以Java线程和CPU核心是一对一的关系，将线程池的工作线程设置为与物理核心相等能做到真正的线程并发，如果设置线程数多于核心则会在核心线程之间不停的切换。 参考Java线程池ThreadPoolExecutor源码分析 线程池-ThreadPoolExecute源码分析]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树与数据结构]]></title>
    <url>%2F2017%2F12%2F16%2F%E6%A0%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[什么是数据结构在计算机科学中，数据结构（英语：data structure）是计算机中存储、组织数据的方式。数据结构可透过程序语言所提供的数据类型、引用及其他操作加以实现。一个设计良好的数据结构，应该在尽可能使用较少的时间与空间资源的前提下，支持各种程序运行。正确的数据结构选择可以提高算法的效率；不同种类的数据结构适合不同种类的应用。常用的数据结构有数组（Array），链表（Linked），队列（Queue），堆（Heap），栈（Stack），树（Tree），图（Graph），散列表（Hash）。 什么是树树（Tree）是一种抽象数据类型（ADT）或是这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由n（n&gt;0）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，它具有以下的特点：每个节点有零个或多个子节点；没有父节点的节点称为根节点；每一个非根节点有且只有一个父节点；除了根节点外，每个子节点可以分为多个不相交的子树；子树与子节点区别，子节点，指的是一个树上的一个节点，而子树指的是这个节点和包括属于这个节点的所有子节点，只有是叶子节点的时候，子树才等于子节点。 树的一些专业术语（概念）节点的度：一个节点含有的子树的个数称为该节点的度（该节点，有多少个子节点）； 树的度：一棵树中，最大的节点的度称为树的度（所有子节点中度数最大的那个节点的度数）； 叶子节点或终端节点：度为零的节点（也就是没有子节点的节点）； 非终端节点或分支节点：度不为零的节点； 父亲节点或父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点； 孩子节点或子节点：一个节点含有的子树的根节点称为该节点的子节点； 兄弟节点：具有相同父节点的节点互称为兄弟节点； 层次：从根开始定义起，根为第1层，根的子节点为第2层，以此类推； 深度：对于任意节点n,n的深度为从根到n的唯一路径长，根的深度为0，高度为整个树的高度； 高度：对于任意节点n,n的高度为从n到一片树叶的最长路径长，所有树叶（叶子节点）的高度为0； 堂兄弟节点：父节点在同一层的节点互为堂兄弟； 节点的祖先：从根到该节点所经分支上的所有节点； 子孙：以某节点为根的子树中任一节点都称为该节点的子孙。 森林：由m（m&gt;=0）棵互不相交的树的集合称为森林； 在图中A为根节点。A节点的度是2，因为他有B和C两个子树（子节点）。没有父亲节点，B和C是A的子节点（孩子节点），层次是第一层，深度是0，高度是4，可以说他是这个树上所有节点的祖先，其他节点都是他的子孙。 图中B节点是分支节点（非叶子节点，非终端节点），他的父节点是A，B与C是兄弟节点，他是第二层，深度是1，高度是三，D，E，F是他的子节点。 图中的F节点叶子节点（终端节点），他的父节点是B，兄弟节点是D和E，他是第三层，深度是2，高度是0（他是叶子节点，叶子节点高度为0），F与G和H是堂兄弟节点。 图中的M节点是分支节点，他的父节点是G，与L是兄弟节点，他是第第四层，深度是3，高度是1，兄弟节点是L，堂兄弟节点是I，J，N节点，子节点是O。 图中的节点K是叶子节点，他的父节点是I，的没有兄弟节点，他的堂兄弟节点是O和P，他的深度是4，高度是0，他是第五层 树的种类 无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树； 有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树； 一般在计算机中比较常用的都是有序树，因为有序树有个好处，就是查找速度比较快，可以根据顺序查找。也有很多应用的实例。有序树比较常用的有二叉查找树，霍夫曼树，B树。这里的B值指的是Balance平衡的意思，意味着，查找和插入的都很快的树。 二叉树（Binary Tree）：每个节点最多含有两个子树（子节点，分支）的树称为二叉树。通常分支被称作“左子树”和“右子树”。二叉树的分支具有左右次序，不能颠倒。二叉树的第i层，有$2^{i-1}$的节点个数，深度为K的二叉树至多有$2^{k+1}-1$的节点个数，定义根节$K_{0}$的深度为0；而总计拥有节点数匹配的，称为“满二叉树”。（所有叶节点都在最底层的完全二叉树）。对任何一棵非空的二叉树T，如果其叶片(终端节点)数为$n_0$，分支度为2的节点数为$n_2$，则$n_0 =n_2+1$。 对于一颗二叉树，假设其深度为d（d&gt;1）。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，（除了最底层其他层都是满的）； 一棵深度为k的二叉树，且有 $2^{k+1}-1$ 个节点的二叉树，称为满二叉树（Full Binary Tree）。若这种树的特点是每一层上的节点数都是最大节点数。而在一棵二叉树中，除最后一层外，若其余层都是满的，并且最后一层或者是满的，或者是在右边缺少连续若干节点，则此二叉树为完全二叉树（Complete Binary Tree）。具有n个节点的完全二叉树的深度为 $log_2n+1$。深度为k的完全二叉树，至少有$2^k$个节点，至多有$ 2^{k+1}-1$个节点。 完全二叉树：总结点树K，$2^{h-1}&lt;K&lt;2^h-1$,树的高度$h=log_2K+1$ 满二叉树：总结点$K=2^{h}-1$,树的高度$h=log_2(K+1)$ 如果要访问二叉树中的某一个节点，通常需要逐个遍历二叉树中的节点，来定位那个节点。它不象数组那样能对指定的节点进行直接的访问。所以查找二叉树的渐进时间是线性的 O(n)，在最坏的情况下需要查找树中所有的节点。也就是说，随着二叉树节点数量增加时，查找任一节点的步骤数量也将相应地增加。（这个时候二叉树不是有序树） 如果一个二叉树的查找时间是线性的，定位时间也是线性的，那相比数组来说到底哪里有优势呢？毕竟数组的查找时间虽然是线性 O(n)，但定位时间却是常量 O(1) 。的确是这样，所以普通的二叉树确实不能提供比数组更好的性能。然而，如果我们按照一定的规则来组织排列二叉树中的元素，就可以很大程度地改善查询时间和定位时间。 二叉查找树（Binary Search Tree），也称二叉搜索树、有序二叉树（ordered binary tree），排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树。1、若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值；2、若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值；3、任意节点的左、右子树也分别为二叉查找树；4、没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低为O(log n)。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构。二叉查找树的查找过程和其他二叉树差不多，有前序遍历，中序遍历，后序遍历。（其他树还有广度优先，和深度优先）。中序遍历二叉查找树可得到一个节点关键字（值）的有序序列（从小到大），一个无序序列可以通过构造一棵二叉查找树变成一个有序序列，构造树的过程即为对无序序列进行查找的过程。搜索、插入、删除的复杂度等于树高（存储的数据越多，树会越高），期望O(logn)，最坏O(n)（数列有序，树退化成线性表，他是十分依赖于树中节点的拓扑结构，也就是节点间的布局关系）。 排序（或称构造）一棵二叉查找树：用一组数值建造一棵二叉查找树的同时，也把这组数值进行了排序。其最差时间复杂度为$O(n^2)$。例如，若该组数值经是有序的（从小到大），则建造出来的二叉查找树的所有节点，都没有左子树。自平衡二叉查找树可以克服上述缺点，其时间复杂度为$O(nlog n)$。一方面，树排序的问题使得CPU Cache性能较差，特别是当节点是动态内存分配时。而堆排序的CPU Cache性能较好。另一方面，树排序是最优的增量排序（incremental sorting）算法，保持一个数值序列的有序性。 二叉查找树性能分析：每个结点的C~i~为该结点的层次数。最坏情况下，当先后插入的关键字有序时，构成的二叉查找树蜕变为单支树，树的深度为n，其平均查找长度为$\frac{n+1}2$（和顺序查找相同），最好的情况是二叉查找树的形态和折半查找的判定树相同，其平均查找长度和$log_2n$成正比。 二叉查找(搜索)树的遍历：对于线性的连续的数组来说，遍历数组采用的是单向的迭代法。从第一个元素开始，依次向后迭代每个元素。而 BST 则有三种常用的遍历方式：前序遍历（Perorder traversal）；中序遍历（Inorder traversal）；后序遍历（Postorder traversal）；当然，这三种遍历方式的工作原理是类似的。它们都是从根节点开始，然后访问其子节点。区别在于遍历时，访问节点本身和其子节点的顺序不同。 如图一个满二叉查找树： 前序遍历（Perorder traversal） 前序遍历从当前节点（节点 c）开始访问，然后访问其左孩子，再访问右孩子。开始时，节点 c 为 BST 的根节点。算法如下：1、访问节点 c；2、对节点 c 的左孩子重复第 1 步；3、对节点 c 的右孩子重复第 1 步； 则上图中树的遍历结果为：90, 50, 20, 5, 25, 75, 66, 80, 150, 95, 92, 111, 175, 166, 200。 中序遍历（Inorder traversal） 中序遍历是从当前节点（节点 c）的左孩子开始访问，再访问当前节点，最后是其右节点。开始时，节点 c 为 BST 的根节点。算法如下：1、访问节点 c 的左孩子；2、对节点 c 重复第 1 步；3、对节点 c 的右孩子重复第 1 步。 则上图中树的遍历结果为：5, 20, 25, 50, 66, 75, 80, 90, 92, 95, 111, 150, 166, 175, 200。(从小到大排序) 后序遍历（Postorder traversal） 后序遍历首先从当前节点（节点 c）的左孩子开始访问，然后是右孩子，最后才是当前节点本身。开始时，节点 c 为 BST 的根节点。算法如下：1、访问节点 c 的左孩子；2、对节点 c 的右孩子重复第1 步；3、对节点 c 重复第 1 步； 则上图中树的遍历结果为：5, 25, 20, 66, 80, 75, 50, 92, 111, 95, 166, 200, 175, 150, 90。 遍历时候都是用递归去实现的，一般会使用组合设计模式来实现树。 二叉查找(搜索)树的插入与删除： 当向树中插入一个新的节点时，该节点将总是作为叶子节点(终端节点)。所以，最困难的地方就是如何找到该节点的父节点。类似于查找算法中的描述，我们将这个新的节点称为节点 n，而遍历的当前节点称为节点 c。开始时，节点 c 为 二叉搜索树（BST） 的根节点。则定位节点 n 父节点的步骤如下：(三个节点很重要。遍历当前节点c，遍历当前节点的父节点m，要插入的节点n) 1、如果节点 c 为空，则节点 c 的父节点将作为节点 n 的父节点。如果节点 n 的值小于该父节点的值，则节点 n 将作为该父节点的左子节点（左孩子节点）；否则(大于父节点的值)节点 n 将作为该父节点的右子节点(右孩子节点)。 2、如果c节点有值，比较节点 c 与节点 n 的值。 如果节点 c 的值与节点 n 的值相等，则说明用户在试图插入一个重复的节点。解决办法可以是直接丢弃节点 n，或者可以抛出异常。 如果节点 n 的值小于节点 c 的值，则说明节点 n 一定是在节点 c 的左子树中。则将父节点m设置为节点 c，并将节点 c 设置为节点 c 的左子节点（左孩子节点），然后返回至第 1 步。 如果节点 n 的值大于节点 c 的值，则说明节点 n 一定是在节点 c 的右子树中。则将父节点m设置为节点 c，并将节点 c 设置为节点 c 的右子节点（右孩子节点），然后返回至第 1 步。 当合适的节点找到时，该算法结束。从而使新节点被放入二叉搜索树中成为某一父节点合适的孩子节点 BST 的插入算法的复杂度与查找算法的复杂度是一样的：最佳情况是$O(log­_2n)$，而最坏情况是 O(n)。因为它们对节点的查找定位策略是相同的。这种插入操作一般都使用递归去实现。 从 二叉搜索树中删除节点比插入节点难度更大。因为删除一个非叶子节点，就必须选择其他节点来填补因删除节点所造成的树的断裂。如果不选择节点来填补这个断裂，那么就违背了 BST 的性质要求。删除节点算法的第一步是定位要被删除的节点，这可以使用前面介绍的查找算法，因此运行时间为 $O(log­_2n)$。如果没有子节点是叶子节点，直接删除，如果有子节点，应该选择合适的节点来代替删除节点的位置，它共有三种情况需要考虑。 情况 1：如果删除的节点没有右子节点（右孩子节点），那么就选择它的左子节点（左孩子节点）来代替原来的节点（要删除的节点）。二叉查找树的性质保证了被删除节点的左子树必然符合二叉查找树的性质。因此左子树的值要么都大于，要么都小于被删除节点的父节点的值，这取决于被删除节点是左孩子还是右孩子。因此用被删除节点的左子树来替代被删除节点，是完全符合二叉搜索树的性质的。（其实如果删除节点没有左子节点也可以用右子节点去代替。有一个孩子删除节点：删除节点并将其替换为其子节点） 情况 2：如果被删除节点的右子节点（右孩子节点）没有左孩子节点，那么这个右子节点被用来替换被删除节点。因为被删除节点的右子节点都大于被删除节点左子树的所有节点，同时也大于或小于被删除节点的父节点，这同样取决于被删除节点是左子节点还是右子节点。因此，用右子节点来替换被删除节点，符合二叉查找树的性质。 情况 3：如果被删除节点的右子节点有左孩子节点，就需要用被删除节点右子节点的左子树中的最下面的节点来替换它，就是说，我们用被删除节点的右子树中最小值的节点来替换。 自平衡二叉树（(Balanced Binary Tree）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树；是一种结构平衡的二叉搜索树，即叶节点深度差不超过1，它能在$O(log n)$内完成插入、查找和删除操作，最早被发明的平衡二叉搜索树为AVL树，后续的有红黑树，树堆（Treap），伸展树。平衡二叉查找树是二分查找的一种算法实现。 AVL树：AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为1，所以它也被称为高度平衡树。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。AVL树得名于它的发明者(G. M. Adelson-Velsky和E. M. Landis)查找、插入和删除在平均和最坏情况下的时间复杂度都是 $O(logn)$。也就是每次修改改树就进行AVL翻转，实现平衡。节点的平衡因子是它的左子树的高度减去它的右子树的高度（有时相反）。所以带有平衡因子1、0或 -1的节点被认为是平衡的。带有平衡因子 -2或2的节点被认为是不平衡的，并需要重新平衡这个树。平衡因子可以直接存储在每个节点中，或从可能存储在节点中的子树高度计算出来。 失去平衡后进行的规律可归纳为下列四种情况： 单向右旋平衡处理LL：由于在a的左子树根节点的左子树上插入节点，a的平衡因子由1增至2，致使以 a为根的子树失去平衡，则需进行一次右旋转操作；（左左） 单向左旋平衡处理RR：由于在a的右子树根节点的右子树上插入节点，a的平衡因子由-1变为-2，致使以a为根的子树失去平衡，则需进行一次左旋转操作；（右右） 双向旋转（先左后右）平衡处理LR：由于在a的左子树根节点的右子树上插入节点，a的平衡因子由1增至2，致使以a为根的子树失去平衡，则需进行两次旋转（先左旋后右旋）操作。（左右） 双向旋转（先右后左）平衡处理RL：由于在a的右子树根节点的左子树上插入节点，a的平衡因子由-1变为-2，致使以a为根的子树失去平衡，则需进行两次旋转（先右旋后左旋）操作。（右左） AVL的四种翻转，也可说是AVL调平，一般都是用递归实现。 红黑树：红黑树（Red–black tree）是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。它是在1972年由鲁道夫·贝尔发明的，他称之为”对称二叉B树”，它是复杂的，但它的操作有着良好的最坏情况运行时间，并且在实践中是高效的：它可以在 $O(logn)$时间内做查找，插入和删除，这里的 n是树中元素的数目。他和AVL树不一样的地方就是他们自平衡的方式一样。也可以是他们保证自己是完全二叉树的策略不一样。因为只有在完全二叉树的情况下才能保证树的效率。红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保logn。这不只是使它们在时间敏感的应用如实时应用（real time application，即时计算）中有价值，而且使它们有在提供最坏情况担保的。同时也为其他数据结构中作为基础，也就是其他的数据结构有红黑树。比如Java的HashMap中，当冲突导致后面链表过长，当长度超过8个的时候，就会把链表转换成红黑树；红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。 红黑树的性质：红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求。1、节点是红色或黑色；2、根是黑色（这个规则有时被省略。由于根可以总是从红色变为黑色，但不一定反之，这个规则对分析影响不大）；3、所有叶子都是黑色（叶子是NIL节点）；4、每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点）；5、从任一节点到其每个叶子（NIL）的所有简单路径都包含相同数目的黑色节点；从根节点到节点的黑色节点的数量是节点的黑色深度 ; 从根到叶的所有路径中统一的黑色节点数称为红黑树的黑色高度 红黑树的5条特性确保了从根到叶子的最长的可能路径不多于最短的可能路径的两倍长，使得整棵树大致上是平衡的。树上的增删改查操作的最坏情况时间都与树的高度成正比，所以红黑树在最坏情况下也是高效的。在红黑树中一般用黑的NIL节点表示叶节点，不包含值，只是标志该分支结束，有时候绘图中会直接省略。导致了这些树好像同上述原则相矛盾，而实际上不是这样。是所有节点都有两个子节点，尽管其中的一个或两个可能是空叶子。 关于红黑树在插入和删除： 红黑树的插入和删除其实和上面BTS很类似，只不过就是在上面插入和删除的之后要对颜色进行判断然后对树进行翻转实现平衡，也可以说红黑树的插入和删除是建立在二叉搜索树之上的。所以红黑树的插入和查找维护起来相对复杂，但是他调整的次数少，其实红黑树不是严格的平衡二叉树。 因为每一个红黑树也是一个特殊化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再匹配红黑树的性质。恢复红黑树的性质需要少量$O(log n)$的颜色变更（实际是非常快速的）和不超过三次树旋转（对于插入操作是两次）。虽然插入和删除很复杂，但操作时间仍可以保持为$O(logn)$次 插入首先以与标准二叉搜索树插入非常相似的方式添加节点，并将其着色为红色（也就是只要是插入的N节点就是红色）。最大的区别在于二叉查找树中新增了一个节点作为叶子，而叶子在红黑树中不包含任何信息，所以新的节点替换了现有叶子，然后增加了两个自己添加的黑叶子。接下来发生什么取决于其他附近节点的颜色。有几个红黑树插入案件处理：(N是要新插入的节点，P是N的父节点，U是N的叔叔节点即不父节点的兄弟节点) N是根节点，即红黑树的第一个节点 N的父母（P）是黑色的 P是红色的（所以它不能是树的根），而N的叔叔（U）是红色的 P是红色的，U是黑色的 插入时注意：属性1（每个节点都是红色或黑色）和属性3（所有叶子都是黑色的）始终成立。属性2（根部是黑色）通过第一种情况进行检查和纠正。属性4（红色节点只有黑色子节点）只会通过添加红色节点，从黑色到红色重新绘制节点或旋转来威胁。属性5（从任何给定节点到其叶节点的所有路径具有相同数量的黑节点）仅受到添加黑节点，重绘节点或旋转的威胁。 当前节点N在树的根部。在这种情况下，为了满足属性2（根部是黑色），将其重新涂成黑色。由于这会一次向每条路径添加一个黑色节点，属性5（从给定节点到其叶节点的所有路径都包含相同数量的黑色节点）不会被违反。 当前节点的父P是黑色的，所以属性4（每个红色节点的子节点都是黑色的）不会失效。在这种情况下，树仍然有效。属性5（从任何给定节点到其叶节点的所有路径都包含相同数量的黑节点）没有受到威胁，因为当前节点N有两个黑色叶子节点，但是因为N是红的，通过其每个孩子的路径黑色节点的数量与通过它所替换的叶子的路径数量相同，这是黑色的，所以这个属性保持满意。（换句话说就是什么都不用做） 如果父节点P和父母U都是红色的，那么他们都可以被重新粉刷成黑色，并且祖父节点G变成红色来维护属性5（从给定节点到其叶子节点的所有路径都包含相同数量的黑色节点）。由于通过父节点或叔父节点的任何路径都必须经过祖父母，所以这些路径上的黑色节点的数目没有改变。然而，祖父G现在可能违反了属性2（根是黑色的，G可能是根），如果它是根或属性4（每个红色节点的子女都是黑色的），如果它有一个红色的父节点。为了解决这个问题，树上的红黑修复程序重新运行在G上。（把G当成是新加入的节点进行各种情形的检查）请注意，这是一个尾递归调用（java里没有尾递归，所以这里及时递归），所以它可以被重写为一个循环。由于这是唯一的循环，并且在该循环之后发生任何旋转，这证明发生了恒定数量的旋转。 父节点P是红色，但叔父节点U是黑色。步骤1：最终目标是将父节点旋转到祖父节点位置，但是如果当前节点位于G子树的“内部” （如果N是子节点的右子节点的左子节点祖父节点或祖父节点的左子节点的正确节点，这里很绕）。在这种情况下，可以执行在P上左转以切换当前节点N和其父节点P的角色。旋转导致一些路径（子树中标记为“1”的路径）通过节点N.他们以前没有。它也会导致一些路径（子树中标记为“3”的路径）不能通过之前做过的节点P. 但是，这两个节点都是红色的，所以属性5（从任何给定节点到其叶节点的所有路径都包含相同数量的黑色节点）不会受到旋转的影响。在这一步完成之后，属性4（每个红色节点的孩子都是黑色的）仍然被违反，但是现在我们可以通过继续步骤2来解决这个问题。 步骤2：当前节点N现在肯定位于G下的子树的外部（P的左子节点或右子节点）。在这种情况下，执行G上的右旋转。结果是前一个父节点P现在是当前节点N和前一个祖父G的父节点的父节点。G是已知的黑色，因为它的前孩子P不可能是红色而不违反属性4 。一旦P节点和G节点的颜色得到的树满足属性4（每个红色节点的子节点都是黑色的）。属性5（从任何给定节点到它的叶节点的所有路径包含相同数量的黑色结点）也就满意，因为通过这三个节点中任何一个的所有路径以前都通过祖父节点G，现在它们都通过以前的父节点P。在各自的情形下，这都是三个节点中唯一的黑色节点。 在上面的算法中，除了情况3外，所有情况都只被调用一次，在情况3中，可以使用祖父节点递归回到情况1，这是迭代实现将有效循环的唯一情况。因为修复的在这种情况下，问题被上报每次更高两个级别，它需要最大限度h/ 2次迭代来修复树（其中h是树的高度）。由于升级的概率随着每次迭代呈指数下降，所以平均插入成本实际上是恒定的。（上述图中的1,2,3,4,5指的都是子树，而不是叶子节点） 节点的删除：同样，红黑树的删除也是基于二叉搜索树的删除。也是在二叉搜索树删除后进行红黑调整，使整棵树处于红黑平衡，也就是符合上面的5个属性。所以删除要比插入相对麻烦。当二叉搜索树要删除一个节点(非叶子结点，不过红黑树的叶子节点都是null也没有意义)的时候，他会选择其他节点的填补。(这样的填补就打乱原来红黑顺序)，所以下面讲的是删除完修复整个红黑树的过程。下面就在简单回顾一下二叉搜索树的删除过程，1、如果是叶子节点直接删除；2、如果删除节点D只有一个子节点，那么用那个子节点去代替（这样就会出现红黑不平衡，如果删除节点的父节点是红色，那么删除节点D的子节点也是红色，违背属性4）；3、如果删除节点D有两个子节点，那么删除就要进行左旋或者右旋。也就是说D节点不是被删除而是被其他节点覆盖（代替了）。 我们在BST中执行标准的删除操作时，我们总是删除一个叶子节点或者只有一个子节点，剩下的都是用递归去搞定（对于一个内部节点，我们复制后继节点，然后递归地调用删除作为后继节点，后继节点在被后继节点的后继节点代替，后继节点总是一个叶节点，或者有一个子节点的节点，然后结束递归）。所以我们只需要处理一个节点是叶子还是有一个子节点的情况。假设C是要删除的节点，并且是替换C的子节点（请注意，当C是叶子节点，NIL的颜色被视为黑色时） 我们首先把要删除的节点替换为它的子节点。出于方便，称呼这个子节点为N（在新的位置上），称呼它的兄弟节点S（它父亲的另一个子节点）。在下面的示意图中，我们还是使用P称呼N的父节点，S~L~称呼S的左子节点，S~R~称呼S的右子节点。在情形2、5和6下，我们假定N是它父节点P的左儿子。如果它是右儿子，则在这些情形下的左右应当对调。 如果删除的是根节点C，那么代替原来根节点的节点也是黑色的节点S，在这种情况下。我们从每个路径中删除一个黑色节点，新的黑色根节点保留属性，树的高度减1。（情况1） 删除完节点C，替换的节点是黑色的N。节点P是黑色，兄弟节点S是红色，S节点的子节点是黑色的。所以要对P为根节点的整个树做左旋转，把红色兄弟节点S转换成N的祖父节点，我们接着对调N的父节点P和祖父节点S的颜色。完成这两个操作后，尽管所有路径上黑色节点的数目没有改变，但现在N有了一个黑色的兄弟和一个红色的父亲（它的新兄弟节点S~R~是黑色，它是原来红色节点S的一个子节点），剩下的我们可以接下去按情况4，情况5或情况6来处理。（情况2）这里的图中没有显示出来，N是删除了黑色节点后替换上来的子节点，所以这个过程中由P-&gt;X-&gt;N变成了P-&gt;N，实际上是少了一个黑色节点，也可以理解为P(Parent,Black)和S(Silbing,Red)那么他们的孩子黑色节点的数目肯定不等，让他们做新兄弟肯定是不平衡的，还需后面继续处理。就是情况4。 删除完节点C，节点P，节点S和节点S的子节点是黑色的。在这种情况下，我们重新绘制节点S为红色。结果是所有通过S的路径，正好是那些不经过N的路径，有一个黑色节点。因为删除N的原始父节点使得所有经过N的路径都有一个黑节点。然而，通过P的所有路径现在比没有经过P的路径少一个黑节点，所以属性5（从任何给定节点到其叶节点的所有路径包含相同数量的黑节点）仍然被违反。为了纠正这一点，我们在P上执行重新平衡程序，从情况1开始。（情况3） 节点S和S的子节点都是黑色，但是N的父节点是红色。在这种情形下，我们简单的交换N的兄弟节点和父节点的颜色。这不影响不通过N的路径的黑色节点的数目，但是它在通过N的路径上对黑色节点数目增加了1，添补了在这些路径上被删除的黑色节点。（应对前面情况2中的问题） 经过上面的旋转，N的兄弟节点S是黑色，S的左子节点是红色，S的右子节点是黑色，而N是它父节点的左子节点，也就是P的右子节点。在这种情形下我们在S节点为根节点做右旋转，这样S的左子节点S~L~成为S的父节点和N节点的新兄弟节点。我们接着交换S和它的新父节点的颜色。所有路径仍有同样数目的黑色节点，但是现在N有了一个黑色兄弟，他的右子节点是红色的。（情况5）所以我们进入了情形6。N节点和它的父节点P都不受这个变换的影响。 节点 S是P节点右子节点黑色，S的右子节点是红色S~R~，N是其父节点P的左子节点。在这种情况下，我们在P处向左旋转，S成为P和S的右子节点的父节点。然后我们交换P和S的颜色，让S的右子节点变黑色。该子树的根目录仍然具有相同的颜色，所以属性4（每个红色节点的子节点都是黑色的）和5（从任何给定节点到它的叶节点的所有路径都包含相同数量的黑色节点）不被违反。然而，N现在又增加了一个黑色的祖先：P变成了黑色，或者是黑色的，S被加入了黑色的祖父母。因此，通过N的路径通过一个附加的黑色节点。然而，如果一条路径不经过N，那么有两种可能性：它通过N的新兄弟节点。那么它以前和现在都必定通过S和N的父亲，而它们只是交换了颜色。所以路径保持了同样数目的黑色节点。 它通过N的新叔父节点，S的右子节点。那么它以前通过S、S的父亲和S的右节点，但是现在只通过S，它被假定为它以前的父亲的颜色，和S的右子节点，它被从红色改变为黑色。合成效果是这个路径通过了同样数目的黑色节点。无论哪种方式，这些路径上的黑色节点的数量不会改变。因此，我们已经恢复属性4（每个红色节点的孩子都是黑色的）和5（从给定节点到其叶节点的所有路径包含相同数量的黑色节点）。图中的白色节点可以是红色或黑色，但在转换之前和之后必须指向相同的颜色。 哈夫曼树：(Huffman Tree)哈(霍)夫曼树又称最优二叉树，是一种带权路径长度最短的二叉树。所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度（高度），树的路径长度是从树根到每一结点的路径长度之和。（若根结点为0层，叶结点到根结点的路径长度为叶结点的层数）。树的路径长度是从树根到每一结点的路径长度之和，记为WPL=（W1L1+W2L2+W3L3+…+WnLn，N个权值Wi（i=1,2,…n）构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为Li（i=1,2,…n）。可以证明霍夫曼树的WPL是最小的。哈夫曼树是从低到上去创建的，不是从根节点，到叶子节点去创建的。最早哈夫曼树，使用来做压缩编码的，也就是哈(霍)夫曼编码，它根据出现的频率来规定编码的长度。出现频率越高的使用的编码长度越短，使用频率越低编码长度越长。是一种用于无损数据压缩的熵编码（权编码）算法。 哈夫曼树的构造（哈夫曼算法的实现） 1、将每个元素依照出权重（出现频率）由小排到大； 2、将最小的两个元素权重（频率）相加合成一个新的节点（新节点的权重等于之前两个节点权重之和）； 3、比较新节点和其他节点权重，仍然找出权重最小的2个点合并； 4、重复上面2个步骤，直到没有可以比较的对象； 5、最后产生的树状图就是哈(霍)夫曼树。 哈夫曼树的特点 1、满二叉树不一定是哈夫曼树 ； 2、哈夫曼树中权越大的叶子离根越近 （很好理解，WPL最小的二叉树） 3、具有相同带权结点的哈夫曼树不惟一 4、哈夫曼树的任何结点的度数为 0 或 2， 没有度为 1 的结点。（都是两个相加之后形成的节点，子节点所以不会有存在1个） 5、包含 n 个叶子结点的哈夫曼树中共有$2n – 1$ 个结点（包括根节点）。 6、包含 n 棵树的森林要经过 n–1 次合并才能形成哈夫曼树，共产生 n–1 个新结点 哈夫曼树的构建过程 权重{2,3,4,4,5,7} 节点演算过程 1、根据节点权重排序{2,3,4,4,5,7} 2、将最小的两个节点也就是节点1，和节点2相加得到新节点，新节点权重是5，现在节点权重是{4,4,5,5,7}（循环） 3、将小的两个节点也就是节点1，和节点2相加得到新的节点，新节点的权重是8，现在的节点重{5,5,7,8}（循环） 4、将小的两个节点也就是节点1，和节点2相加得到新的节点，新节点的权重是8，现在的节点权重{7,8,10}（循环） 5、将小的两个节点也就是节点1，和节点2相加得到新的节点，新节点的权重是8，现在的节点权重{10,15}（循环） 6、将小的两个节点也就是节点1，和节点2相加得到新的节点，新节点的权重是8，现在的节点权重{25}（循环） 7、构建哈夫曼树结束 B-树：B树(B-Tree)是一种自我平衡的树型数据结构，它保持数据的排序并允许在对数时间内进行搜索，顺序访问，插入和删除操作。B树是一个二叉搜索树的泛化，一个节点可以有两个以上的孩子。与自平衡二叉搜索树不同，B-树针对读取和写入大块数据的系统进行了优化。B树是外部存储器(硬盘)数据结构的一个很好的例子。它通常用于数据库和文件系统。(Rudolf Bayer和Ed McCreight于1971年在波音研究实验室工作时发明了B-树)，这两个没有解释B是什么意思，有人说是B代表波音，也有人说这是拜尔的意思。不过区分一下二叉树（Binary Tree）就可以。个人感觉叫拜尔树好一点。插入，删除，搜索复杂度平均$O(logn)$，最坏是$O(logn)$。空间是$O(n)$ 在B树中，内部（非叶）节点可以在一些预定义的范围内具有可变数目的子节点。当数据插入或从一个节点中删除时，其子节点的数量会发生变化。为了保持预定义的范围，内部节点可以被连接或拆分(根据关键字)。由于许多子节点空是允许的，所以B树不需要像其他自平衡搜索树一样频繁地重新平衡，但是由于节点并不是完全满的，所以可能会浪费一些空间(空间换时间)。子节点数量的下限和上限对于特定的实现通常是固定的，一般是$d+1$到$2d+1$之间，但是也有固定的例如2-3树(也是最小的B-树)。这里d指的是关键字。 键：键(keys)也有人说这个是关键字的，B树的每个内部节点都包含一些键。这些键（分离值）用来分割它们的子树。例如，如果一个内部节点具有3个的子节点（或子树），则它必须有2个键：A1和A2，A1&lt;A2。在最左边的子树的所有值将小于A1，在中间子树的所有值将是之间A1和A2，并且在最右边的子树的所有值将大于A2。 B树中每一个内部节点会包含一定数量的键值。通常，键值的数量被选定在d和2d之间。在实际中，键值占用了节点中大部分的空间，所以一般节点都会要被填满一半以上。而因数2(也就是2d的2)是保证该节点(内部节点，分支节点，非终端节点)可以被拆分或者组合。如果一个内部节点有 2d个键，添加一个键给此节点的过程（整个是$2d+1$键），将会把2d键拆分为2个有d个键的节点，并把中间的键添（因为是从小到大排序的，把$d+1$的键为中间键）加给父节点。每一个拆分的节点都拥有最小数目的键d个。相似地，如果一个内部节点和他的邻居两者都有d个键，将通过它与邻居的合并来删除一个键。删除此键值将导致此节点拥有d-1个键;与邻居的合并则加上 d个键（此时当前节点是$2d-1$个键），再加上从邻居节点的父节点移来的一个键(填充在中间一半是d-1，或者d+1的位置)。结果为完全填充的2d个键。 B树通过要求所有叶节点处于相同深度而保持平衡。随着元素被添加到树中，该深度将会缓慢增加，但整体深度的增加并不频繁，结果导致所有叶子节点与根节点距离加1（分支节点多一个键或者关键字）。 B-树又叫平衡多路查找树。一棵N阶的B-树 (切勿简单的认为一棵N阶的B树是N叉树)的特性如下： 树中每个结点最多含有m个孩子（m&gt;=2）； 除根结点和叶子结点外，其它每个结点至少有$ceil(m / 2)$个子节点或子树（其中$ceil(x)$是一个取上限的函数）； 根结点至少有2个孩子（除非B树只包含一个结点：根结点）； 所有叶子结点都出现在同一层，叶子结点不包含任何键信息(可以看做是外部结点或查询失败的结点，指向这些结点的指针都为null)；（注：叶子节点只是没有孩子和指向孩子的指针，这些节点也存在，也有元素。类似红黑树中，每一个NULL指针即当做叶子结点，只是没画出来而已）。 k个子节点的非叶节点包含k -1个键， (n，P0，K1，P1，K2，P2，……，Kn，Pn)。其中： a) Ki (i=1…n)为键，且键按顺序升序排序K(i-1)&lt; Ki。b) Pi为指向子树根的结点，且指针P(i-1)指向子树种所有结点的键均小于Ki，但都大于K(i-1)。c) 键的个数n必须满足：$ (ceil(m / 2)-1)&lt;= n &lt;= m-1$。比如有j个孩子的非叶结点恰好有j-1个键(m为子节点或者子树个数)。 B-树的高度 设h是经典B树的高度。设n &gt; 0是树中节点的数量。让m是孩子的节点可以具有的最大数量。每个节点最多可以有m -1个键。 可以证明（通过上面的例子），该高度的B树ħ以其所有节点完全填充具有$n= m^{h+1} -1$的条目。因此，B树的最佳情况高度是：$h&gt;=log_m(n+1)-1$，满二叉树的m=2。相同数量节点，高度最低，查询效率最高，插入会导致树变动。 让d内部（非根）节点可以拥有的最小子数，也就是拥有$ceil(m / 2)$子节点或子树,$d=(m/2)。n=2(d^{h+1})-1$，因子2代表只有一办的值中有子节点或者子树，其他的没有被填满。所以要在原来的基础上乘2才能实现满B-树中n的数量，让等式成立。所以$h&lt;=log_d(\frac{(n+1)}{2})-1$，也就是所有内部节点，都只有一半子节点或者子树。这样会导致整个树的高度增高，降低查询效率，但增加了插入的效率。 B树用于数据库优点：保持按键顺序遍历排序；使用分层索引来减少磁盘读取次数；使用部分满块来加速插入和删除；用递归算法保持索引平衡；此外，通过确保内部节点至少满一半，B树可以最大限度地减少浪费。B树可以处理任意数量的插入和删除操作。 已排序文件的查找时间：通常，排序和查找算法会被通过大O符号，刻画为比较级别的数值。对一个有N笔记录的已排序表进行二叉查找，打个比方说，可以在$O（log_2N）$比较级完成。如果表有1,000,000笔记录,那么定位其中一笔记录，将在20 个比较级内完成。 $log_21,000,000 = 19.931…$ 大数据库一直以来被存储在磁盘。从磁盘上读取一笔记录，与之后的比较键值操作相比，在花费的运行时间上前者处于支配地位。从磁盘读取记录的时间涉及到一个 寻道时间 和 旋转延迟。寻道时间可能是从0到20或者更多毫秒，旋转延迟平均下来约是旋转周期的一半。对于一个7200 转每分钟的磁盘，旋转周期大约是8.33毫秒。像希捷ST3500320NS这样的磁盘,磁道至磁道的寻道时间为 0.8毫秒，平均读取寻道时间为8.5毫秒。为了简化，假设从磁盘读取花费10毫秒。乐观来说，如此，在一百万中定位一笔记录将会话花费20次磁盘读取乘上10毫秒每次读取时间，总共是0.2秒。时间花费没有那么糟糕的原因是，独立的记录被成组地记录在磁盘块上。一个磁盘块可能为16 千字节。如果每笔记录大小为160 字节，那么一个块可以存储100 笔记录。上面假设的磁盘读取时间确切地说是读取一个完整块的时间。一旦磁头到达位置，一个或者更多的磁盘块可以以较小的延迟来完成读取。对于100笔记录每块，最后差不多6个比较级是不需要任何磁盘读取的都在上次读取操作中完成了。 B树总结：B树就是，有序数组+平衡多叉树(每个非叶子节点都是一个数组)；顺便说一句，由于根或者树的上面几层被反复查询，所以这几块可以存在内存中，换言之，B树的根结点和部分顶层数据在内存中，大部分下层数据在磁盘上。保持键值有序，以顺序遍历使用层次化的索引来最小化磁盘读取，使用不完全填充的块来加速插入和删除，通过优雅的遍历算法来保持索引平衡。另外，B树通过保证内部节点至少半满来最小化空间浪费。一棵B树可以处理任意数目的插入和删除。 伸展树（Splay Tree）：是一种二叉查找树，它能在$O(log n)$内完成插入、查找和删除操作。在伸展树上的一般操作都基于伸展操作：假设想要对一个二叉查找树执行一系列的查找操作，为了使整个查找时间更小，被查频率高的那些条目就应当经常处于靠近树根的位置。于是想到设计一个简单方法， 在每次查找之后对树进行调整，把被查找的条目搬移到离树根近一些的地方。伸展树应运而生。伸展树是一种自调整形式的二叉查找树，它会沿着从某个节点到树根之间的路径，通过一系列的旋转把这个节点搬移到树根去。它的优势在于不需要记录用于平衡树的冗余信息。 优点：可靠的性能，它的平均效率不输于其他平衡树；存储所需的内存少，伸展树无需记录额外的什么值来维护树的信息，相对于其他平衡树，内存占用要小；查找和更新算法概念简单，易于实现。 缺点：伸展树最显著的缺点是它有可能会变成一条链。这种情况可能发生在以非降顺序访问n个元素之后。然而均摊的最坏情况是对数级$O(log n)$；它们需要更多的局部调整，尤其是在查找期间。（那些有明确限制的数据结构仅需在更新期间进行调整，查找期间则不用）；一系列查找操作中的某一个可能会耗时较长，这在实时应用程序中可能是个不足之处。 树堆（Treap）：是有一个随机附加域满足堆的性质的二叉搜索树，其结构相当于以随机数据插入的二叉搜索树。其基本操作的期望时间复杂度为 $O(logn)$。相对于其他的平衡二叉搜索树，Treap的特点是实现简单，且能基本实现随机平衡的结构。Treap=Tree+Heap。Treap本身是一棵二叉搜索树，它的左子树和右子树也分别是一个Treap，和一般的二叉搜索树不同的是，Treap纪录一个额外的数据，就是优先级。Treap在以关键码构成二叉搜索树的同时，还满足堆的性质。Treap维护堆性质的方法用到了旋转，只需要两种旋转，编程复杂度比Splay要小一些。 插入节点：给节点随机分配一个优先级，先和二叉搜索树的插入一样，先把要插入的点插入到一个叶子上，然后跟维护堆一样，如果当前节点的优先级比根大就旋转，如果当前节点是根的左儿子就右旋如果当前节点是根的右儿子就左旋。由于旋转是 $O(1)$的，最多进行h次（h是树的高度），插入的复杂度是 O(h)的，在期望情况下 $h=O(log n)$，所以它的期望复杂度是 $O(logn)$，最坏的情况下$O(n)$。 删除节点：因为Treap满足堆性质，所以只需要把要删除的节点旋转到叶节点上，然后直接删除就可以了。具体的方法就是每次找到优先级最大的儿子，向与其相反的方向旋转，直到那个节点被旋转到了叶节点，然后直接删除。删除最多进行$ O(h)$次旋转，期望复杂度是 $O(logn)$，最坏的情况下$O(n)$。 查找：和一般的二叉搜索树一样，但是由于Treap的随机化结构，Treap中查找的期望复杂度是 $O(logn)$，最坏的情况下$O(n)$。 堆(heap)：堆是被称为优先级队列的抽象数据类型的最高效实现，事实上，优先级队列通常被称为“堆”，而不管它们如何实现。堆的常见实现是二进制堆，其中树是二叉树（父节点的优先级大于子节点的优先级）。堆数据结构，特别是二进制堆，由Williams于1964年引入，作为堆排序算法的数据结构 跳表（和树差不多的性能的数据结构）跳跃链表：（SkipList）是一种数据结构，允许快速查询一个有序连续元素的数据链表。快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集。基于并联的链表，其效率可比拟于二叉查找树（对于大多数操作需要$O(log n)$平均时间）。 跳跃链表是允许在有序元素列表内快速搜索的数据结构。通过子链表保持链接的层次结构，可以快速搜索，每个连续的子序列链表少于前一个的元素列表。搜索从最稀疏的子链表开始，通过小于，大于或等于搜索的元素，直到找到两个连续的元素。通过链接的层次结构，这两个元素链接到下一个稀疏的子链表的元素，在那里继续搜索直到最后我们搜索完整个链表。 跳跃链表数据结构的示意图。每个带有箭头的框表示一个指针，一行是一个给出稀疏子序列的链表 ; 底部的数字框（黄色）表示有序的数据链表。搜索从最上面的子子链表向下进行，直到找到包含搜索元素的连续元素。 跳跃列表是按层建造的。底层是一个普通的有序链表。每个更高层都充当下面列表的“快速跑道”，这里在层 i 中的元素按某个固定的概率 p (通常为0.5或0.25)出现在层 i+1 中。平均起来，每个元素都在$\frac{1}{1-p}$ 个列表中出现，而最高层的元素（通常是在跳跃列表前端的一个特殊的头元素）在$ O(log_{1/p}n)$ 个列表中出现。 跳过列表是一种概率数据结构，似乎可能取代平衡树作为许多应用程序的实现方法。跳过列表算法具有与平衡树相同的渐近期望时间界限，并且更简单，更快速并且使用更少的空间。 总结树是一种非常常用的数据结构，它在很多地方可以用到上，一般情况下，树都是有序的，因为有序才有意义。例如二叉搜索树，大多数树都是这种树的变种，可以自动平衡（因为平衡之后效率才高），自平衡二叉树是折半查找算法的一种实现方式，包括跳表也可以实现，所以对于查找很快，比如红黑树，AVL树。但是同样的因为查找很快，因为有序所以就要去维护，所以插入和查找就会变得很复杂。每次都要对树进行旋转，特别树的高度越高数据量越多维护成本就越高。所以这个时候就出现了B树，B+，B*树。他们通过冗余（留出一些空的空间等待插入值）键（关键字）的空间。来解决大数据量下的高度问题增长问题，这这中一般在文件系统和数据库系统中比较常用，mysql的索引默认就是B+树。这些归根到底也就是空间换时间。所以恰当的数据结构就可以提升算法效率，减少存储空间。 参考 Scale-out Thinking的博客, MrLining的GitHub ,红黑树的删除,红黑树的插入]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP-IP基础知识(二)]]></title>
    <url>%2F2017%2F11%2F25%2FTCP-IP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%8602%2F</url>
    <content type="text"><![CDATA[回顾 之前讲过一篇关于IP协议的一篇博客。如果了解网络的人应该都知道开放式系统互联通信参考模型。也就是OSI模型（Open System Interconnection Reference Model），我们之前说的IP协议是指的网络层。今天我们来可能说一说TCP协议，他是位于传输层。OSI模型总共有七层，详细看图。 应用层（Application Layer）提供为应用软件而 设的界面，以设置与另一应用软件之间的通信。例如: HTTP，HTTPS，FTP，TELNET，SSH，SMTP，POP3等 表示层（Presentation Layer）把数据转换为能与接收者的系统格式兼容并适合传输的格式，该层被弃用。应用层的HTTP、FTP、Telnet等协议有类似的功能。传输层的TLS/SSL也有类似功能 会话层（Session Layer）负责在数据传输中设置和维护电脑网络中两台电脑之间的通信连接，该层被弃用。应用层的HTTP、RPC、SDP、RTCP等协议有类似的功能。 传输层（Transport Layer）把传输表头（TH）加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。（分割并重新组装上层提供的数据流，为数据流提供端到端的传输服务）。例如:传输控制协议（TCP）等。例如：TCP，UDP，TLS，SSL等协议 网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络数据。例如:IP(v4)，ICMP(v6)。 数据链路层（Data Link Layer）负责网络寻址、错误侦测和改错。当表头和表尾被加至数据包时，会形成帧。数据链表头（DLH）是包含了物理地址和错误侦测及改错的方法。数据链表尾（DLT）是一串指示数据包末端的字符串。分为两个子层：逻辑链路控制（logic link control，LLC）子层和介质访问控制（media access control，MAC）子层，所以有的书上说OSI是八层协议。 物理层（Physical Layer）在局部局域网上传送帧，它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机适配器等。 ​ 感觉回顾的有点多，其实还有个四层协议的这里先不讲了。应用层（应用层，表示层，会话层），传输层（传输层），网络层（网络层），网络接口层（数据链路层，物理层），可以自行百度，突然感觉自己废话好多。 TCP协议 传输控制协议（英语：Transmission Control Protocol，缩写为 TCP）是一种面向连接的、可靠的、基于字节流的传输层通信协议。 TCP端口 TCP 的包是不包含 IP 地址信息的，那是 IP 层上的事，但是有源端口和目的端口。就是说，端口这一东西，是属于 TCP 知识范畴的。我们知道两个进程，在计算机内部进行通信，可以有管道、内存共享、信号量、消息队列等方法。而两个进程如果需要进行通讯最基本的一个前提是能够唯一的标识一个进程，在本地进程通讯中我们可以使用 「PID(进程标识符)」 来唯一标识一个进程。但 PID 只在本地唯一，如果把两个进程放到了不同的两台计算机，然后他们要通信的话，PID 就不够用了，这样就需要另外一种手段了。解决这个问题的方法就是在运输层使用 「协议端口号 (protocol port number)」，简称 「端口 (port)」。我们知道 IP 层的 ip 地址可以唯一标识主机，而 TCP 层协议和端口号可以唯一标识主机的一个进程，这样我们可以利用：「ip地址＋协议＋端口号」唯一标示网络中的一个进程。在一些场合，也把这种唯一标识的模式称为「套接字 (Socket)」。这就是说，虽然通信的重点是应用进程，但我们只要把要传送的报文交到目的主机的某一个合适的端口，剩下的工作就由 TCP 来完成了 认识端口 TCP 用一个 16 位端口号来标识一个端口，可允许有 65536 ( 2的16次方) 个不同的端口号，范围在 0 ~ 65535 之间。 服务器端使用的端口号 熟知端口号：取值范围：0 ~ 1023。可以在 www.iana.org 查到，服务器机器一接通电源，服务器程序就运行起来，为了让因特网上所有的客户程序都能找到服务器程序，服务器程序所使用的端口就必须是固定的，并且总所众所周知的。例如：FTP是21，Telnet是23，SMTP是25，DNS是53，TFTP是69，HTTP是80，HTTPS是443，SNMP是161。登记端口号：取值范围：1024 ~ 49151。这类端口没有熟知的应用程序使用，但是需要登记，以防重复 客户端使用端口号 取值范围：49152 ~ 65535。这类端口仅在客户端进程运行时才动态选择。又叫 短暂端口号，表示这种端口的存在时间是短暂的，客户进程并不在意操作系统给它分配的是哪一个端口号，因为客户进程之所以必须有一个端口号，是为了让传输层的实体能够找到自己。 什么是报文（TCP 是面向字节流的，但传送的数据单元却是报文段。） 例如一个 100kb 的 HTML 文档需要传送到另外一台计算机，并不会整个文档直接传送过去，可能会切割成几个部分，比如四个分别为 25kb 的数据段。而每个数据段再加上一个 TCP 首部，就组成了 TCP 报文。一共四个 TCP 报文，发送到另外一个端。另外一端收到数据包，然后再剔除 TCP 首部，组装起来。等到四个数据包都收到了，就能还原出来一个完整的 HTML 文档了。在 OSI 的七层协议中，第二层（数据链路层）的数据叫「Frame」，第三层（网络层）上的数据叫「Packet」，第四层（传输层）的数据叫「Segment」。TCP 报文 (Segment)，包括首部和数据部分。而 TCP 的全部功能都体现在它首部中各字段的作用，只有弄清 TCP 首部各字段的作用才能掌握 TCP 的工作原理。TCP 报文段首部的前20个字节是固定的，后面有 4N 字节是根据需要而增加的。下图是把 TCP 报文中的首部放大来看。 ​ TCP 的首部包括以下内容： 1、源端口 source port（2字节），目的端口 destination port（2字节）： 源端口和目的端口各占 2 个 字节，共 4 个字节。用来告知主机该报文段是来自哪里以及传送给哪个应用程序（应用程序绑定了端口）的。进行 TCP 通讯时，客户端通常使用系统自动选择的临时端口号，而服务器则使用知名服务端口号 2、序号 sequence number（4字节）: 序号字段值指的是本报文段所发送的数据的第一个字节的序号。那么 100 的 HTML 文档分割成四个等分之后，（例如 100 kb 的 HTML 文档数据，一共 102400 (100 * 1024) 个字节，那么每一个字节就都有了编号，整个文档的编号的范围是 0 ~ 102399）第一个 TCP 报文段包含的是第一个 25kb 的数据，0 ~ 25599 字节， 该报文的序号的值就是：0第二个 TCP 报文段包含的是第二个 25kb 的数据，25600 ~ 51199 字节，该报文的序号的值就是：25600……根据 8 位 = 1 字节，那么 4 个字节可以表示的数值范围：[0, 2^32]，一共 2^32 (4294967296) 个序号。序号增加到最大值的时候，下一个序号又回到了 0.也就是说 TCP 协议可对 4GB 的数据进行编号，在一般情况下可保证当序号重复使用时，旧序号的数据早已经通过网络到达终点或者丢失了。TCP 是面向字节流的，在一个 TCP 连接中传输的字节流中的每个字节都按照顺序编号。 3、确认号 acknowledgment number（4个字节）： 表示期望收到对方下一个报文段的序号值。TCP 的可靠性，是建立在「每一个数据报文都需要确认收到的基础之上的。就是说，通讯的任何一方在收到对方的一个报文之后，都要发送一个相对应的「确认报文」，来表达确认收到。那么，确认报文，就会包含确认号。（例如，通讯的一方收到了第一个 25kb 的报文，该报文的 序号值=0，那么就需要回复一个确认报文，其中的确认号 = 25600。） 4、数据偏移 offset（0.5个字节）： 占 0.5 个字节 (4 位)。这个字段实际上是指出了 TCP 报文段的首部长度 ，它指出了 TCP报文段的数据起始处 距离 TCP报文的起始处 有多远。（注意 数据起始处 和 报文起始处 的意思）一个数据偏移量 = 4 byte，由于 4 位二进制数能表示的最大十进制数字是 15，因此数据偏移的最大值是 60 byte，这也侧面限制了 TCP 首部的最大长度。 6、保留 reserved（0.75个字节）： 占 0.75 个字节 (6 位)。保留为今后使用，但目前应置为 0。 7、标志位 tcp flags：（0.75个字节） 标志位，一共有 6 个，分别占 1 位，共 6 位 。每一位的值只有 0 和 1，分别表达不同意思（上面图上有显示 ）。 URG（Urgent）紧急 ：当 URG = 1 的时候，表示紧急指针（Urgent Pointer）有效。它告诉系统此报文段中有紧急数据，应尽快传送，而不要按原来的排队顺序来传送。URG 要与首部中的 紧急指针 字段配合使用。 ACK（Acknowledgemt ）确认：当 ACK = 1 的时候，确认号（Acknowledgemt Number）有效。一般称携带 ACK 标志的 TCP 报文段为「确认报文段」。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 设置为 1。（也就是建立链接之后一般传输和返回报文的标志位都是ACK） PSH（Push）推送：当 PSH = 1 的时候，表示该报文段高优先级，接收方 TCP 应该尽快推送给接收应用程序，而不用等到整个 TCP 缓存都填满了后再交付。 RST（Reset）复位：当 RST = 1 的时候，表示 TCP 连接中出现严重错误，需要释放并重新建立连接。一般称携带 RST 标志的 TCP 报文段为「复位报文段」。 SYN（Synchronization）同步：当 SYN = 1 的时候，表明这是一个请求连接报文段。一般称携带 SYN 标志的 TCP 报文段为「同步报文段」。在 TCP 三次握手中的第一个报文就是同步报文段，在连接建立时用来同步序号。对方若同意建立连接，则应在响应的报文段中使 SYN = 1 和 ACK = 1。 FIN（Finis）终止：当 FIN = 1 时，表示此报文段的发送方的数据已经发送完毕，并要求释放 TCP 连接。一般称携带 FIN 的报文段为「结束报文段」。在 TCP 四次挥手释放连接的时候，就会用到该标志。 8、窗口大小 window size（2字节）： 该字段明确指出了现在允许对方发送的数据量，它告诉对方本端的 TCP 接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。窗口大小的值是指，从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。例如，假如确认号是 701 ，窗口字段是 1000。这就表明，从 701 号算起，发送此报文段的一方还有接收 1000 （字节序号是 701 ~ 1700） 个字节的数据的接收缓存空间 9、检验和 checksum（2字节）： 由发送端填充，接收端对 TCP 报文段执行 CRC 算法，以检验 TCP 报文段在传输过程中是否损坏，如果损坏这丢弃。检验范围包括首部和数据两部分，这也是 TCP 可靠传输的一个重要保障 10、紧急指针 urgent pointer（2字节）： 仅在 URG = 1 时才有意义，它指出本报文段中的紧急数据的字节数。当 URG = 1 时，发送方 TCP 就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。因此，紧急指针指出了紧急数据的末尾在报文段中的位置。 11、选项 tcp options（最多40个字节）； TCP头部的最后一个选项字段（options）是可变长的可选信息。这部分最多包含40字节，因为TCP头部最长是60字（其中还包含前面讨论的20字节的固定部分）。一般由kind，length和info组成。选项的第一个字段kind说明选项的类型。有的TCP选项没有后面两个字段，仅包含1字节的kind字段。第二个字段length（如果有的话）指定该选项的总长度，该长度包括kind字段和length字段占据的2字节。第三个字段info（如果有的话）是选项的具体信息。常见的TCP选项有7种。这7种就不详细展开。 TCP链接建立与数据传输：TCP 的整个交流过程可以总结为：先建立连接，然后传输数据，最后释放链接。 三次握手，四次挥手 TCP 连接建立要解决的首要问题就是：要使每一方能够确知对方的存在。三次握手就像，在一个黑暗的森林，你知道前方十点钟方向好像有人。 你喊了一句：Hello？I’am JerryC，Who are you？对面回了一句：Hi! I’am David, and nice to meet you!然后你回了一句：Nice to meet you too!……(自此，你们才算真正认识了双方，开始了后面省略3000字的谈话) 所以说，两个人需要交朋友（两个端点需要建立连接），至少需要三次的通话（握手）其实，网络上的传输是没有连接的，TCP 也是一样的。而 TCP 所谓的「连接」，其实只不过是在通信的双方维护一个「连接状态」，让它看上去好像有连接一样。其实没有三次握手也可以传输数据，但是那样数据传输不会那么准确，比如以后会说的UDP协议，他就没有三次握手和四次挥手。 连接建立过程，三次握手（这里面也有拜占庭将军问题，这个也是在分布式系统中的一个问题） TCP 连接的建立采用客户服务器方式，主动发起连接建立的一方叫客户端（Client），被动等待连接建立的一方叫服务器（Server）。最初的时候，两端都处于 CLOSED 的状态，然后服务器打开了 TCP 服务，进入 LISTEN 状态，监听特定端口，等待客户端的 TCP 请求。第一次握手： 客户端主动打开连接，发送 TCP 报文，进行第一次握手，然后进入 SYN_SEND（客户端） 状态，等待服务器发回确认报文。这时首部的同步位 SYN = 1，同时初始化一个序号 Sequence Number = J。TCP 规定，SYN 报文段不能携带数据，但会消耗一个序号。第二次握手： 服务器收到了 SYN 报文，如果同意建立连接，则向客户端发送一个确认报文，然后服务器进入 SYN_RCVD （服务端）状态。这时首部的 SYN = 1，ACK = 1，而确认号 Acknowledgemt Number = J + 1，同时也为自己初始化一个序号 Sequence Number = K。这个报文同样不携带数据。第三次握手：客户端收到了服务器发过来的确认报文，还要向服务器给出确认，然后进入 ESTABLISHED（服务端） 状态。这时首部的 SYN 不再置为 1，而 ACK = 1，确认号 Acknowledgemt Number = K + 1，序号 Sequence Number = J + 1。第三次握手，一般会携带真正需要传输的数据，当服务器收到该数据报文的时候，就会同样进入 ESTABLISHED 状态。 此时，TCP 连接已经建立。对于建立连接的三次握手，主要目的是初始化序号 Sequence Number，并且通信的双方都需要告知对方自己的初始化序号，所以这个过程也叫 SYN。这个序号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输问题而乱序，因为TCP 会用这个序号来拼接数据。 服务端SYN超时 当客户端给服务端发送SYN报文时，如果服务端没有返回SYN+ACK报文，那么客户端会重发SYN报文给服务端，重发的次数由参数tcp_syn_retries参数设置，该值默认是5，超过5次服务端还是不返回SYN+ACK报文，那么本次连接失败。服务端没有返回SYN+ACK主要有两种情况，一种是由于网络问题SYN包丢失；另一种是服务端SYN队列满(半连接队列，与之对应的是ACCPECT队列，全连接队列)，导致SYN包被丢弃。 客户端ACK超时 如果服务端接到了客户端发的SYN并回发SYN+ACK后，客户端掉线了，这时，服务端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功也没失败。于是，服务端端如果在一定时间内没有收到客户端端的ACK，那么服务端端会重发SYN+ACK。在Linux下，默认重试次数为5次，重发的间隔时间从1s开始每次都翻番（指数退避），5次的重发的时间间隔分别1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s+2s+4s+8s+16s+32s = 2^6-1 = 63s，TCP才会把断开这个连接。 利用连接设计缺陷实施 TCP Flood 攻击 知道了 TCP 建立一个连接，需要进行三次握手。但如果你开始思考「三次握手的必要性」的时候，就会知道，其实网络是很复杂的，一个信息在途中丢失的可能性是有的。如果数据丢失了，那么，就需要重新发送，这时候就要知道数据是否真的送达了。这就是三次握手的必要性。但是再向深一层思考，你给我发信息，我收到了，我回复，因为我是君子。如果是小人，你给我发信息，我就算收到了，我也不回复，你就一直等我着我的回复。那么很多小人都这样做，你就要一直记住你在等待着小人1号、小人2号、小人3号……直到你的脑容量爆棚，烧坏脑袋。黑客就是利用这样的设计缺陷，实施 TCP Flood 攻击，属于 DDOS 攻击的一种。也就是把tcp的全部SYN队列全部都塞满。一般socket编程的时候都会调整backlog这个值来设置这个队列。不过这个也不能太大，这样会小时系统性能。为了应对SYN Flood攻击，Linux实现了一种称为SYN cookie的机制，通过net.ipv4.tcp_syncookies来设置。当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使不在SYN队列中）。 下面罗列一些常用于TCP连接过程优化的参数。 tcp_max_syn_backlog SYN队列长度。如果服务器经常出现过载，可以尝试增加这个数字。 tcp_synack_retries 连接被动打开方的确认连接的应答最大重试次数。对于一个新建连接，内核要发送多少SYN连接请求才决定放弃。 tcp_syn_retries 连接主动打开方的syn尝试次数。 tcp_syncookies 防止SYN Flood攻击（请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是妥协版的TCP协议，并不严谨）。 tcp_abort_on_overflos ACCEPT队列满，处理不过来的时候，如果设置了该参数，内核将会回发RST包 释放连接过程 在结束之前，通信双方都是处于 ESTABLISHED 状态，然后其中一方主动断开连接。下面假如客户端先主动断开连接。第一次挥手：客户端向服务器发送结束报文段，然后进入 FIN_WAIT_1 （客户端）状态。此报文段 FIN = 1， Sequence Number = M。第二次挥手：服务端收到客户端的结束报文段，然后发送确认报文段，进入 CLOSE_WAIT（服务端） 状态。此报文段 ACK = 1， Sequence Number = M + 1。客户端收到该报文，会进入 FIN_WAIT_2（客户端） 状态。第三次挥手：同时服务端向客户端发送结束报文段，然后进入 LAST_ACK（服务端） 状态。此报文段 FIN = 1，Sequence Number = N。第四次挥手：客户端收到服务端的结束报文段，然后发送确认报文段，进入 TIME_WAIT（客户端） 状态，经过 2MSL 之后，自动进入 CLOSED （客户端）状态。此报文段 ACK = 1, Sequence Number = N + 1。服务端收到该报文之后，进入 CLOSED （服务端）状态。关于 TIME_WAIT 过渡到 CLOSED 状态说明：从 TIME_WAIT 进入 CLOSED 需要经过 2MSL，其中 MSL 就叫做 最长报文段寿命（Maxinum Segment Lifetime），根据 RFC 793 建议该值这是为 2 分钟，也就是说需要经过 4 分钟，才进入 CLOSED 状态。对于4次挥手，其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。 tcp状态流转 无论客户端还是服务器，在双方 TCP 通讯的过程中，都会有着一个「状态」的概念，状态会随着 TCP 通讯的不同阶段而变化。 ​ 各种状态表示的意思 CLOSED：表示初始状态。LISTEN：表示服务器端的某个 socket 处于监听状态，可以接受连接。SYN_SENT：在服务端监听后，客户端 socket 执行 CONNECT 连接时，客户端发送 SYN 报文，此时客户端就进入 SYN_SENT 状态，等待服务端确认。SYN_RCVD：表示服务端接收到了 SYN 报文。ESTABLISHED：表示连接已经建立了。FIN_WAIT_1：其中一方请求终止连接，等待对方的 FIN 报文。FIN_WAIT_2：在 FIN_WAIT_2 之后， 当对方回应 ACK 报文之后，进入该状态。TIME_WAIT：表示收到了对方的 FIN 报文，并发送出了 ACK 报文，就等 2MSL 之后即可回到 CLOSED 状态。CLOSING：一种罕见状态，发生在发送 FIN 报文之后，本应是先收到 ACK 报文，却先收到对方的 FIN 报文，那么就从 FIN_WAIT_1 的状态进入 CLOSING 状态。CLOSE_WAIT：表示等待关闭，在 ESTABLISHED 过渡到 LAST_ACK 的一个过渡阶段，该阶段需要考虑是否还有数据发送给对方，如果没有，就可以关闭连接，发送 FIN 报文，然后进入 LAST_ACK 状态。LAST_ACK：被动关闭一方发送 FIN 报文之后，最后等待对方的 ACK 报文所处的状态。CLOSED：当收到 ACK 保温后，就可以进入 CLOSED 状态了。 TCP 是如何一种提供可靠性交付的协议。 TCP 是一种提供可靠性交付的协议也就是说，通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。但是在网络中相连两端之间的介质，是复杂的，并不确保数据的可靠性交付，那么 TCP 是怎么样解决问题的？这就需要了解 TCP 的几种技术：滑动窗口、超时重传、流量控制、拥塞控制不过上面有提到一些可靠性的东西比如三次握手，超时重传，四次挥手等等。如果没有建立起Sequence Number和Acknowledgemt Number也就没有后面这几种技术。 TCP的超时重传（TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。） 接收端给发送端的Ack确认只会确认最后一个连续的包，比如，发送端发了1,2,3,4,5一共五份数据，接收端收到了1，2，于是回ack 3，然后收到了4（注意此时3没收到），此时的TCP会怎么办？我们要知道，因为正如前面所说的，SeqNum和Ack是以字节数为单位，所以ack的时候，不能跳着确认，只能确认最大的连续收到的包，不然，发送端就以为之前的都收到了。 超时重传机制：因为tcp协议是每一个发送都会有一个回执标志位都是ACK，当发送方一直收不到3的回执 。那么发送端就会重新的发送3的数据包直到收到这个回执（重传）。但是如果发送了3,4,5三个包，只有3自己丢失那4和5怎么办。这个时候TCP是不能跳着确认的，所以发送端只能悲观的认为4和5也没传过来。这个时候重传就需要策略： 一种是仅重传timeout的包。也就是第3份数据。这样也可节省带宽，但是比较慢 另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。 但总体来说都不好。因为都在等timeout，timeout可能会很长 快速重传机制：Fast Retransmit 算法，不以时间驱动，而以数据驱动重传。也就是说，如果，包没有连续到达（也就是没收到回执），就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的回执（上次的ACK），就重传。Fast Retransmit的好处是不用等timeout了再重传 Fast Retransmit只解决了一个问题，就是timeout的问题，它依然面临一个艰难的选择，就是，是重传之前的一个还是重传所有的问题。同时如果ACK丢失他也没办法，只能启动超时重传。 SACK方法(Selective Acknowledgment )：这种方式需要在TCP头里加一个SACK的东西，ACK(回执)还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版。也就是他会告诉发送端，自己接收的数据从哪里开始丢失的，丢失的是那个几个包。这样就不用所有的都重发，只重发已经丢掉的包即SACK标记的和ACK开始的那些。（ACK的是从哪里开始丢失的，而SACK是表示丢失了那些包） 这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。于是就优化了Fast Retransmit的算法。当然，这个协议需要两边都支持。在 Linux下，可以通过tcp_sack参数打开这个功能。接收方Reneging的意思就是接收方可以在某些情况下把已经报给发送端SACK里的数据给丢弃，接收方这么做可能会有些极端情况，一个SACK都没有。所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out。如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack D-SACK（Duplicate SACK，重复 SACK） 来告诉发送端，有那些数据已经重复接收。D-SACK使用了SACK的第一个段来做标志，SACK的第一个段的范围被ACK所覆盖（SACK中的值标记的第一个包，已经有回执ACK）或者SACK的第一个段的范围被SACK的第二个段覆盖（也就当前SACK所提供丢包的信息，能被其他SACK所代替），那么这个SACK（回执）就是D-SACK。DSACK好处：1、可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。2、是不是自己的timeout太小了，导致重传。3、网络上出现了先发的包后到的情况（又称reordering）4、网络上是不是把我的数据包给复制了。知道这些东西可以很好得帮助TCP了解网络情况，从而可以更好的做网络上的流控。Linux下的tcp_dsack参数用于开启这个功能（Linux 2.4后默认打开） TCP的RTT算法（如何动态计算和设置超时时间，从前面的TCP重传机制我们知道Timeout的设置对于重传非常重要） 超时时间（timeout）设长了，重发就慢，丢了老半天才重发，没有效率，性能差；设短了，会导致可能并没有丢就重发。于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。而且，这个超时时间在不同的网络的情况下，根本没有办法设置一个死的值。只能动态地设置。 为了动态地设置，TCP引入了RTT——Round Trip Time，也就是一个数据包从发出去到回来的时间。这样发送端就大约知道需要多少的时间，从而可以方便地设置Timeout——RTO（Retransmission TimeOut），以让我们的重传机制更高效。 听起来似乎很简单，好像就是在发送端发包时记下t0，然后接收端再把这个ack回来时再记一个t1，于是RTT = t1 – t0。没那么简单，这只是一个采样，不能代表普遍情况。 经典算法 1）首先，先采样RTT，记下最近好几次的RTT值。 2）然后做平滑计算SRTT（ Smoothed RTT）。公式为：（其中的 α 取值在0.8 到 0.9之间，这个算法英文叫Exponential weighted moving average，中文叫：加权移动平均） SRTT = ( α * SRTT ) + ((1- α) * RTT) 3）开始计算RTO。公式如下： RTO = min [ UBOUND, max [ LBOUND, (β * SRTT) ] ] 其中：UBOUND是最大的timeout时间，上限值，LBOUND是最小的timeout时间，下限值，β 值一般在1.3到2.0之间。 Karn / Partridge 算法 但是上面的这个算法在重传的时候会出有一个终极问题——你是用第一次发数据的时间和ack回来的时间做RTT样本值，还是用重传的时间和ACK回来的时间做RTT样本值？这个算法的最大特点是忽略重传，不把重传的RTT做采样。 如果在某一时间，网络闪动，突然变慢了，产生了比较大的延时，这个延时导致要重转所有的包（因为之前的RTO很小），于是，因为重转的不算，所以，RTO就不会被更新，这是一个灾难。 于是Karn算法用了一个取巧的方式——只要一发生重传，就对现有的RTO值翻倍（这就是所谓的 Exponential backoff），很明显，这种死规矩对于一个需要估计比较准确的RTT也不靠谱 Jacobson / Karels 算法 前面两种算法用的都是“加权移动平均”，这种方法最大的毛病就是如果RTT有一个大的波动的话，很难被发现，因为被平滑掉了。所以，1988年，又有人推出来了一个新的算法，这个算法叫Jacobson / Karels Algorithm（参看RFC6289）。这个算法引入了最新的RTT的采样和平滑过的SRTT的差距做因子来计算。 公式如下：（其中的DevRTT是Deviation RTT的意思） SRTT = SRTT + α*(RTT – SRTT) —计算平滑RTT DevRTT = (1-β)DevRTT + β**(|RTT-SRTT|) —计算平滑RTT和真实的差距（加权移动平均） RTO= µ * SRTT + ∂ *DevRTT —神一样的公式 （其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——这就是算法中的“调得一手好参数”，nobody knows why, it just works…） 最后的这个算法在被用在今天的TCP协议中。 TCP滑动窗口 我们都知道，TCP必需要解决的可靠传输以及包乱序（reordering）的问题，所以，TCP必需要知道网络实际的数据处理带宽或是数据处理速度，这样才不会引起网络拥塞，导致丢包。TCP引入了一些技术和设计来做网络流控，Sliding Window是其中一个技术。 前面我们说过，TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 TCP 缓冲区的数据结构 接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，我们可以看到中间有些数据还没有到达，所以有数据空白区。 发送端的LastByteAcked指向了被接收端Ack过的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有收到成功确认的Ack，LastByteWritten指向的是上层应用正在写的地方。 整个数据的流程中，首先网卡接收到的数据存放到内核缓冲区内，然后内核缓冲区存放的数据根据TCP信息将数据移动到具体的某一个TCP连接上的接收缓冲区内，也就是接收滑动窗口内，然后应用程序从TCP的接受缓冲区内读取数据，如果应用程序一直不读取，那么滑动窗口就会变小，直至为0.滑动窗口的大小与套接字缓存区会在一定程度上影响并发连接的数据，每个TCP连接都会为维护TCP滑动窗口而消耗内存，这个窗口会根据服务器的处理速度收缩或扩张。 如果网卡处理数据的速度比内核处理数据的速度慢，那么内核会有一个队列来保存这些数据，这个队列的大小就是由参数netdev_max_backlog决定的。 对于发送数据来说，应用程序将数据拷贝到各自TCP发送缓冲区内（也就是发送滑动窗口），然后系统的所有TCP套接字上发送缓冲区（也就是发送滑动窗口）内的数据都将数据拷贝到内核发送缓冲区内，然后内核将内核缓冲区的数据经过网卡发送出去。 TCP的发送/接受缓冲区（也就是发送/接受滑动窗口），是针对某一个具体的TCP连接来说的，每一个TCP连接都会有相应的滑动窗口，但是内核的发送/接受缓冲区是针对整个系统的，里面存放着整个系统的所有TCP连接的接收/发送的数据。 每个TCP套接口有一个发送缓冲区，可以用SO_SNDBUF套接口选项来改变这一缓冲区的大小。当应用进程调用write往套接口写数据时，内核从应用进程缓冲区中拷贝所有数据到套接口的发送缓冲区，如果套接口发送缓冲区容不下应用程序的所有数据，或者是应用进程的缓冲区大于套接口的发送缓冲区，或者是套接口的发送缓冲区中有别的数据，应用进程将被挂起。内核将不从write返回。直到应用进程缓冲区中的所有数据都拷贝到套接口发送缓冲区。所以，从写一个TCP套接口的write调用成功返回仅仅表示我们可以重新使用应用进程缓冲区，它并不是告诉我们对方收到数据。TCP发给对方的数据，对方在收到数据时必须给矛确认，只有在收到对方的确认时，本方TCP才会把TCP发送缓冲区中的数据删除。 接收端在给发送端回ACK中会汇报自己的AdvertisedWindow = MaxRcvBuffer – LastByteRcvd – 1; 而发送方会根据这个窗口来控制发送数据的大小，以保证接收方可以处理。 发送方的滑动窗口示意图（也就是发送端是如何处理发送数据数据的也可说是把数据分个类，那个是已经发的，那个是能发的，那个是不能发的）： 整个黑框指的是滑动窗口，上面的红框范围就是windows里面存的值，也就是如果接收到在接收到回执，在发送的数据 类别1：已经接收到回执（ACK）的数据。这部分接收端已经处理完了，从tcp缓冲区删除 类别2：发送还没收到回执（ACK）的数据。这部分接收端正在处理中或者没有处理完，还留在tcp缓冲中（LastByteRcvd -LastByteRead-1）。 类别3：还没有发送的数据，但是接收端的缓冲区能够处理的了，也就是AdvertisedWindow 。 类别4：还没有发送的数据。接收端缓冲区也不能够处理的数据。 滑动后的示意图（收到36的ack，并发出了46-51的字节）： 下面是整个过程的图片: Zero Window 我们可以看到一个处理缓慢的Server（接收端）是怎么把Client（发送端）的TCP Sliding Window给降成0的。此时，你一定会问，如果Window变成0了，TCP会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿Window size 可用了，怎么通知发送端呢？ 解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。 注意：只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。 Silly Window Syndrome 翻译成中文就是“糊涂窗口综合症”。正如你上面看到的一样，如果我们的接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送这几个字节。要知道，我们的TCP+IP头有40个字节，为了几个字节，要达上这么大的开销，这太不经济了。 对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，而576减去TCP/IP头的40个字节就是536）。最大传输单元（Maximum Transmission Unit，缩写MTU）是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位）。最大传输单元这个参数通常与通信接口有关（网络接口卡、串口等）。如果你的网络包可以塞满MTU，那么你可以用满整个带宽，如果不能，那么你就会浪费带宽。（大于MTU的包有两种结局，一种是直接被丢了，另一种是会被重新分块打包发送） 你可以想像成一个MTU就相当于一个飞机的最多可以装的人，如果这飞机里满载的话，带宽最高，如果一个飞机只运一个人的话，无疑成本增加了。 Silly Windows Syndrome这个现像就像是你本来可以坐200人的飞机里只做了一两个人。 要解决这个问题也不难，就是避免对小的window size做出响应，直到有足够大的window size再响应，这个思路可以同时实现在sender和receiver两端。 如果这个问题是由Receiver端引起的，那么就会使用 David D Clark’s 方案。在receiver端，如果收到的数据导致window size小于某个值，可以直接ack(0)回sender，这样就把window给关闭了，也阻止了sender再发数据过来，等到receiver端处理了一些数据后windows size 大于等于了MSS，或者，receiver buffer有一半为空，就可以把window打开让send 发送数据过来。 如果这个问题是由Sender端引起的，那么就会使用著名的 Nagle’s algorithm。这个算法的思路也是延时处理，他有两个主要的条件：1、要等到 Window Size&gt;=MSS 或是 Data Size &gt;=MSS。2、收到之前发送数据的ack回包，他才会发数据，否则就是在攒数据。 另外，Nagle算法默认是打开的，所以，对于一些需要小包场景的程序——比如像telnet或ssh这样的交互性比较强的程序，你需要关闭这个算法。你可以在Socket设置TCP_NODELAY选项来关闭这个算法（关闭Nagle算法没有全局参数，需要根据每个应用自己的特点来关闭 TCP的拥塞处理 TCP通过Sliding Window来做流控（Flow Control），但是TCP觉得这还不够，因为Sliding Window需要依赖于连接的发送端和接收端，其并不知道网络中间发生了什么。TCP的设计者觉得，一个伟大而牛逼的协议仅仅做到流控并不够，因为流控只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。 具体一点，我们知道TCP通过一个timer采样了RTT并计算RTO，但是，如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。这是一个灾难。 所以，TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了 拥塞控制主要是四个算法：1、慢启动，2、拥塞避免，3、拥塞发生，4、快速恢复。这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。 UDP协议的相关内容（尽管说UDP没有TCP那么靠谱，但是他也有他自己好处，开销小，简单。这UDP经常会在游戏服务器里面使用，流媒体，具体例子我就不说了） UDP 全称 User Datagram Protocol, 与 TCP 同是在网络模型中的传输层的协议。UDP为应用程序提供的是一种不可靠的、无连接的分组交付，因此，UDP报文可能会出现丢失、乱序、重复、延时等问题。特点：1、无连接的，即发送数据之前不需要建立连接，因此减少了开销和发送数据之前的时延。2、不保证可靠交付，因此主机不需要为此复杂的连接状态表。3、面向报文的，意思是 UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界，在添加首部后向下交给 IP 层。4、没有阻塞控制，因此网络出现的拥塞不会使发送方的发送速率降低。5、支持一对一、一对多、多对一和多对多的交互通信，也即是提供广播和多播的功能。6、头部开销小，首部只有 8 个字节，分为四部分 UDP的头部和伪头部 UDP 数据报分为数据字段和首部字段。首部字段只有 8 个字节，由四个字段组成，每个字段的长度是 2 个字节。 头部的组成：1、源端口：源端口号，在需要对方回信时选用，不需要时可全 0。2、目的端口：目的端口号，在终点交付报文时必须要使用到。3、长度：UDP 用户数据报的长度，在只有首部的情况，其最小值是 8 。4、检验和：检测 UDP 用户数据报在传输中是否有错，有错就丢弃。 伪头部:UDP 数据报首部中检验和的计算方法比较特殊。在计算检验和时，要在数据报之前增加 12 个字节的伪首部，用来计算校验和。伪首部并不是数据报真正的首部，是为了计算校验和而临时添加在数据报前面的，在真正传输的时候并不会把伪首部一并发送。1、第一字段，源 IP 地址。2、第二字段，目的 IP 地址。3、第三字段，字段全 0。4、第四字段，IP 首部中的协议字段的值，对于 UDP，此字段值为 17。5、第五字段，UDP 用户数据报的长度 为什么UDP开销小：1、因为UDP是无连接的。在传输数据之前，不需要进行复杂的三次握手来建立连接。2、在传输数据时，没有协议间通信流量（确认信号），也不需要浪费不必要的处理时间（接收确认信号再发一下）。3、传输结束后，也不用再用改进的四次挥手手来断开链接。 参考： TCP 的那些事儿(下), 理解 TCP 和 UDP]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP基础知识（一）]]></title>
    <url>%2F2017%2F11%2F18%2FTCP-IP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[什么是IP，IP地址是什么 互联网协议地址（英语：Internet Protocol Address，又译为网际协议地址），缩写为IP地址（英语：IP Address），是分配给网络上使用网际协议（英语：Internet Protocol, IP）的设备的数字标签。 IPv4到IPv6 常见的IP地址分为IPv4与IPv6两大类。IP地址由32位二进制数组成，为便于使用，常以XXX.XXX.XXX.XXX形式表现，每组XXX代表小于或等于255的10进制数。例如维基媒体的一个IP地址是208.80.152.2。地址可分为A、B、C、D、E五大类，其中E类属于特殊保留地址。IP地址是唯一的。目前IP技术可能使用的IP地址最多可有4,294,967,296个（即2的32方）。骤看可能觉得很难会用尽，但由于早期编码和分配上的问题，使很多区域的编码实际上被空出或不能使用。加上互联网的普及，IPv4的42亿个地址的分配最终于2011年2月3日用尽。相应的科研组织已研究出128位的IPv6，其IP地址数量最高可达3.402823669 × 1038个，届时每个人家居中的每件电器，每件对象，甚至地球上每一粒沙子都可以拥有自己的IP地址。从IPv4到IPv6最显著的变化就是网络地址的长度。RFC 2373和RFC 2374定义的IPv6地址，就像下面章节所描述的，有128位长；IPv6地址的表达形式，一般采用32个十六进制数。IPv6中可能的地址有2的128方≈3.4×1038个，具体数量为**340,282,366,920,938,463,463,374,607,431,768,211,456**个。在很多场合，IPv6地址由两个逻辑部分组成：一个64位的网络前缀和一个64位的主机地址，主机地址通常根理地址自动生成，叫做EUI-64（或者64-位扩展唯一标识） IP地址的表示方法 把整个Internet网堪称单一的网络，IP地址就是给每个连在Internet网的主机分配一个在全世界范围内唯一的标示符，Internet管理委员会定义了A、B、C、D、E五类地址，在每类地址中，还规定了网络编号和主机编号。在 TCP/IP协议中，IP地址是以二进制数字形式出现的，共32bit，1bit就是二进制中的1位，但这种形式非常不适用于人阅读和记忆。因此Internet管理委员会决定采用一种点分十进制表示法表示IP地址：面向用户的文档中，由四段构成的32 比特的IP地址被直观地表示为四个以圆点隔开的十进制整数，其中，每一个整数对应一个字节（8个比特为一个字节称为一段）。A、B、C类最常用，下面加以介绍。本文介绍的都是版本4的IP地址，称为IPv4. 从上图可以看出： A类地址：A类地址的网络标识由第一组8位二进制数表示， A类地址的特点是网络标识的第一位二进制数取值必须为0。不难算出，A类地址第一个地址为00000001，最后一个地址是01111111，换算成十进制就是127，其中127留作保留地址，A类地址的第一段范围是：1～126，A类地址允许有27 -2=126个网段（减2是因为0不用，127留作它用，127.0.0.1），网络中的主机标识占3组8位二进制数，每个网络允许有224-2=16777216台主机（减2是因为全0地址为网络地址，全1为广播地址，这两个地址一般不分配给主机）。通常分配给拥有大量主机的网络。 B类地址：B类地址的网络标识由前两组8位二进制数表示，网络中的主机标识占两组8位二进制数，B类地址的特点是网络标识的前两位二进制数取值必须为10。 B类地址第一个地址为10000000，最后一个地址是10111111，换算成十进制B类地址第一段范围就是128～191，B类地址允许有214 =16384个网段，网络中的主机标识占2组8位二进制数，每个网络允许有216-2=65533台主机，适用于结点比较多的网络。 B类地址：B类地址的网络标识由前两组8位二进制数表示，网络中的主机标识占两组8位二进制数，B类地址的特点是网络标识的前两位二进制数取值必须为10。 B类地址第一个地址为10000000，最后一个地址是10111111，换算成十进制B类地址第一段范围就是128～191，B类地址允许有214 =16384个网段，网络中的主机标识占2组8位二进制数，每个网络允许有216-2=65533台主机，适用于结点比较多的网络。 C类地址：C类地址的网络标识由前3组8位二进制数表示，网络中主机标识占1组8位二进制数C类地址的特点是网络标识的前3位二进制数取值必须为110。C类地址第一个地址为11000000，最后一个地址是11011111，换算成十进制C类地址第一段范围就是192～223，C类地址允许有221 =2097152个网段，网络中的主机标识占1组8位二进制数，每个网络允许有28-2= 254台主机，适用于结点比较少的网络。 越到后面网络，主机就越少，网络编号越长，主机编号越少。 有些人对范围是2x不太理解，举个简单的例子加以说明。如C类网，每个网络允许有28-2= 254台主机是这样来的。因为C类网的主机位是8位，变化如下: ​ 00000000 ​ 00000001 ​ 00000010 ​ 00000011 ​ …… ​ 11111110 ​ 11111111 除去00000000和11111111不用外，从00000001到11111110共有254个变化，也就是28-2个。下图是IP地址的使用范围 几个特殊的IP地址 私有地址 上面提到IP地址在全世界范围内唯一，看到这句话你可能有这样的疑问，像192.168.0.1这样的地址在许多地方都能看到，并不唯一，这是为何？Internet管理委员会规定如下地址段为私有地址，私有地址可以自己组网时用，但不能在Internet网上用，Internet网没有这些地址的路由，有这些地址的计算机要上网必须转换成为合法的IP地址,也称为公网地址，这就像有很到的世界公园，每个公园内都可命名相同的大街，如香榭丽舍大街，但对外我们只能看到公园的地址和真正的香榭丽舍大街。下面是A、B、C类网络中的私有地址段。你自己组网时就可以用这些地址了。 1234510.0.0.0～10.255.255.255172.16.0.0～172.131.255.255192.168.0.0～192.168.255.255 回送地址 A类网络地址127是一个保留地址，用于网络软件测试以及本地机进程间通信，叫做回送地址（loopback address）。无论什么程序，一旦使用回送地址发送数据，协议软件立即返回之，不进行任何网络传输。含网络号127的分组不能出现在任何网络上 Ping 127.0.0.1,如果反馈信息失败,说明IP协议栈有错,必须重新安装TCP/IP协议。如果成功,ping本机IP地址,如果反馈信息失败,说明你的网卡不能和IP协议栈进行通信。 如果网卡没接网线，用本机的一些服务如Sql Server、IIS等就可以用127.0.0.1这个地址 网络地址 TCP/IP协议规定，各位全为0的网络号被解释成本网络。由上可以看出：一、含网络号127的分组不能出现在任何网络上；二、主机和网关不能为该地址广播任何寻径信息。由以上规定可以看出，主机号全0全1的地址在TCP/IP协议中有特殊含义，一般不能用作一台主机的有效地址。 广播地址 TCP/IP规定，主机号全为1的网络地址用于广播之用，叫做广播地址。所谓广播，指同时向同一子网所有主机发送报文。 子网掩码 从上面的例子可以看出，子网掩码的作用就是和IP地址与运算后得出网络地址，子网掩码也是32bit，并且是一串1后跟随一串0组成，其中1表示在IP地址中的网络号对应的位数，而0表示在IP地址中主机对应的位数。 标准子网掩码 A类网络（1 - 126） 缺省子网掩码：255·0·0·0 255·0·0·0 换算成二进制为 11111111·00000000·00000000·00000000 可以清楚地看出前8位是网络地址，后24位是主机地址，也就是说，如果用的是标准子网掩码，看第一段地址即可看出 是不是同一网络的。如21.0.0.0.1和21.240.230.1，第一段为21属于A类，如果用的是默认的子网掩码，那这两个地址就是一个网段的。 B类网络（128 - 191） 缺省子网掩码：255·255·0·0 C类网络（192 - 223） 缺省子网掩码：255·255·255·0 B类、C类分析同上 特殊的子网掩码 标准子网掩码出现的都是255和0的组合，在实际的应用中还有下面的子网掩码 255·128·0·0 255·192·0·0 。。。。。。 255·255·192·0 255·255·240·0 。。。。。。 255·255·255·248 255·255·255·252 这些子网掩码又是什么意思呢？这些子网掩码的出现是为了把一个网络划分成多个网络。 还记得上面的例子吗？如下所示：192·168·0·1和192·168·0·200如果是默认掩码255.255.255.0两个地址就是一个网络的，如果掩码变为255.255.255.192这样各地址就不属于一个网络了。下面的子网划分将作详细介绍。 ​ 表1是几个子网掩码计算过程中非常有用的十进制和二进制的对照 IPv4与IPv6的转换 IPv6地址为128位长但通常写作8组每组四个十六进制数的形式。例如： 2001:0db8:85a3:08d3:1319:8a2e:0370:7344 是一个合法的IPv6地址。 如果四个数字都是0，可以被省略。例如： 2001:0db8:85a3:0000:1319:8a2e:0370:7344 等价于 2001:0db8:85a3::1319:8a2e:0370:7344 遵从这些规则，如果因为省略而出现了两个以上的冒号的话，可以压缩为一个，但这种零压缩在地址中只能出现一次。因此： 2001:0DB8:0000:0000:0000:0000:1428:57ab 2001:0DB8:0000:0000:0000::1428:57ab 2001:0DB8:0:0:0:1428:57ab 2001:0DB8:0::0:1428:57ab 2001:0DB8::1428:57ab 都是合法的地址，并且他们是等价的。但 2001::25de::cade 是非法的。（因为这样会使得搞不清楚每个压缩中有几个全零的分组）同时前导的零可以省略，因此：2001:0DB8:02de::0e13 等价于 2001:DB8:2de::e13 如果这个地址实际上是IPv4的地址 后32位可以用10进制数表示；因此： IPv4地址可以很容易的转化为IPv6格式。举例来说，如果IPv4的一个地址为135.75.43.52（十六进制为0x874B2B34），它可以被转化为0000:0000:0000:0000:0000:0000:874B:2B34或者::874B:2B34。同时，还可以使用混合符号（IPv4-compatible address），则地址可以为::135.75.43.52。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayBlockingQueue]]></title>
    <url>%2F2017%2F10%2F25%2FArrayQueue%2F</url>
    <content type="text"><![CDATA[什么是Queue Queue就是队列的意思，所谓的队列就是排队，先进先出（FIFO first in frist out）。队列是一种非常常见的数据结构，他是一种特殊的线性表，只允许从head头出队，从tail尾入队。先进先出（FIFO）：先插入的队列的元素也最先出队列，类似于排队的功能。从某种程度上来说这种队列也体现了一种公平性。 什么是Array 在计算机科学中，数组数据结构（英语：array data structure），简称数组（英语：Array），是由相同类型的元素（element）的集合所组成的数据结构，分配一块连续的内存来存储。利用元素的索引（index）可以计算出该元素对应的存储地址。所以查找起来比较方便，和数组相对数据结构的就是链表，链表是不连续的存储。连续存储的好处就是她查找起来比较方便，每个元素都是相同大小的存放到一起。但是很容易出现碎片化的问题，而且对于大数组来说内存的消耗很大。但是链表就不会，他是很多和节点联系在一起，所以插入和删除比较方便，不用去移动位置。需要更改前驱和后继的指针就好了。 什么是BlockingQueue Blocking（阻塞）Queue（队列）。多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和“消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。假设我们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地解决他们之间的数据共享问题。但如果生产者和消费者在某个时间段内，万一发生数据处理速度不匹配的情况呢？理想情况下，如果生产者产出数据的速度大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的数据处理完毕，反之亦然。（在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒） 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。 什么是ArrayBlockingQueue ArrayBlockingQueue就是通过数组来实现阻塞队列的一种方式。在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。 ArrayBlockingQueue在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。 ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。而在创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643//ArrayBlockingQueue 继承AbstractQueue实现了BlockingQueue接口和序列化接口public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; //这个Object数组就是用来存放ArrayBlockingQueue里面的对象。这里面也就ArrayBlockingQueue的Array /** The queued items */ final Object[] items; //用于取出（take），删除（remove），出队（poll，peek）的对象的下标（索引） /** items index for next take, poll, peek or remove */ int takeIndex; //用于放入（put），提供（offer），添加（add）的对象下标 /** items index for next put, offer, or add */ int putIndex; //用于记录队列里元素的个数 /** Number of elements in the queue */ int count; /* * Concurrency control uses the classic two-condition algorithm * found in any textbook. * 并发控制使用任何教科书中的经典双条件算法。 */ //守护所有访问的主要锁，也就是所有的访问都要通过这个锁 /** Main lock guarding all access */ final ReentrantLock lock; //取操作等待的条件（take，remove，poll） /** Condition for waiting takes */ private final Condition notEmpty; //放入操作的等待条件（put，offer，add） /** Condition for waiting puts */ private final Condition notFull; /** * Shared state for currently active iterators, or null if there * are known not to be any. Allows queue operations to update * iterator state. */ // 当前活动迭代器的共享状态，如果不存在任何已知操作，则为null。 允许队列操作更新迭代器状态。 transient Itrs itrs = null; /** * Circularly decrement i.从i循环递减到0 */ final int dec(int i) &#123; return ((i == 0) ? items.length : i) - 1; &#125; /** * Returns item at index i. 返回items i的元素 */ @SuppressWarnings("unchecked") final E itemAt(int i) &#123; return (E) items[i]; &#125; /** * Throws NullPointerException if argument is null. * 校验参数v是否为空 v是元素 * @param v the element */ private static void checkNotNull(Object v) &#123; if (v == null) throw new NullPointerException(); &#125; /** * Inserts element at current put position, advances, and signals. * Call only when holding lock. */ //插入元素在put位置（下标putIndex位置），也就是当前插入下标的数组节点，同时唤醒持有锁的插入线程 private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; //获取存储所有数据的数组 final Object[] items = this.items; //把数据放入当前下标节点的数组节点中 items[putIndex] = x; //判断一下是不是到数组最后节点也就 length-1，这里用的是++putIndex来说明 if (++putIndex == items.length) //如果是的话，就从头开始存放，因为那边消费也就是从投开始消费。 //即每次插入都从0开始，消费也都从0开始那么就可以实现先入先出 putIndex = 0; //加入成功后增加对列中元素数量，数组中元素加一 count++; //唤醒那些等待插入的线程（持有锁的线程），可以插入。获取的Condition notEmpty的插入线程 notEmpty.signal(); &#125; /** * Extracts element at current take position, advances, and signals. * Call only when holding lock. */ //提取take位置的元素（下标takeIndex的元素），同时唤醒持有锁的取出线程 private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; //获取存储所有数据的数组 final Object[] items = this.items; //获取数组中take位置的元素 @SuppressWarnings("unchecked") E x = (E) items[takeIndex]; //将take位置制为空 items[takeIndex] = null; //判读是不是取数取到item数组的最后元素，如果超过会出现数组越界 if (++takeIndex == items.length) //如果是从投开始取 takeIndex = 0; //对列中存在的元素数量减一 count--; //如果迭代器不为空，说明有线程把数据取走，元素减一 if (itrs != null) itrs.elementDequeued(); //唤醒取出线程（持有锁的） notFull.signal(); //返回take节点元素 return x; &#125; /** * Deletes item at array index removeIndex. * Utility for remove(Object) and iterator.remove. * Call only when holding lock. */ //删除item数组中index下标的元素，同时移除迭代器中数据，唤醒阻塞的线程 //删除元素，不影响队列的顺序，就是要不从队列的前面删除，出队删除，也就是找到takeIndex，然后删除。 //如果不是，那么就从队列最后面删除，即把之前的元素，和其他元素依次移动，然后把要删除的元素，移动到 //putIndex哪里然后删除 void removeAt(final int removeIndex) &#123; // assert lock.getHoldCount() == 1; // assert items[removeIndex] != null; // assert removeIndex &gt;= 0 &amp;&amp; removeIndex &lt; items.length; //获取存储数据的数组 final Object[] items = this.items; //如果取出位置，和要移除的位置正好是同一个（从队列前删除） if (removeIndex == takeIndex) &#123; // removing front item; just advance //清空位置信息 items[takeIndex] = null; //如果取出位置的下一个位置是最大位置，将取出位设成0，起始位置 if (++takeIndex == items.length) takeIndex = 0; //count-- 表示位置减少 count--; //迭代器中的如果也存有值，那么将这个值也清除掉 if (itrs != null) itrs.elementDequeued(); &#125; else &#123; // an "interior" remove // slide over all others up through putIndex. //如果要删除位置，不是取出位置，那么进行循环，直到找到取出位置 final int putIndex = this.putIndex; for (int i = removeIndex;;) &#123; //进行for的死循环 int next = i + 1; //如果next是数组的长度，那么从数组的长度为0也就是头部开始 if (next == items.length) next = 0; // if (next != putIndex) &#123; //找到要移除的元素，然后把要移除的元素，放到putIndex哪里，然后删除掉（从队列后删除） items[i] = items[next]; i = next; &#125; else &#123; //删除队列，并设置putIndex值 items[i] = null; this.putIndex = i; break; &#125; &#125; //队列中的值减少 count--; //如果迭代器不为空，清除迭代器中存放的值 if (itrs != null) itrs.removedAt(removeIndex); &#125; //唤醒线程 notFull.signal(); /** * Creates an &#123;@code ArrayBlockingQueue&#125; with the given (fixed) * capacity and default access policy. * * @param capacity the capacity of this queue * @throws IllegalArgumentException if &#123;@code capacity &lt; 1&#125; */ //ArrayBlockingQueue 构造函数，默认是不公平锁，这里是指定了队列的大小 /** * Creates an &#123;@code ArrayBlockingQueue&#125; with the given (fixed) * capacity and the specified access policy. * * @param capacity the capacity of this queue * @param fair if &#123;@code true&#125; then queue accesses for threads blocked * on insertion or removal, are processed in FIFO order; * if &#123;@code false&#125; the access order is unspecified. * @throws IllegalArgumentException if &#123;@code capacity &lt; 1&#125; */ // ArrayBlockingQueue的构造函数，指定队列大小，和是否使用公平锁（一次插入，一次移除） public ArrayBlockingQueue(int capacity, boolean fair) &#123; //当 capacity小于0的时候抛出异常 if (capacity &lt;= 0) throw new IllegalArgumentException(); //创建大小合适的数组 this.items = new Object[capacity]; //创建并发时候用的锁 lock = new ReentrantLock(fair); //入队条件 notEmpty = lock.newCondition(); //出队条件 notFull = lock.newCondition(); &#125; public ArrayBlockingQueue(int capacity) &#123; this(capacity, false); &#125; &#125; /** * Creates an &#123;@code ArrayBlockingQueue&#125; with the given (fixed) * capacity, the specified access policy and initially containing the * elements of the given collection, * added in traversal order of the collection's iterator. * * @param capacity the capacity of this queue * @param fair if &#123;@code true&#125; then queue accesses for threads blocked * on insertion or removal, are processed in FIFO order; * if &#123;@code false&#125; the access order is unspecified. * @param c the collection of elements to initially contain * @throws IllegalArgumentException if &#123;@code capacity&#125; is less than * &#123;@code c.size()&#125;, or less than 1. * @throws NullPointerException if the specified collection or any * of its elements are null */ //将一个已有的集合，放入到队列中去 public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) &#123; //初始化构造函数 this(capacity, fair); //初始化锁 final ReentrantLock lock = this.lock; //将队列锁住，也就当前线程获取锁。 lock.lock(); // Lock only for visibility, not mutual exclusion //然后将集合中的值遍历出来放到队列数组中去 try &#123; int i = 0; try &#123; for (E e : c) &#123; //校验是否为空，是空则抛出空指针异常 checkNotNull(e); items[i++] = e; &#125; &#125; catch (ArrayIndexOutOfBoundsException ex) &#123; throw new IllegalArgumentException(); &#125; count = i; //初始化队尾，如果等于最大值，为变为头，如果不是则为 i putIndex = (i == capacity) ? 0 : i; &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; /** * Inserts the specified element at the tail of this queue if it is * possible to do so immediately without exceeding the queue's capacity, * returning &#123;@code true&#125; upon success and throwing an * &#123;@code IllegalStateException&#125; if this queue is full. * * @param e the element to add * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) * @throws IllegalStateException if this queue is full * @throws NullPointerException if the specified element is null */ //向队列加入值，这里面调用的是父类的方法，父类中调用的是offer()方法， //如果添加成功返回true，失败则抛出异常（也就是）队列满了情况下 public boolean add(E e) &#123; return super.add(e); &#125; /** * Inserts the specified element at the tail of this queue if it is * possible to do so immediately without exceeding the queue's capacity, * returning &#123;@code true&#125; upon success and &#123;@code false&#125; if this queue * is full. This method is generally preferable to method &#123;@link #add&#125;, * which can fail to insert an element only by throwing an exception. * * @throws NullPointerException if the specified element is null */ //插入一个元素，向队列中，如果插入成功返回true，失败返回false public boolean offer(E e) &#123; //如果插入的值是null，抛空指针异常 checkNotNull(e); final ReentrantLock lock = this.lock; //当前线程获取锁，也就是操作权限 lock.lock(); try &#123; //队列已满，插入失败 if (count == items.length) return false; else &#123; //插入对列，返回成功 enqueue(e); return true; &#125; &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; //出队 public E poll() &#123; //获取到锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //如果count等于0返回null，否则出队一个元素 return (count == 0) ? null : dequeue(); &#125; finally &#123; //最后释放锁 lock.unlock(); &#125; &#125; //从队列取出一个元素 public E take() throws InterruptedException &#123; //获取锁 final ReentrantLock lock = this.lock; //如果当前线程没有被打断，获取锁。如果这个 锁没有被获取 lock.lockInterruptibly(); try &#123; //当count==0也就是队列是空的情况，线程一直保持等待，其他线程进不来 while (count == 0) notEmpty.await(); //如果不是空则，出队一个元素 return dequeue(); &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; //在一段时间出队一个元素，时间是纳秒 public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; //使用TimeUnit设置时间长度 long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; //如果当前线程没有被打断，获取锁。如果这个 锁没有被获取 lock.lockInterruptibly(); try &#123; //如果队列元素为0个，同时超过了等待时间，那就返回一个空，否则就继续等待 while (count == 0) &#123; if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); &#125; //如果队列元素不是0，那就出队一个元素 return dequeue(); &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; //从队列头取出一个元素 public E peek() &#123; //获取锁，如果没有获取，那么线程就一直处于等待状态 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //返回一个元素，即takeIndex位置的元素。都是最前面的元素 return itemAt(takeIndex); // null when queue is empty &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125;// this doc comment is overridden to remove the reference to collections //这个文章的注解@overridden，被移除掉引用从集合接口中 // greater in size than Integer.MAX_VALUE /** * Returns the number of elements in this queue. * 返回队列元素的个数 * @return the number of elements in this queue */ public int size() &#123; //获取锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //返回count值，即队列中元素的数量 return count; &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; // this doc comment is a modified copy of the inherited doc comment, // without the reference to unlimited queues. /** * Returns the number of additional elements that this queue can ideally * (in the absence of memory or resource constraints) accept without * blocking. This is always equal to the initial capacity of this queue * less the current &#123;@code size&#125; of this queue. * * &lt;p&gt;Note that you &lt;em&gt;cannot&lt;/em&gt; always tell if an attempt to insert * an element will succeed by inspecting &#123;@code remainingCapacity&#125; * because it may be the case that another thread is about to * insert or remove an element. */ //队列中剩余多少可以插入的元素，一般就是用数组的总长度减去当前元素的个数 public int remainingCapacity() &#123; //获取锁，如果没有获取等待 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //返回当前线程时，剩余能插入的元素个数 return items.length - count; &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; /** * Removes a single instance of the specified element from this queue, * if it is present. More formally, removes an element &#123;@code e&#125; such * that &#123;@code o.equals(e)&#125;, if this queue contains one or more such * elements. * Returns &#123;@code true&#125; if this queue contained the specified element * (or equivalently, if this queue changed as a result of the call). * * &lt;p&gt;Removal of interior elements in circular array based queues * is an intrinsically slow and disruptive operation, so should * be undertaken only in exceptional circumstances, ideally * only when the queue is known not to be accessible by other * threads. * * @param o element to be removed from this queue, if present * @return &#123;@code true&#125; if this queue changed as a result of the call */ //从队列里删除一个元素o public boolean remove(Object o) &#123; //如果o是null返回false if (o == null) return false; //获取存取队列的到当前的数组 final Object[] items = this.items; //获取锁，如果获取不到进入等待，等待condition.signal()唤醒 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //如果队列中有元素，就去查找移除，否则返回false if (count &gt; 0) &#123; final int putIndex = this.putIndex; int i = takeIndex; //通过do while循环去遍历整个数组，也就是队列。从对列的头进入。也就是从takeIndex节点开始 do &#123; //如果找到，然后调用removeAt将元素删除，并且调整队列 if (o.equals(items[i])) &#123; removeAt(i); //返回成功 return true; &#125; //如果达到数组的最大长度，然后从数组的头开始，即第一个元素 if (++i == items.length) i = 0; //当i等于putIndex也就是从头找到尾，因为putIndex即队尾 &#125; while (i != putIndex); &#125; //否则返回false，就是没找到相等的对象，在这个队列 return false; &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; /** * Returns &#123;@code true&#125; if this queue contains the specified element. * More formally, returns &#123;@code true&#125; if and only if this queue contains * at least one element &#123;@code e&#125; such that &#123;@code o.equals(e)&#125;. * * @param o object to be checked for containment in this queue * @return &#123;@code true&#125; if this queue contains the specified element */ //是否包含当前元素o public boolean contains(Object o) &#123; //如果当前元素是null返回false if (o == null) return false; //获取当前数组存储队列值 final Object[] items = this.items; //获取锁，如果获取不到进入等待，等待condition.signal()唤醒 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //如果队列里有元素就去查找，否则返回false if (count &gt; 0) &#123; //获取当前队列中队列尾部在数组中位置 final int putIndex = this.putIndex; //获取当前队列的开头部分，也就是出队位置 int i = takeIndex; do &#123; //如果队列开头位置的元素，是包含的，返回true if (o.equals(items[i])) return true; //如果达到数组的最大长度，然后从数组的头开始，即第一个元素 if (++i == items.length) i = 0; //循环到队列尾部，结束也就是i==putIndex &#125; while (i != putIndex); &#125; return false; &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; /** * Atomically removes all of the elements from this queue. * The queue will be empty after this call returns. */ //移除该队列中所有元素 public void clear() &#123; //获取存放队列元素的数组 final Object[] items = this.items; //获取锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //获取队列张还有多少元素 int k = count; //如果元素小于等于0，说明没有元素队列 if (k &gt; 0) &#123; //获取队尾的节点的数组位置 final int putIndex = this.putIndex; //获取队头节点的数组位置 int i = takeIndex; do &#123; //清空该节点的位置，也就是对头元素位置 items[i] = null; //是否达到数组最大边界,如果是从数组第一个元素开始 if (++i == items.length) i = 0; //直到把整个队列数据清空 &#125; while (i != putIndex); //清空后把队尾，和队列头放到一起 takeIndex = putIndex; //清空队列里计算 count = 0; //清空迭代器里的值，告诉迭代器现在队列中值是空的 if (itrs != null) itrs.queueIsEmpty(); //如果之前队列元素，那么看一下还有多少个等待添加的线程，如果有唤醒他们，让他们向队列添加。也就是 //clear队列，对应的是当前线程，如果有加入线程，在当前线程清空后还可以加入。 for (; k &gt; 0 &amp;&amp; lock.hasWaiters(notFull); k--) notFull.signal(); &#125; &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125; //最多从此队列中移除给定数量的可用元素，并将这些元素添加到给定 collection 中 。返回值int代表添加了多少个 public int drainTo(Collection&lt;? super E&gt; c, int maxElements) &#123; //校验给定的集合是不是空，如果是空抛出空指针异常 checkNotNull(c); //如果这个给定的集合，等于当前这个队列，抛出非法参数异常 if (c == this) throw new IllegalArgumentException(); //如果要移除的元素个数小于等于0，直接返回0 if (maxElements &lt;= 0) return 0; //获取存放队列的数组 final Object[] items = this.items; //获取锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //从要转移的最大元素个数，和线程中存在的元素个数取小的那个 int n = Math.min(maxElements, count); //获取队列的起始位置，也就是队列的头 int take = takeIndex; int i = 0; try &#123; //开始循环，取出值 while (i &lt; n) &#123; @SuppressWarnings("unchecked") //从队列取出值放到集合中去，然后删除队列中的值 E x = (E) items[take]; c.add(x); items[take] = null; //如果队列头位置，到达数组最大值那么从数组第一元素开始 if (++take == items.length) take = 0; //取出元素+1 i++; &#125; //最后返回n个 return n; &#125; finally &#123; // Restore invariants even if c.add() threw if (i &gt; 0) &#123; //成功个数大于0,将队列中元素减去i个 count -= i; //设置takeIndex位置 takeIndex = take; //如果迭代器不等于null if (itrs != null) &#123; //如果count等于0，说明队列中没有元素 if (count == 0) //设置迭代器队列是空 itrs.queueIsEmpty(); else if (i &gt; take) //否则用Index的值来覆盖到迭代器中 itrs.takeIndexWrapped(); &#125; //唤醒等待的线程 for (; i &gt; 0 &amp;&amp; lock.hasWaiters(notFull); i--) notFull.signal(); &#125; &#125; &#125; finally &#123; //释放锁 lock.unlock(); &#125; //这个有两个try操作中有两个finally，一个是处理迭代器的，另一个是处理锁的 &#125; 其实ArrayBockingQueue中还有几个内部类没有说，但是我在这里就不多解释，包括序列化和toString方法，迭代器方法和内部类没有介绍。所以我这也就不过多的介绍，本文是基于JDK 1.8.0_121的进行的分析。 ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁。而且ArrayBlockingQueue相比LinkedBlockingQueue性能更高。因为ArrayBlocking是通过数组，查找更快，移除使用过的元素会更快，但删除队列中元素对整个队列排序时候LinkedBlockingQueue更快。而且队列长度越大越明显，也会移动调整元素数量更多。但一般情况队列都不会存特别多数据。LinkedBlockingQueue最大长大度也就是Integer的最大值]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>java</tag>
        <tag>源代码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap]]></title>
    <url>%2F2017%2F09%2F17%2FLinkedHashMap%2F</url>
    <content type="text"><![CDATA[Linked是什么 linked是串联，连接的意思。编程里面理解成是用链表实现的数据结构，一般与HashMap，List，Set什么联合使用，说明这些集合类，都是通过链表实现的，这些集合存储额都是有顺序的，按照放进去的顺序。 什么是链表，链表与数组的去别 链表这个名称，估计学过数据结构的人都不陌生，链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据。也就是说他存储的信息的地址不是顺序的，与之相反的是数组。他的存储的信息和内存地址是连续的。使用链表的好处就在于每次修改删除比较方便，你只要找到对于位置，修改掉前驱元素和后继元素的指针就可以，不用移动其他数据，而数组在新增和删除的时候要移动大量的数据。所以在查询方面数组有很的优势，而在频繁的修改的数据，使用链表速度快一点。数组利用下标定位，时间复杂度为O(1)，链表定位元素时间复杂度O(n)； 数组插入或删除元素的时间复杂度O(n)，链表的时间复杂度O(1)。同时链表也增加了存储空间，原来只存data，现在要存data的before和after。 LinkedHashMap是什么 LinkedHashMap是HashMap的子类，他实现了Map接口 其扩展了 HashMap 增加了双向链表的实现。相较于 HashMap 的迭代器中混乱的访问顺序，LinkedHashMap 可以提供可以预测的迭代访问，即按照插入序 (insertion-order) 或访问序 (access-order) 来对哈希表中的元素进行迭代。从类声明中可以看到，LinkedHashMap 确实是继承了 HashMap，因而 HashMap 中的一些基本操作，如哈希计算、扩容、查找等，在 LinkedHashMap 中都和父类 HashMap 是一致的。插入序就是安装插入的顺序来访问，即从链表的头（frist）开始访问，如果是访问序，就是从链表的尾部（tail）来开始访问，即最新插入，或者是之前访问过的就是最先访问。但是，和 HashMap 有所区别的是，LinkedHashMap 支持按插入序 (insertion-order) 或访问序 (access-order) 来访问其中的元素。所谓插入顺序，就是 Entry 被添加到 Map 中的顺序，更新一个 Key 关联的 Value 并不会对插入顺序造成影响；而访问顺序则是对所有 Entry 按照最近访问 (least-recently) 到最远访问 (most-recently) 进行排序，读写都会影响到访问顺序，但是对迭代器 (entrySet(), keySet(), values()) 的访问不会影响到访问顺序。访问序的特性使得可以很容易通过 LinkedHashMap 来实现一个 LRU(least-recently-used) Cache，后面会给出一个简单的例子。之所以 LinkedHashMap 能够支持插入序或访问序的遍历，是因为 LinkedHashMap 在 HashMap 的基础上增加了双向链表的实现。下面是代码分析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt;&#123; //一个匿名内部类，用于存放相关节点信息，继承HashMap的Node内部类 //多了Entry&lt;K,V&gt;类型的 before和after。类似组合模式static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125; &#125;//当前链表节点的头节点，最老的节点transient LinkedHashMap.Entry&lt;K,V&gt; head;//当前链表的尾部节点，最新的节点transient LinkedHashMap.Entry&lt;K,V&gt; tail; &#125;//将新节点 p 链接到双向链表的末尾//一个私有方法，把一个节点加到另一个节点后面，如果前驱节点为null，只有他一个节点，即他是head也是tail private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; //之前最后的节点是last，把last节点放到最新节点p的before，把last节点after设置成最新节点p p.before = last; last.after = p; &#125; &#125;//私有方法，把src链接到dst上，就是用dst替换src在双向链表中的位置private void transferLinks(LinkedHashMap.Entry&lt;K,V&gt; src, LinkedHashMap.Entry&lt;K,V&gt; dst) &#123; //将之前src的前驱，和后继都复制给dst，同时赋值给a和b，b是前驱，a是后继 LinkedHashMap.Entry&lt;K,V&gt; b = dst.before = src.before; LinkedHashMap.Entry&lt;K,V&gt; a = dst.after = src.after; //如果b为空，src原来就是head节点，把dst设置成head节点 if (b == null) head = dst; else //否则把src的前驱节点的after设置成dst b.after = dst; // 如果a为空,src是原来的tail节点，把dst设置成tail节点 if (a == null) tail = dst; else //否则把src的后继节点before设置成dst a.before = dst; &#125;//调用父类的重新初始化方法，把值设成nullvoid reinitialize() &#123; super.reinitialize(); head = tail = null; &#125;//创建一个新的entry节点，重写父类hashmap的方法Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); //将创建的新节点，加到列表后面 linkNodeLast(p); return p; &#125;//将TreeNode节点转换成普通节点。TreeNode节点是个红黑树，在hashMap中，当链表长度超过8时，会把entry链表转换//成TreeNode.普通节点即entry节点，是个单链表由key，value，next，hash组成Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; LinkedHashMap.Entry&lt;K,V&gt; q = (LinkedHashMap.Entry&lt;K,V&gt;)p; LinkedHashMap.Entry&lt;K,V&gt; t = new LinkedHashMap.Entry&lt;K,V&gt;(q.hash, q.key, q.value, next); //替换节点的方法 transferLinks(q, t); return t; &#125;//创建一个treeNode节点，加入到链表的最后，treeNode是hashmap的内部类，LinkedHashMap继承了HashMapTreeNode&lt;K,V&gt; newTreeNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(hash, key, value, next); linkNodeLast(p); return p; &#125;//将一个entry节点替换成TreeNode节点，一般碰撞超过8个会用一个树来代替上面的链表 TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; LinkedHashMap.Entry&lt;K,V&gt; q = (LinkedHashMap.Entry&lt;K,V&gt;)p; //新建一个treeNode节点 TreeNode&lt;K,V&gt; t = new TreeNode&lt;K,V&gt;(q.hash, q.key, q.value, next); //替换节点 transferLinks(q, t); return t; &#125;//移除节点的回调函数，这个函数在hashmap中声明，但是没有实现，然后在linkedhashmap实现。void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink //移除一个节点，双向链表中的连接关系也要调整，先将节点里的值取出来 LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; //移除节点 p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b;&#125;/*插入节点的回调函数，也是在hashmap中声明，在Linkedhashmap中实现，evict（赶出），在hashmap照片您好evict都是等于true,本函数也就是在没有指定removeEldestEntry这个函数等于true的时候，是不会移除第一个节点，都只是向后插入，而不替换之前的节点，但是，如果是set的话，*/ void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; //对是否删除eldest节点做判断 //如果evict是true，节点不为空，removeEldestEntry函数返回的是true，删除eldest节点 //一般默认removeEldestEntry函数返回的是FALSE，在LinkedHashMap，所以只是把head赋值给了first，并 //没有移除eldest节点，如果你要设置LRU算法的时候覆写该方法，一般的实现是，当设定的内存 //（这里指节点个数）达到最大值时，返回true if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; //hashMap中的方法，用来节点，linkedhashMap继承过来的 removeNode(hash(key), key, null, false, true); &#125; &#125;//访问节点的回调函数，这里实现了访问序和插入序的实现 void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; //如果是访问序，把当前节点放到tail节点 if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; //如果当前的节点的前驱点是空，也可以说，当前节点为head结点那，把after节点，放到head上， //如果不是把 p 的前驱节点节点的后继节点改成 p 的后继节点。 if (b == null) head = a; else b.after = a; //如果p的后继节点不为空，p的后继节点与的前驱节点改成p的前驱节点 //如果不是也就是p节点是没有后继节点，也就是tail节点那把p的前驱节点复制给last节点，last节点是tail节点 if (a != null) a.before = b; else last = b; //如果last节点为空，也就是只有一个节点（当前的tail节点），把当前节点赋值给head节点 //如果不是last节点不为空，把当前节点的前驱设置成last节点，把last节点的后继设成当前节点。 if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; //把当前节点放到tail节点上 tail = p; ++modCount; &#125; &#125; //遍历LinkedHashMap，将LinkedHashMap中的key和value实现序列化 void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125;//遍历LinkedHashMap，查找是否包含某个值 public boolean containsValue(Object value) &#123; for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) &#123; V v = e.value; if (v == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; return false; &#125;//获取value值，getNode()方法，实现在hashMap类中 public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value; &#125;//是否移除最老的entry，记录，默认是false，如果写LRU缓存可以重写这方法。protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false; &#125;//最后说一下LinkedHashMap的构造函数//指定LinkedHashMap的初始大小，和负载因子，防止hash碰撞过多，这里是符合泊松分布的。默认加载因子是0.75，//super这里调用的是HashMap的构造方法。//访问序（accessOrder是false）。 public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false; &#125;//这个应该是他最全的构造函数，这里accessOrder是指是否访问序public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder; &#125; 其实LinkedHashMap中还有几个内部类没有说，但是我在这里就不多解释，他都是重写或者实现了上层的方法。所以我这也就不过多的介绍，本文是基于JDK 1.8.0_121的进行的分析。LinkedHashMap的好处就是插入和删除比较快，他不会像数组那样每次删除增加都会移动，但是，每次查询都会比较慢，毕竟是连续的存储，只有知道当前节点才能知道下一个节点。不如数组快。同时采用链表的设计会对内存的要求增大(每个节点不仅存数据，还要存前驱后继的地址)，不LinkedHashMap是有序的，在很多要求有序的场景下可以使用。 最后还要LRU缓存的实现，这个是从网上找的例子。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//http://blog.jrwang.me/2016/java-collections-linkedhashmap/ 代码出处public class CacheImpl&lt;K,V&gt; &#123; private Map&lt;K, V&gt; cache; private int capacity; public enum POLICY &#123; LRU, FIFO &#125; public CacheImpl(int cap, POLICY policy) &#123; this.capacity = cap; cache = new LinkedHashMap&lt;K, V&gt;(cap, 0.75f, policy.equals(POLICY.LRU))&#123; //超出容量就删除最老的值 @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; return size() &gt; capacity; &#125; &#125;; &#125; public V get(K key) &#123; if (cache.containsKey(key)) &#123; return cache.get(key); &#125; return null; &#125; public void set(K key, V val) &#123; cache.put(key, val); &#125; public void printKV() &#123; System.out.println("key value in cache"); for (Map.Entry&lt;K,V&gt; entry : cache.entrySet()) &#123; System.out.println(entry.getKey() + ":" + entry.getValue()); &#125; &#125; public static void main(String[] args) &#123; CacheImpl&lt;Integer, String&gt; cache = new CacheImpl(5, POLICY.LRU); cache.set(1, "first"); cache.set(2, "second"); cache.set(3, "third"); cache.set(4, "fourth"); cache.set(5, "fifth"); cache.printKV(); cache.get(1); cache.get(2); cache.printKV(); cache.set(6, "sixth"); cache.printKV(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>java</tag>
        <tag>源代码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转发与重定向]]></title>
    <url>%2F2017%2F08%2F29%2F%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[转发(forward)：转发做了一次请求，浏览器的地址栏一直是第一次请求的地址。转发是服务器内部request/response控制权的移交。整个过程是一个请求，一个响应。 重定向(redirect):重定向行为是做了两次请求，及产生了两个request对象，重定向会导致request对象信息丢失。两个请求，两个响应。 区别：重定向是客户端行为，转发是服务器行为.重定向可以跨域访问，而转发是在web服务器内部进行的，不能跨域访问。 过程： 重定向：浏览器发出http请求 &gt;&gt; 服务器接受请求并发送302状态码和新的对应的url到浏览器 &gt;&gt; 浏览器接收响应并自动请求新的url &gt;&gt; 服务器接收请求并寻找客户所需的资源响应到浏览器。 转发：浏览器发出http求其 &gt;&gt; 服务器接收请求 &gt;&gt; 服务器调用内部的一个方法在容器内完成请求处理和转发动作 &gt;&gt; 将客户所需资源发送到浏览器。 调用方式： 重定向： 1).response.sendRedict(url);2).response.setState(302); response.setHeader(“location”,url)； 转发： 1).request.getRequestDispatcher(url).forward(request,response);2).request.getRequestDispatcher(url).include(request,response) 总结： 转发在服务器端完成的；重定向是在客户端完成的转发的速度快；重定向速度慢 转发的是同一次请求；重定向是两次不同请求 转发不会执行转发后的代码；重定向会执行重定向之后的代码 转发地址栏没有变化；重定向地址栏有变化 转发必须是在同一台服务器下完成；重定向可以在不同的服务器下完成]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么你一直没有成就（来干了这碗鸡汤）]]></title>
    <url>%2F2017%2F08%2F06%2F%E9%B8%A1%E6%B1%A4%E9%9A%8F%E7%AC%94%2F</url>
    <content type="text"><![CDATA[因为你随波逐流，近墨者黑、不思上进，分钱没有、死爱面子！因为你畏惧你的父母、你听信你亲戚、你没有主张、你不敢一个人做决定。你观念传统、只想结婚生子，然后生老病死、走你父母一模一样的路。因为你天生脆弱、脑筋迟钝只想做按班就部的工作。因为你总以为只有自己创业才叫成功 整天应付你现在的工作而不思进取。因为你想做无本的生意，你想坐在家里等天上掉陷饼！因为你抱怨没有机遇、机遇来到你身边的时候你又抓不住，因为你不会抓！因为你的贫穷，所以你自卑！你退缩了、你什么都不敢做！你没有特别技能，你只有使蛮力！你和你父母一样，恶性循环！所以，你永远一辈子碌碌无为，很多人想把握机会、但要做一件事情时，往往给自己找了很多理由让自己一直处于矛盾之中！不断浪费时间，虚度时光 1 、我没有口才——错：没有人天生就很会说话，台上的演讲大师也不是一下子就能出口成章，那是他们背后演练了无数次的结果！你骂人的时候很擅长，抱怨的时候也很擅长，但这种口才是没有价值的口才，看别人争论的时候、自己满嘴评头论足、却不知反省自己，倘若你付出努力练习，你今天是否还说自己没口才？ 2 、我没有钱—— 错： 不是没有钱，而是没有赚钱的脑袋。工作几年了没有钱么？有，但是花掉了。花在没有投资回报的事情上面。花在吃喝玩乐上或存放贬值了，没有实现价值最大化，所以钱就这样入不敷出。每月当月光族、周而复始、没有远虑、当一天和尚敲一天钟，得过且过。 3 、我没有能力——错：不给自己机会去锻炼，又有谁一出生就有能力？一毕业就是社会精英？一创业就马上成功？当别人很努力的学习、很努力的积累、努力找方法，而你每天就只做了很少一点就觉得乏味。学了一些就觉得没意思、看了几页书就不想看、跟自己也跟别人说没兴趣学。然后大半辈子过去一事无成，整天抱怨上天不给机会。能力是努力修来的、不努力想有能力，天才都会成蠢材。但努力，再笨的人也能成精英。 4 、我没有时间——错：时间很多、但浪费的也很多！别人很充实、你在看电视，别人在努力学习时、你在玩游戏消遣虚度。总之时间就是觉得很多余、你过得越来越无聊。别人赚钱了羡慕别人、但不去学别人好好把握时间创造价值，整天不学无术。 5 、我没有心情——错：心情好的时候去游玩、心情不好的时候在家喝闷酒，心情好的时候去逛街、心情不好的时候玩游戏，心情好的时候去享受、心情不好的时候就睡大觉。好坏心情都一样，反正就是不做正事。 6 、我没有兴趣——错：兴趣是什么？吃喝玩乐谁都有兴趣，没有成就哪来的尽兴！没钱拿什么享受生活！你的兴趣是什么？是出去旅游回来月光族、出去K歌回头钱包空空、出去大量购物回来惨兮兮…. 打工有没有兴趣？挤公交车有没有兴趣？上班签到下班打卡有没有兴趣？家里急需要一大笔钱拿不出来有没有兴趣？借了钱没钱还有没有兴趣？卖老鼠药的人对老鼠药有兴趣…..？ 7 、我考虑考虑——错：考虑做吧有可能就成了、不做吧好不甘心！一想整天上班也没有个头、还是明天开始做吧！又一想还是算了、这钱挣的也不容易！不不、决定了不能放弃机会！哎呀、天都黑了，明天再说吧！然后第二天又因为以上12345 点、因为左思右想、继续循环、最终不能决定。犹犹豫豫、耽误了很多时间、还是一无所获。有句话是：“可怜之人必有可恨之处！” 这一生中不是没有机遇，而是没有争取与把握！借口太多，理由太多….！争取之人必竭力争取、一分钱都没有也千方百计想办法！不争取之人给一百万也动不起来、发财不了、还有可能一败涂地。这就是行动力的欠缺！喜欢犹豫不决、喜欢拖延、喜欢一辈子平庸。在你穷的时候，要少在家里，多在外面。在你富有的时候，要多在家里，少在外面。这就是生活的艺术。 穷得时候，钱要花给别人，富的时候，钱要花给自己。很多人，都做颠倒了。 穷得时候，不要计较，对别人要好。富的时候，要学会让别人对自己好。自己对自己更好。 穷要把自己贡献出去，尽量让别人利用。富，要把自己收藏好，小心别让别人随便利用。这些奇妙的生活方式，是很少人能够明白的。 穷的时候，花钱给别人看。富的时候，花钱给自己享受。 穷的时候一定要大方，富的时候，就不要摆阔了。生命已经恢复了简单，已经回到了宁静。 年轻不是过错，贫穷无需害怕。懂得培养自己，懂得什么是贵重物品，懂得该投资什么，懂得该在哪里节约，这是整个过程的关键。 少在外面吃饭，要吃就请客，要请，就请比自己更有梦想的、更有思想、更努力的人。 一旦生活需要的钱已经够了，最大的花费，就是用你的收入，完成你的梦想，去放开你的翅膀大胆地做梦，去让生命经历不一样的旅程。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>鸡汤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2017%2F07%2F27%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java内存模型(Java Memory Model)：往往是指Java程序在运行时内存的模型，而Java代码是运行在Java虚拟机之上的，由Java虚拟机通过解释执行(解释器)或编译执行(即时编译器)来完成，虚拟机在执行Java程序的过程中，会把它管理的内存划分为几个不同的数据区域，这些区域都有各自的用途、创建时间、销毁时间。故Java内存模型，也就是指Java虚拟机的运行时内存模型。它包括程序计数器(Program Counter Register)、虚拟机栈（栈 Stack）、本地方法栈(Native Method Stack)、方法区(Method Area)、堆(Heap)。其实还有常量池，只不过他一般都是在方法区中。 Java栈： 栈是一种非常常见的数据结构，它采用典型的先进后出(后进先出 LIFO)的操作方式完成的。每一个栈都包含一个栈顶，每次出栈是将栈顶的数据取出，同样存数据也是存到栈顶。栈式一块连续的内存区域，大小是有操作系统觉决定的(这个可以在配置文件中配置)。所以栈的大小比较小，远远小于堆。主要存储一些引用和局部变量(基本类型的局部变量)和方法调用信息，也就是每个方法调用被压入栈中，当他运行完的时候(return)被弹出，每个方法也就是一个栈帧，所以栈内是有严格的生命周期的，同时当方法调用过多的时候，栈空间不足会抛出java.lang.StackOverFlowError。在Hot Spot虚拟机中，可以使用-Xss参数来设置栈的大小。栈的大小直接决定了函数调用的可达深度 Java栈总是与线程关联在一起的，每当创建一个线程，JVM就会为该线程创建对应的Java栈，在这个Java栈中又会包含多个栈帧(Stack Frame)，这些栈帧是与每个方法关联起来的，每运行一个方法就创建一个栈帧，每个栈帧会含有一些局部变量、操作栈和方法返回值等信息。每当一个方法执行完成时，该栈帧就会弹出栈帧的元素作为这个方法的返回值，并且清除这个栈帧，Java栈的栈顶的栈帧就是当前正在执行的活动栈，也就是当前正在执行的方法，PC寄存器也会指向该地址。只有这个活动的栈帧的本地变量可以被操作栈使用，当在这个栈帧中调用另外一个方法时，与之对应的一个新的栈帧被创建，这个新创建的栈帧被放到Java栈的栈顶，变为当前的活动栈。同样现在只有这个栈的本地变量才能被使用，当这个栈帧中所有指令都完成时，这个栈帧被移除Java栈，刚才的那个栈帧变为活动栈帧，前面栈帧的返回值变为这个栈帧的操作栈的一个操作数。所以Java栈是线程是不共享的，而堆内的数据是共享的 由于Java栈是与线程对应起来的，Java栈数据不是线程共有的，所以不需要关心其数据一致性，也不会存在同步锁的问题。 栈帧(Stack Frame)由三部分组成：局部变量区、操作数栈、帧数据区(动态链接方法，返回地址，额外的信息)。局部变量区和操作数栈的大小要视对应的方法而定，他们是按字长计算的。但调用一个方法时，它从类型信息中得到此方法局部变量区和操作数栈大小，并据此分配栈内存，然后压入Java栈。 局部变量表 (locals大小，编译期确定)，一组变量存储空间， 容量以slot为最小单位。 操作栈(stack大小，编译期确定)，操作栈元素的数据类型必须与字节码指令序列严格匹配 动态连接， 指向运行时常量池中该栈帧所属方法的引用，为了 动态连接使用。 前面的解析过程其实是静态解析； 对于运行期转化为直接引用，称为动态解析。 方法返回地址 正常退出，执行引擎遇到方法返回的字节码，将返回值传递给调用者 异常退出，遇到Exception,并且方法未捕捉异常，那么不会有任何返回值。 额外附加信息，虚拟机规范没有明确规定，由具体虚拟机实现。 Java堆： Java的堆，是用来存储真正的对象，即new的时候向内存申请的地方，Java是自动分配，他存储对象真正的信息。Java中通过引用去访问对象，即通过栈中的引用（存的是堆中的地址来拿到堆中的数据，这一点和C语言的指针很想，不过在Java中对堆的内存回收和处理都是通过JVM的GC(Garbage Collection)来处理内存。从内存回收的角度来看，由于现在GC基本都采用分代收集算法，所以Java堆还可以细分为：新生代和老年代；新生代再细致一点有Eden空间、From Survivor空间、To Survivor空间等。 从内存回收角度，Java堆被分为新生代和老年代；这样划分的好处是为了更快的回收内存； 从内存分配角度，Java堆可以划分出线程私有的分配缓冲区(Thread Local Allocation Buffer,TLAB)；这样划分的好处是为了更快的分配内存； 堆内存用来存储Java中的对象。无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内存中。堆空间不足会抛出异常java.lang.OutOfMemoryError。他是线程共享，每一线程都去堆（heap）去取值，是被所有Java线程锁共享的，也就是线程不安全的。关于在堆上内存分配是并发进行的，虚拟机采用CAS加失败重试保证原子操作，或者是采用每个线程预先分配TLAB内存。 对象创建的过程是在堆上分配着实例对象，那么对象实例的具体结构如下：对于填充数据不是一定存在的，仅仅是为了字节对齐。HotSpot VM的自动内存管理要求对象起始地址必须是8字节的整数倍。对象头本身是8的倍数，当对象的实例数据不是8的倍数，便需要填充数据来保证8字节的对齐。该功能类似于高速缓存行的对齐。 方法区： 方法区存放了要加载的类的信息（名称、修饰符等）、类中的静态常量、类中定义为final类型的常量、类中的Field信息、类中的方法信息，当在程序中通过Class对象的getName.isInterface等方法来获取信息时，这些数据都来源于方法区。方法区是被Java线程锁共享的，不像Java堆中其他部分一样会频繁被GC回收，它存储的信息相对比较稳定，在一定条件下会被GC，当方法区要使用的内存超过其允许的大小时，会抛出OutOfMemory的错误信息。方法区也是堆中的一部分，就是我们通常所说的Java堆中的永久区 Permanet Generation，大小可以通过参数来设置,可以通过-XX:PermSize指定初始值，-XX:MaxPermSize指定最大值，在java 8中移除方法区增加了MetaData区，也就是元数据区。 PC寄存器/程序计数器： 当前线程所执行的字节码行号指示器，严格来说是一个数据结构，用于保存当前正在执行的程序的内存地址，由于Java是支持多线程执行的，所以程序执行的轨迹不可能一直都是线性执行。当有多个线程交叉执行时，被中断的线程的程序当前执行到哪条内存地址必然要保存下来，以便用于被中断的线程恢复执行时再按照被中断时的指令地址继续执行下去。为了线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存,这在某种程度上有点类似于“ThreadLocal”，是线程安全的。 当线程正在执行一个Java方法时，PC计数器记录的是正在执行的虚拟机字节码的地址；当线程正在执行的一个Native方法时，PC计数器则为空（Undefined） 常量池： 常量池本身是方法区中的一个数据结构。常量池中存储了如字符串、final变量值、类名和方法名常量。常量池在编译期间就被确定，并保存在已编译的.class文件中。一般分为两类：字面量和应用量。字面量就是字符串、final变量等。类名和方法名属于引用量。引用量最常见的是在调用方法的时候，根据方法名找到方法的引用，并以此定为到函数体进行函数代码的执行。引用量包含：类和接口的权限定名、字段的名称和描述符，方法的名称和描述符。 本地方法栈： 本地方法栈和Java栈所发挥的作用非常相似，区别不过是Java栈为JVM执行Java方法服务，而本地方法栈为JVM执行Native方法服务。本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。 下面是详细的图片介绍：]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务]]></title>
    <url>%2F2017%2F06%2F17%2F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[(Transaction)事务:访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。也可以说一系列的操作，不允许加塞。Transaction是交易的意思，unit是单元也有单位的意思，也可以说是一种访问时交易的单位。 事务的特性：事务是恢复和并发的基本单位。即每次出问题回滚一个事务(Transaction)。在并发的情况下，也就是并发多个事务,也就是同时处理多个事务，事务之间是并发。 事务具有的四个属性：原子性 atomicity，一致性 consistency，隔离性 isolation，永久性 durability。 原子性：一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。也就是原子不可分割，但单内部执行，还是一条一条指令去执行。 一致性：事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。在关系型数据库中都是强一致性，非关系数据库中弱一致性也就是最终一致性是可以接受的。 强一致性：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值(可能是多个数据库节点，也有可能是单机)。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要牺牲可用性。 弱一致性：系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。 最终一致性：弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS 是一个典型的最终一致性系统(由于DNS多级缓存的实现，所以修改DNS记录后不会在全球所有DNS服务节点生效，需要等待DNS服务器缓存过期后向源服务器更新新的记录才能实现)。也可说最终一致性，就是不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。也可以简单的理解为在一段时间后，节点间的数据会最终达到一致状态。 隔离性：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。SQL标准定义了4类隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。 Read Uncommitted（读取未提交内容）在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read），这个一般只多个事务之间存在的问题。 Read Committed（读取提交内容）这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。 Repeatable Read（可重读，即一个事务中可以重复读取数据）这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读（Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影”行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。 Serializable（可串行化） 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。(不存在事务的并发) 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。即一次事务中不可已重复读取数据 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 持久性：持久性也称永久性，指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响，除非下一个事务中的操作更改这个数据。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS-乐观锁]]></title>
    <url>%2F2017%2F05%2F29%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁在java中一般并发编程时候（多线程）才会用到锁，锁的作用就是保证数据的一致性，防止操作数据时出现脏数据。而加上锁就可以保证 共享资源 会被单个线程使用，保证了数据的一致性。（即不会出现多个线程操作同一个资源导致数据异常）。不过引入了锁就会导致一个问题，那就是死锁 死锁顾明思义，就是因为锁的缘故（共享资源）导致两个或两个以上线程互相等待（阻塞），和死循环类似。 也可以指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 死锁的产生条件1、互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。2、请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。3、不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。4、环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源总结一下就是因为有共享资源，所以有竞争，有竞争后有锁，有锁后有死锁（不过非互斥锁没有死锁，也就是乐观锁，不过会一直自旋） 悲观锁顾名思义比较悲观，每次操作之前都上锁，不管用没有竞争都有锁；如果持有时间比较长的时间时，对性能上的开销比较大，因为每次都会将资源锁定。比如在java中synchronized关键字，synchronized一般用于引用类型而不是基本类型。 乐观锁也就是每次操作之前，都不上锁。然后通过一定检测手段决定是否更新数据，这种方式下，已经没有所谓的锁概念了，每条线程都直接先去执行操作，计算完成后检测是否与其他线程存在共享数据竞争，如果没有则让此操作成功，如果存在共享数据竞争则可能不断地重新执行操作和检测，直到成功为止。 乐观锁的缺点观锁只能保证一个共享变量的原子操作。如上例子，自旋过程中只能保证value变量的原子性，这时如果多一个或几个变量，乐观锁将变得力不从心，但互斥锁能轻易解决，不管对象数量多少及对象颗粒度大小。长时间自旋可能导致开销大。假如CAS长时间不成功而一直自旋，会给CPU带来很大的开销。ABA问题。CAS的核心思想是通过比对内存值与预期值是否一样而判断内存值是否被改过，但这个判断逻辑不严谨，假如内存值原来是A，后来被一条线程改为B，最后又被改成了A，则CAS认为此内存值并没有发生改变，但实际上是有被其他线程改过的，这种情况对依赖过程值的情景的运算结果影响很大。解决的思路是引入版本号，每次变量更新都把版本号加一。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap]]></title>
    <url>%2F2017%2F05%2F14%2FHashMap%2F</url>
    <content type="text"><![CDATA[什么是hash 散列法（Hashing）或哈希法是一种将字符组成的字符串转换为固定长度（一般是更短长度）的数值或索引值的方法，称为散列法，也叫哈希法。==简单来讲就是将任意长度的二进制映射到固定长度的较小的二进制，而这个较小的二进制是由hash算法来生成。== 在简单点就是像是查字典，只不过是字典里的查询不是a,b,c,d而是hashcode。而这个hashcode就有是较短的二进制。 什么是mapmap即映射，也就是平时说的key-value键值对，entry：也是key，value的形式存储的，有了entry后从map里取值，赋值上更方便[对象操作对象]（查了好多资料都是这样说的，而且好多实现都是把值存到entry中，在存到map里，而jdk8用的不是entry用的是node，而对hash算法，也是对entry或者是node的使用进行了hash而对map本身没有影响） 什么是hashMap，也就是使用了hash算法的map但是在代码实现就不是那么简单了。Java中的hashMap中的数据存储是由数组和链表实现的。 数组：组是在内存中开辟一段连续的空间，因此，只要知道了数组首个元素的地址，在数组中寻址就会非常容易，其时间复杂度为O(1)。但是当要插入或删除数据时，时间复杂度就会变为O(n)。 链表： 是内存中一系列离散的空间，其插入和删除操作的内存复杂度为O(1)，但是寻址操作的复杂度却是O(n)。那有没有一种方法可以结合两者的优点，即寻址，插入删除都快呢？这个方法就是HashMap。 散列函数：将数据的hashCode映射到散列表中的位置，此过程不需给出冲突解决方案。好的散列函数的2个必备条件：1，快捷，在O（1）时间内运行；2，均匀的分布hashCode，填充概率相同。 冲突解决方案（collisionsolution）：当一个新项散列到已经被占据的散列表中的位置时，被告之发生冲突，解决方案用于确定新项可以插入散列表中未被占据的位置。解决冲突主要的主要方法：开放寻址方法（寻找另外的空位）；封闭寻址方法（吊挂另一种数据结构）一般采用后者挂链表的方式。 再散列（rehash）：当数据的容量大于散列表的容量的容量时，那么创建一张指定新容量的表，再将原来表中的数据映射到新表中。 java.util.HashMap是很常见的类，实现了java.util.Map接口HashMap主要是用数组来存储数据的，我们都知道它会对key进行哈希运算，哈系运算会有重复的哈希值，对于哈希值的冲突，HashMap采用链表（挂链）来解决的。 Entry就是HashMap存储数据所用的类，相当于链表的节点。它拥有的属性如下Java代码 123456static class Entry implements Map.Entry &#123; final K key; V value; Entry next; int hash; &#125; 看到next了吗？next就是为了哈希冲突而存在的。比如通过哈希运算，一个新元素应该在数组的第10个位置，但是第10个位置已经有Entry，那么好吧，将新加的元素也放到第10个位置，将第10个位置的原有Entry赋值给当前新加的 Entry的next属性。数组存储的是链表，链表是为了解决哈希冲突的。 后记 这种一般在其他的包装类也可以看得到如arrayList中的 elementData。也是用来存放数据的。包装类只不过是帮你把一些操作封装了，相关操作，方便我们使用。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java语法糖]]></title>
    <url>%2F2017%2F05%2F14%2FJava%E8%AF%AD%E6%B3%95%E7%B3%96%2F</url>
    <content type="text"><![CDATA[Java语法糖（syntactic sugar），也称为糖衣语法，是由英国计算机科学家Peter.j.Landin发明的术语，指计算机语言中添加某种语法。（说白了就是对现有语法的封装）这种语法对语言是我功能并没有影响，但是方便程序员使用。Java中最常用的语法糖泛型，变长参数，条件编译，自动拆装箱，内部类，枚举类等。虚拟机其实并不支持这些语法，他们都是在编译期被还原成简单基础的语法结构。这个过程为语法糖。 泛型的实现 1234567891011121314151617/*** 在源代码中存在泛型*/public static void main(String[] args) &#123; Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;(); map.put("hello","你好"); String hello = map.get("hello"); System.out.println(hello);&#125;//当上述源代码被编译为class文件后，泛型被擦除且引入强制类型转换public static void main(String[] args) &#123; HashMap map = new HashMap(); //类型擦除 map.put("hello", "你好"); String hello = (String)map.get("hello");//强制转换 System.out.println(hello);&#125; 自动拆装箱的实现 12345678910111213141516//源码中的泛型public static void main(String[] args) &#123; Integer a = 1; int b = 2; int c = a + b; System.out.println(c);&#125;//编译为class文件public static void main(String[] args) &#123; Integer a = Integer.valueOf(1); // 自动装箱 byte b = 2; int c = a.intValue() + b;//自动拆箱 System.out.println(c);&#125; 变长参数 123456789101112131415161718192021222324252627282930313233//源码中的变长参数public class Varargs &#123; public static void print(String... args) &#123; for(String str : args)&#123; System.out.println(str); &#125; &#125; public static void main(String[] args) &#123; print(&quot;hello&quot;, &quot;world&quot;); &#125;&#125;//编译后的变长参数，而且能看出来变长参数是通过数组实现的public class Varargs &#123; public Varargs() &#123; &#125; public static void print(String... args) &#123; String[] var1 = args; int var2 = args.length; //增强for循环的数组实现方式 for(int var3 = 0; var3 &lt; var2; ++var3) &#123; String str = var1[var3]; System.out.println(str); &#125; &#125; public static void main(String[] args) &#123; //变长参数转换为数组 print(new String[]&#123;&quot;hello&quot;, &quot;world&quot;&#125;); &#125;&#125; 内部类 12345678910111213//在源码中的内部类public class Outer &#123; class Inner&#123; &#125;&#125;//在编译后的内部类class Outer$Inner &#123; Outer$Inner(Outer var1) &#123; this.this$0 = var1; &#125;&#125; 枚举类型 1234567891011121314151617181920212223242526272829303132333435363738394041//在源码中的枚举实现public enum Fruit &#123; APPLE,ORINGE&#125;//编译后的枚举//继承java.lang.Enum并声明为finalpublic final class Fruit extends Enum&#123; public static Fruit[] values() &#123; return (Fruit[])$VALUES.clone(); &#125; public static Fruit valueOf(String s) &#123; return (Fruit)Enum.valueOf(Fruit, s); &#125; private Fruit(String s, int i) &#123; super(s, i); &#125; //枚举类型常量 public static final Fruit APPLE; public static final Fruit ORANGE; private static final Fruit $VALUES[];//使用数组进行维护 static &#123; //protected Enum(String name, int ordinal),这个构造函数是Enum自带的，ordinal是用来排序的 APPLE = new Fruit(&quot;APPLE&quot;, 0); ORANGE = new Fruit(&quot;ORANGE&quot;, 1); $VALUES = (new Fruit[] &#123; APPLE, ORANGE &#125;); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
</search>
